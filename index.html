<!DOCTYPE html>
<html>
<head>
	<title>Essentia Algorithm Table</title>
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://bootswatch.com/lumen/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.2/jquery.min.js"></script>
<style type="text/css">
body{
	padding: 10px;
}
th, td {
  word-wrap:break-word;
  word-break:break-word;
}
.table-hover tbody tr:hover td, .table-hover tbody tr:hover th {
  background-color: #D3D4D8;
}
.results tr[visible='false'],
.no-result{
  display:none;
}

.results tr[visible='true']{
  display:table-row;
}

.counter{
  padding:8px; 
  color:#ccc;
}
.topright{
	position: fixed;
	top: 25px;
	right: 10px;
	height: 48px;
	padding: 5px;
	outline: 2px solid #c81331;
	background-color: white;
}
header > h1 { display: inline-block;color: #c81331; }
header p { display: inline-block; }
</style>
<script type="text/javascript">
$(document).ready(function() {
  $(".search").keyup(function () {
    var searchTerm = $(".search").val();
    var listItem = $('.results tbody').children('tr');
    var searchSplit = searchTerm.replace(/ /g, "'):containsi('")
    
  $.extend($.expr[':'], {'containsi': function(elem, i, match, array){
        return (elem.textContent || elem.innerText || '').toLowerCase().indexOf((match[3] || "").toLowerCase()) >= 0;
    }
  });
    
  $(".results tbody tr").not(":containsi('" + searchSplit + "')").each(function(e){
    $(this).attr('visible','false');
  });

  $(".results tbody tr:containsi('" + searchSplit + "')").each(function(e){
    $(this).attr('visible','true');
  });

  var jobCount = $('.results tbody tr[visible="true"]').length;
    $('.counter').text(jobCount + ' item');

  if(jobCount == '0') {$('.no-result').show();}
    else {$('.no-result').hide();}
		  });
});
</script>	
</head>
<body>
<header><h1>Essentia Algorithm Table</h1>
<p class="text-muted">by Kevin Yen</p></header>
<div class="topright"><div class="form-group pull-right">
    <input type="text" class="search form-control" placeholder="Search the table">
</div>
<span class="counter pull-right"></span></div>
<hr>
<table class="table table-striped table-hover results">
    <thead>
        <tr>
            <th>Algorithm</th>
            <th>Inputs</th>
            <th>Outputs</th>
            <th>Parameters</th>
            <th>Description</th>
        </tr>
	    <tr class="warning no-result">
	      <td colspan="4"><i class="fa fa-warning"></i> No result</td>
	    </tr>
    </thead>
    <tbody>
<tr>
<th scope="row" class="col-xs-1">
AfterMaxToBeforeMaxEnergyRatio<br>[standard]

</th><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the array of pitch values [Hz]</li>
</td><td class="col-xs-2">
<li><strong>afterMaxToBeforeMaxEnergyRatio</strong> (<em>real</em>) - the ratio between the pitch energy after the pitch maximum to the pitch energy before the pitch maximum</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the ratio between the pitch energy after the pitch maximum and the pitch energy before the pitch maximum. Sounds having an monotonically ascending pitch or one unique pitch will show a value of (0,1], while sounds having a monotonically descending pitch will show a value of [1,∞). In case there is no energy before the max pitch, the algorithm will return the energy after the maximum pitch.</p>
<p>The algorithm throws exception when input is either empty or contains only zeros.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AllPass<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandwidth</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the bandwidth of the filter [Hz] (used only for 2nd-order filters)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>order</strong> (<em>integer ∈ {1, 2}, default = 1</em>) :</dt>
<dd><p class="first last">the order of the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a IIR all-pass filter of order 1 or 2. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, p. 43,
John Wiley &amp; Sons, 2002</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AudioLoader<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_stereosample</em>) - the input audio signal</li>
<li><strong>sampleRate</strong> (<em>real</em>) - the sampling rate of the audio signal [Hz]</li>
<li><strong>numberChannels</strong> (<em>integer</em>) - the number of channels</li>
<li><strong>md5</strong> (<em>string</em>) - the MD5 checksum of raw undecoded audio payload</li>
<li><strong>bit_rate</strong> (<em>integer</em>) - the bit rate of the input audio, as reported by the decoder codec</li>
<li><strong>codec</strong> (<em>string</em>) - the codec that is used to decode the input audio</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>computeMD5</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">compute the MD5 checksum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file this algorithm loads an audio file and outputs the raw signal data, the samplerate and the number of channels. Supported formats are: wav, aiff, flac (not supported on Windows), ogg and mp3.</p>
<p>This algorithm will throw an exception if it hasn't been properly configured which normally is due to not specifying a valid filename. Invalid names comprise those with extensions different than the supported  formats and non existent files.
Note: ogg files are decoded in reverse phase, due to be using ffmpeg library.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] WAV - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Wav">http://en.wikipedia.org/wiki/Wav</a></dd>
<dt>[2] Audio Interchange File Format - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Aiff">http://en.wikipedia.org/wiki/Aiff</a></dd>
<dt>[3] Free Lossless Audio Codec - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Flac">http://en.wikipedia.org/wiki/Flac</a></dd>
<dt>[4] Vorbis - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Vorbis">http://en.wikipedia.org/wiki/Vorbis</a></dd>
<dt>[5] MP3 - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Mp3">http://en.wikipedia.org/wiki/Mp3</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AudioOnsetsMarker<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal mixed with bursts at onset locations</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>onsets</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of onset locations [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the output signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {beep, noise}, default = beep</em>) :</dt>
<dd><p class="first last">the type of sound to be added on the event</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm creates a wave file in which a given audio signal is mixed with a series of time onsets. The sonification of the onsets can be heard as beeps, or as short white noise pulses if configured to do so.</p>
<p>This algorithm will throw an exception if parameter &quot;filename&quot; is not supplied</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AudioWriter<br>[standard]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_stereosample</em>) - the audio signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bitrate</strong> (<em>integer ∈ {32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160, 192, 224, 256, 320}, default = 192</em>) :</dt>
<dd><p class="first last">the audio bit rate for compressed formats [kbps]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the encoded file</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>format</strong> (<em>string ∈ {wav, aiff, mp3, ogg, flac}, default = wav</em>) :</dt>
<dd><p class="first last">the audio output format</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm encodes an input signal into a stereo audio file.</p>
<p>Supported formats are wav, aiff, mp3, flac and ogg.</p>
<p>An exception is thrown when other extensions are given. Note that to encode in mp3 format it is mandatory that ffmpeg was configured with mp3 enabled.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AutoCorrelation<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the array to be analyzed</li>
</td><td class="col-xs-2">
<li><strong>autoCorrelation</strong> (<em>vector_real</em>) - the autocorrelation vector</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>normalization</strong> (<em>string ∈ {standard, unbiased}, default = standard</em>) :</dt>
<dd><p class="first last">type of normalization to compute: either 'standard' (default) or 'unbiased'</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the autocorrelation vector of a signal.
It uses the version most commonly used in signal processing, which doesn't remove the mean from the observations.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Autocorrelation -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/Autocorrelation.html">http://mathworld.wolfram.com/Autocorrelation.html</a></p>
<p class="last">[2] Autocorrelation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Autocorrelation">http://en.wikipedia.org/wiki/Autocorrelation</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BandPass<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandwidth</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the bandwidth of the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 2nd order IIR band-pass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, 2nd edition, p. 55,
John Wiley &amp; Sons, 2011</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BandReject<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandwidth</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the bandwidth of the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 2nd order IIR band-reject filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, 2nd edition, p. 55,
John Wiley &amp; Sons, 2011</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BarkBands<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy of the bark bands</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ [1, 28], default = 27</em>) :</dt>
<dd><p class="first last">the number of desired barkbands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ [0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the spectral energy contained in a given number of bands, which correspond to an extrapolation of the Bark band scale [1]:
[0.0, 50.0, 100.0, 150.0, 200.0, 300.0, 400.0, 510.0, 630.0, 770.0, 920.0, 1080.0, 1270.0, 1480.0, 1720.0, 2000.0, 2320.0, 2700.0, 3150.0, 3700.0, 4400.0, 5300.0, 6400.0, 7700.0, 9500.0, 12000.0, 15500.0, 20500.0, 27000.0]</p>
<p>For each bark band the power-spectrum (mag-squared) is summed. The first two bands [0,100] and [100,200] have been split in half for better resolution. It was observed that beat detection is better when this is done.</p>
<p>This algorithm uses FrequencyBands and thus inherits its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] The Bark Frequency Scale,
<a class="reference external" href="http://ccrma.stanford.edu/~jos/bbt/Bark_Frequency_Scale.html">http://ccrma.stanford.edu/~jos/bbt/Bark_Frequency_Scale.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Beatogram<br>[standard]

</th><td class="col-xs-2">
<li><strong>loudness</strong> (<em>vector_real</em>) - the loudness at each beat</li>
<li><strong>loudnessBandRatio</strong> (<em>vector_vector_real</em>) - matrix of loudness ratios at each band and beat</li>
</td><td class="col-xs-2">
<li><strong>beatogram</strong> (<em>vector_vector_real</em>) - filtered matrix loudness</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 16</em>) :</dt>
<dd><p class="first last">number of beats for dynamic filtering</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm filters the loudness matrix given by BeatsLoudness algorithm in order to keep only the most salient beat band representation.
This algorithm has been found to be useful for estimating time signatures.</p>
<p>Quality: experimental (not evaluated, do not use)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BeatsLoudness<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>vector_real</em>) - the beat's energy in the whole spectrum</li>
<li><strong>loudnessBandRatio</strong> (<em>vector_vector_real</em>) - the ratio of the beat's energy on each frequency band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>beatDuration</strong> (<em>real ∈ (0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">the duration of the window in which the beat will be restricted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beatWindowDuration</strong> (<em>real ∈ (0, ∞), default = 0.1</em>) :</dt>
<dd><p class="first last">the duration of the window in which to look for the beginning of the beat (centered around the positions in 'beats') [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beats</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of beat positions (each position is in seconds)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [20, 150, 400, 3200, 7000, 22000]</em>) :</dt>
<dd><p class="first last">the list of bands to compute energy ratios [Hz</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Calculates the loudness computed only on the beats, both on the whole frequency range and on each specified frequency band. See the Loudness algorithm for a description of loudness and SingleBeatLoudness for a more detailed explanation.</p>
<p>Note that the algorithm will output empty results in the case if no beats are specified in the &quot;beats&quot; parameter.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BeatTrackerDegara<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) -  the estimated tick locations [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the beat locations given an input signal. It computes 'complex spectral difference' onset detection function and utilizes the beat tracking algorithm (TempoTapDegara) to extract beats [1]. The algorithm works with the optimized settings of 2048/1024 frame/hop size for the computation of the detection function, with its posterior x2 resampling.) While it has a lower accuracy than BeatTrackerMultifeature (see the evaluation results in [2]), its computational speed is significantly higher, which makes reasonable to apply this algorithm for batch processings of large amounts of audio signals.</p>
<p>Note that the algorithm requires the audio input with the 44100 Hz sampling rate in order to function correctly.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] N. Degara, E. A. Rua, A. Pena, S. Torres-Guijarro, M. E. Davies, and
M. D. Plumbley, &quot;Reliability-informed beat tracking of musical signals,&quot;
IEEE Transactions on Audio, Speech, and Language Processing, vol. 20,
no. 1, pp. 290–301, 2012.</p>
<p class="last">[2] J. Zapata, M.E.P. Davies and E. Gómez, &quot;Multi Feature Beat tracker,&quot;
submitted article to IEEE TSALP, 2013.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BeatTrackerMultiFeature<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) -  the estimated tick locations [s]</li>
<li><strong>confidence</strong> (<em>real</em>) - confidence of the beat tracker [0, 5.32]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the beat locations given an input signal. It computes a number of onset detection functions and estimates beat location candidates from them using TempoTapDegara algorithm. Thereafter the best candidates are selected using TempoTapMaxAgreement. The employed detection functions, and the optimal frame/hop sizes used for their computation are:</p>
<blockquote>
<ul class="simple">
<li>complex spectral difference (see 'complex' method in OnsetDetection algorithm, 2048/1024 with posterior x2 upsample or the detection function)</li>
<li>energy flux (see 'rms' method in OnsetDetection algorithm, the same settings)</li>
<li>spectral flux in Mel-frequency bands (see 'melflux' method in OnsetDetection algorithm, the same settings)</li>
<li>beat emphasis function (see 'beat_emphasis' method in OnsetDetectionGlobal algorithm, 2048/512)</li>
<li>spectral flux between histogrammed spectrum frames, measured by the modified information gain (see 'infogain' method in OnsetDetectionGlobal algorithm, 2048/512)</li>
</ul>
</blockquote>
<p>You can follow these guidelines [2] to assess the quality of beats estimation based on the computed confidence value:</p>
<blockquote>
<ul class="simple">
<li>[0, 1)      very low confidence, the input signal is hard for the employed candidate beat trackers</li>
<li>[1, 1.5]    low confidence</li>
<li>(1.5, 3.5]  good confidence, accuracy around 80% in AMLt measure</li>
<li>(3.5, 5.32] excellent confidence</li>
</ul>
</blockquote>
<p>Note that the algorithm requires the audio input with the 44100 Hz sampling rate in order to function correctly.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Zapata, M. Davies and E. Gómez, &quot;Multi-feature beat tracker,&quot;
IEEE/ACM Transactions on Audio, Speech and Language Processing. 22(4),
816-825, 2014</p>
<p class="last">[2] J.R. Zapata, A. Holzapfel, M.E.P. Davies, J.L. Oliveira, F. Gouyon,
&quot;Assigning a confidence threshold on automatic beat annotation in large
datasets&quot;, International Society for Music Information Retrieval Conference
(ISMIR'12), pp. 157-162, 2012</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BinaryOperator<br>[standard]

</th><td class="col-xs-2">
<li><strong>array1</strong> (<em>vector_real</em>) - the first operand input array</li>
<li><strong>array2</strong> (<em>vector_real</em>) - the second operand input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the array containing the result of binary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {add, subtract, multiply, divide}, default = add</em>) :</dt>
<dd><p class="first last">the type of the binary operator to apply to the input arrays</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given two vectors of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>using this algorithm in streaming mode can cause diamond shape graphs which have not been tested with the current scheduler. There is NO GUARANTEE of its correct work for diamond shape graphs.</li>
<li>for y&lt;0, x/y is invalid</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BinaryOperatorStream<br>[standard]

</th><td class="col-xs-2">
<li><strong>array1</strong> (<em>vector_real</em>) - the first operand input array</li>
<li><strong>array2</strong> (<em>vector_real</em>) - the second operand input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the array containing the result of binary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {add, subtract, multiply, divide}, default = add</em>) :</dt>
<dd><p class="first last">the type of the binary operator to apply to the input arrays</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given two vectors of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>using this algorithm in streaming mode can cause diamond shape graphs which have not been tested with the current scheduler. There is NO GUARANTEE of its correct work for diamond shape graphs.</li>
<li>for y&lt;0, x/y is invalid</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BPF<br>[standard]

</th><td class="col-xs-2">
<li><strong>x</strong> (<em>real</em>) - the input coordinate (x-axis)</li>
</td><td class="col-xs-2">
<li><strong>y</strong> (<em>real</em>) - the output coordinate (y-axis)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>xPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the x-coordinates of the points forming the break-point function (the points must be arranged in ascending order and cannot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>yPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the y-coordinates of the points forming the break-point function</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>A break point function linearly interpolates between discrete xy-coordinates to construct a continuous function.</p>
<p>Exceptions are thrown when the size the vectors specified in parameters is not equal and at least they contain two elements. Also if the parameter vector for x-coordinates is not sorted ascendantly. A break point function cannot interpolate outside the range specified in parameter &quot;xPoints&quot;. In that case an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Linear interpolation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Linear_interpolation">http://en.wikipedia.org/wiki/Linear_interpolation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BpmHistogramDescriptors<br>[standard]

</th><td class="col-xs-2">
<li><strong>bpmIntervals</strong> (<em>vector_real</em>) - the list of bpm intervals [s]</li>
</td><td class="col-xs-2">
<li><strong>firstPeakBPM</strong> (<em>real</em>) - value for the highest peak [bpm]</li>
<li><strong>firstPeakWeight</strong> (<em>real</em>) - weight of the highest peak</li>
<li><strong>firstPeakSpread</strong> (<em>real</em>) - spread of the highest peak</li>
<li><strong>secondPeakBPM</strong> (<em>real</em>) - value for the second highest peak [bpm]</li>
<li><strong>secondPeakWeight</strong> (<em>real</em>) - weight of the second highest peak</li>
<li><strong>secondPeakSpread</strong> (<em>real</em>) - spread of the second highest peak</li>
<li><strong>histogram</strong> (<em>vector_real</em>) - bpm histogram [bpm]</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes beats per minute histogram and its statistics for the highest and second highest peak.
Note: histogram vector contains occurance frequency for each bpm value, 0-th element corresponds to 0 bpm value.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BpmRubato<br>[standard]

</th><td class="col-xs-2">
<li><strong>beats</strong> (<em>vector_real</em>) - list of detected beat ticks [s]</li>
</td><td class="col-xs-2">
<li><strong>rubatoStart</strong> (<em>vector_real</em>) - list of timestamps where the start of a rubato region was detected [s]</li>
<li><strong>rubatoStop</strong> (<em>vector_real</em>) - list of timestamps where the end of a rubato region was detected [s]</li>
<li><strong>rubatoNumber</strong> (<em>integer</em>) - number of detected rubato regions</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>longRegionsPruningTime</strong> (<em>real ∈ [0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">time for the longest constant tempo region inside a rubato region [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>shortRegionsMergingTime</strong> (<em>real ∈ [0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">time for the shortest constant tempo region from one tempo region to another [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, 1], default = 0.08</em>) :</dt>
<dd><p class="first last">minimum tempo deviation to look for</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the locations of large tempo changes from a list of beat ticks.</p>
<p>An exception is thrown if the input beats are not in ascending order and/or if the input beats contain duplicate values.</p>
<p>Quality: experimental (non-reliable, poor accuracy).</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Tempo Rubato - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Rubato">http://en.wikipedia.org/wiki/Rubato</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CartesianToPolar<br>[standard]

</th><td class="col-xs-2">
<li><strong>complex</strong> (<em>vector_complex</em>) - the complex input vector</li>
</td><td class="col-xs-2">
<li><strong>magnitude</strong> (<em>vector_real</em>) - the magnitude vector</li>
<li><strong>phase</strong> (<em>vector_real</em>) - the phase vector</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm converts an array of complex numbers from its cartesian form to its polar form using the Euler formula:</dt>
<dd><dl class="first last docutils">
<dt>z = x + i*y = |z|(cos(α) + i sin(α))</dt>
<dd>where x = Real part, y = Imaginary part,
and |z| = modulus = magnitude, α = phase in (-π,π]</dd>
</dl>
</dd>
</dl>
<p>It returns the magnitude and the phase as 2 separate vectors.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Polar Coordinates -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/PolarCoordinates.html">http://mathworld.wolfram.com/PolarCoordinates.html</a></p>
<p class="last">[2] Polar coordinate system - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Polar_coordinates">http://en.wikipedia.org/wiki/Polar_coordinates</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CentralMoments<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>centralMoments</strong> (<em>vector_real</em>) - the central moments of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>mode</strong> (<em>string ∈ {pdf, sample}, default = pdf</em>) :</dt>
<dd><p class="first last">compute central moments considering array values as a probability density function over array index or as sample points of a distribution</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results in the 'pdf' mode</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the 0th, 1st, 2nd, 3rd and 4th central moments of an array (i.e. it returns a 5-tuple in which the index corresponds to the order of the moment).</p>
<p>Central moments cannot be computed on arrays which size is less than 2, in which case an exception is thrown.</p>
<p>Note: the 'mode' parameter defines whether to treat array values as a probability distribution function (pdf) or as sample points of a distribution (sample).</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Sample Central Moment -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/SampleCentralMoment.html">http://mathworld.wolfram.com/SampleCentralMoment.html</a></p>
<p class="last">[2] Central Moment - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Central_moment">http://en.wikipedia.org/wiki/Central_moment</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Centroid<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>centroid</strong> (<em>real</em>) - the centroid of the array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the centroid, normalized to a specified range, of the input array [1]. In particular, it can be used to compute spectral centroid or temporal centroid.</p>
<p>The spectral centroid is a measure that indicates where the &quot;center of mass&quot; of the spectrum is. Perceptually, it has a robust connection with the impression of &quot;brightness&quot; of a sound, and therefore is used to characterise musical timbre. It is calculated as the weighted mean of the frequencies present in the signal, with their magnitudes as the weights.</p>
<p>The temporal centroid is the point in time in a signal that is a temporal balancing point of the sound event energy. It can be computed from the envelope of the signal across audio samples [3] (see Envelope algorithm) or over the RMS level of signal across frames [4] (see RMS algorithm).</p>
<p>Note:
- For a spectral centroid [hz], frequency range should be equal to samplerate/2
- For a temporal envelope centroid [s], range should be equal to (audio_size_in_samples-1) / samplerate
- Exceptions are thrown when input array contains less than 2 elements.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Function Centroid -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/FunctionCentroid.html">http://mathworld.wolfram.com/FunctionCentroid.html</a>
[2] Spectral centroid - Wikipedia, the free encyclopedia,
<a class="reference external" href="https://en.wikipedia.org/wiki/Spectral_centroid">https://en.wikipedia.org/wiki/Spectral_centroid</a>
[3] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004.
[4] Klapuri, A., &amp; Davy, M. (Eds.). (2007). Signal processing methods for
music transcription. Springer Science &amp; Business Media.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ChordsDescriptors<br>[standard]

</th><td class="col-xs-2">
<li><strong>chords</strong> (<em>vector_string</em>) - the chord progression</li>
<li><strong>key</strong> (<em>string</em>) - the key of the whole song, from A to G</li>
<li><strong>scale</strong> (<em>string</em>) - the scale of the whole song (major or minor)</li>
</td><td class="col-xs-2">
<li><strong>chordsHistogram</strong> (<em>vector_real</em>) - the normalized histogram of chords</li>
<li><strong>chordsNumberRate</strong> (<em>real</em>) - the ratio of different chords from the total number of chords in the progression</li>
<li><strong>chordsChangesRate</strong> (<em>real</em>) - the rate at which chords change in the progression</li>
<li><strong>chordsKey</strong> (<em>string</em>) - the most frequent chord of the progression</li>
<li><strong>chordsScale</strong> (<em>string</em>) - the scale of the most frequent chord of the progression (either 'major' or 'minor')</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>Given a chord progression this algorithm describes it by means of key, scale, histogram, and rate of change.
Note:</p>
<blockquote>
<ul class="simple">
<li>chordsHistogram indexes follow the circle of fifths order, while being shifted to the input key and scale</li>
<li>key and scale are taken from the most frequent chord. In the case where multiple chords are equally frequent, the chord is hierarchically chosen from the circle of fifths.</li>
<li>valid chords are C, Em, G, Bm, D, F#m, A, C#m, E, G#m, B, D#m, F#, A#m, C#, Fm, G#, Cm, D#, Gm, A#, Dm, F, Am. Chords that not follow this terminology (i.e. Gb) will raise an exception.</li>
</ul>
</blockquote>
<p>Input chords vector may not be empty, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Chord progression - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Chord_progression">http://en.wikipedia.org/wiki/Chord_progression</a></p>
<p class="last">[2] Circle of fifths - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Circle_of_fifths">http://en.wikipedia.org/wiki/Circle_of_fifths</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ChordsDetection<br>[standard]

</th><td class="col-xs-2">
<li><strong>pcp</strong> (<em>vector_vector_real</em>) - the pitch class profile from which to detect the chord</li>
</td><td class="col-xs-2">
<li><strong>chords</strong> (<em>vector_string</em>) - the resulting chords, from A to G</li>
<li><strong>strength</strong> (<em>vector_real</em>) - the strength of the chord</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hop size with which the input PCPs were computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>windowSize</strong> (<em>real ∈ (0, ∞), default = 2</em>) :</dt>
<dd><p class="first last">the size of the window on which to estimate the chords [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Using pitch profile classes, this algorithm calculates the best matching major or minor triad and outputs the result as a string (e.g. A#, Bm, G#m, C). This algorithm uses the Sharp versions of each Flatted note (i.e. Bb -&gt; A#).</p>
<p>Note:</p>
<blockquote>
<ul class="simple">
<li>This algorithm assumes that input pcps have been computed with framesize = 2*hopsize</li>
</ul>
</blockquote>
<p>Quality: experimental (prone to errors, algorithm needs improvement)</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez, &quot;Tonal Description of Polyphonic Audio for Music Content
Processing,&quot; INFORMS Journal on Computing, vol. 18, no. 3, pp. 294–304,
2006.</p>
<p class="last">[2] D. Temperley, &quot;What's key for key? The Krumhansl-Schmuckler
key-finding algorithm reconsidered&quot;, Music Perception vol. 17, no. 1,
pp. 65-100, 1999.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ChordsDetectionBeats<br>[standard]

</th><td class="col-xs-2">
<li><strong>pcp</strong> (<em>vector_vector_real</em>) - the pitch class profile from which to detect the chord</li>
<li><strong>ticks</strong> (<em>vector_real</em>) - the list of beat positions (in seconds)</li>
</td><td class="col-xs-2">
<li><strong>chords</strong> (<em>vector_string</em>) - the resulting chords, from A to G</li>
<li><strong>strength</strong> (<em>vector_real</em>) - the strength of the chords</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hop size with which the input PCPs were computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates chords using pitch profile classes similar to ChordsDetection algorithm given a list of beat positions. The chords are estimated on audio segments between each pair of consecutive beats.</p>
<p>Quality: experimental (algorithm needs evaluation)</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez, &quot;Tonal Description of Polyphonic Audio for Music Content
Processing,&quot; INFORMS Journal on Computing, vol. 18, no. 3, pp. 294–304,
2006.</p>
<p class="last">[2] D. Temperley, &quot;What's key for key? The Krumhansl-Schmuckler
key-finding algorithm reconsidered&quot;, Music Perception vol. 17, no. 1,
pp. 65-100, 1999.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Clipper<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the output signal with the added noise</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>max</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum value above which the signal will be clipped</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>min</strong> (<em>real ∈ (-∞, ∞), default = -1</em>) :</dt>
<dd><p class="first last">the minimum value below which the signal will be clipped</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm clips the input signal to fit between the range given by the min and max parameters.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Clipping - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Clipping_(audio">http://en.wikipedia.org/wiki/Clipping_(audio</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Crest<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (cannot contain negative values, and must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>crest</strong> (<em>real</em>) - the crest of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the crest of an array. The crest is defined as the ratio between the maximum value and the arithmetic mean of an array. Typically it is used on the magnitude spectrum.</p>
<p>Crest cannot be computed neither on empty arrays nor arrays which contain negative values. In such cases, exceptions will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CrossCorrelation<br>[standard]

</th><td class="col-xs-2">
<li><strong>arrayX</strong> (<em>vector_real</em>) - the first input array</li>
<li><strong>arrayY</strong> (<em>vector_real</em>) - the second input array</li>
</td><td class="col-xs-2">
<li><strong>crossCorrelation</strong> (<em>vector_real</em>) - the cross-correlation vector between the two input arrays (its size is equal to maxLag - minLag + 1)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxLag</strong> (<em>integer ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum lag to be computed between the two vectors</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minLag</strong> (<em>integer ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the minimum lag to be computed between the two vectors</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the cross-correlation vector of two signals. It accepts 2 parameters, minLag and maxLag which define the range of the computation of the innerproduct.</p>
<p>An exception is thrown if &quot;minLag&quot; is larger than &quot;maxLag&quot;. An exception is also thrown if the input vectors are empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Cross-correlation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Cross-correlation">http://en.wikipedia.org/wiki/Cross-correlation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CubicSpline<br>[standard]

</th><td class="col-xs-2">
<li><strong>x</strong> (<em>real</em>) - the input coordinate (x-axis)</li>
</td><td class="col-xs-2">
<li><strong>y</strong> (<em>real</em>) - the value of the spline at x</li>
<li><strong>dy</strong> (<em>real</em>) - the first derivative of the spline at x</li>
<li><strong>ddy</strong> (<em>real</em>) - the second derivative of the spline at x</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>leftBoundaryFlag</strong> (<em>integer ∈ {0, 1, 2}, default = 0</em>) :</dt>
<dd><p class="first last">type of boundary condition for the left boundary</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>leftBoundaryValue</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the value to be used in the left boundary, when leftBoundaryFlag is 1 or 2</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>rightBoundaryFlag</strong> (<em>integer ∈ {0, 1, 2}, default = 0</em>) :</dt>
<dd><p class="first last">type of boundary condition for the right boundary</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>rightBoundaryValue</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the value to be used in the right boundary, when rightBoundaryFlag is 1 or 2</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>xPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the x-coordinates where data is specified (the points must be arranged in ascending order and cannot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>yPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the y-coordinates to be interpolated (i.e. the known data)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Computes the second derivatives of a piecewise cubic spline.
The input value, i.e. the point at which the spline is to be evaluated typically should be between xPoints[0] and xPoints[size-1]. If the value lies outside this range, extrapolation is used.
Regarding [left/right] boundary condition flag parameters:</p>
<blockquote>
<ul class="simple">
<li>0: the cubic spline should be a quadratic over the first interval</li>
<li>1: the first derivative at the [left/right] endpoint should be [left/right]BoundaryFlag</li>
<li>2: the second derivative at the [left/right] endpoint should be [left/right]BoundaryFlag</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Spline interpolation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Spline_interpolation">http://en.wikipedia.org/wiki/Spline_interpolation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Danceability<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>danceability</strong> (<em>real</em>) - the danceability value. Normal values range from 0 to ~3. The higher, the more danceable.</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTau</strong> (<em>real ∈ (0, ∞), default = 8800</em>) :</dt>
<dd><p class="first last">maximum segment length to consider [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTau</strong> (<em>real ∈ (0, ∞), default = 310</em>) :</dt>
<dd><p class="first last">minimum segment length to consider [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tauMultiplier</strong> (<em>real ∈ [1, ∞), default = 1.1</em>) :</dt>
<dd><p class="first last">multiplier to increment from min to max tau</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Calculates the danceability vector for a given signal. The algorithm is
derived from Detrended Fluctuation Analysis (DFA) described in [1]. The
parameters minTau and maxTau are used to define the range of time over
which DFA will be performed. The output of this algorithm is the
danceability of the audio signal. These values usually range from 0 to 3
(higher values meaning more danceable).
Exception is thrown when minTau is greater than maxTau.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Streich, S. and Herrera, P., Detrended Fluctuation Analysis of Music
Signals: Danceability Estimation and further Semantic Characterization,
Proceedings of the AES 118th Convention, Barcelona, Spain, 2005</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DCRemoval<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal, with the DC component removed</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm removes the DC offset from a signal using a 1st order IIR highpass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Smith, J.O.  Introduction to Digital Filters with Audio Applications,
<a class="reference external" href="http://ccrma-www.stanford.edu/~jos/filters/DC_Blocker.html">http://ccrma-www.stanford.edu/~jos/filters/DC_Blocker.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DCT<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>dct</strong> (<em>vector_real</em>) - the discrete cosine transform of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ [1, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the size of the input array</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>outputSize</strong> (<em>integer ∈ [1, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the number of output coefficients</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the Discrete Cosine Transform of an array.
It uses the DCT-II form, with the 1/sqrt(2) scaling factor for the first coefficient.
Note: The 'inputSize' parameter is only used as an optimization when the algorithm is configured. The DCT will automatically adjust to the size of any input.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Discrete cosine transform - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Discrete_cosine_transform">http://en.wikipedia.org/wiki/Discrete_cosine_transform</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Decrease<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>decrease</strong> (<em>real</em>) - the decrease of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the decrease of an array of Reals (which is defined as the linear regression coefficient). The range parameter is used to normalize the result. For a spectral centroid, the range should be equal to Nyquist and for an audio centroid the range should be equal to (audiosize - 1) / samplerate.
The size of the input array must be at least two elements for &quot;decrease&quot; to be computed, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Least Squares Fitting -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/LeastSquaresFitting.html">http://mathworld.wolfram.com/LeastSquaresFitting.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Derivative<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the derivative of the input signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm returns the first-order derivative of the input signal, ie: for each input value, it returns the value minus the previous one.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DerivativeSFX<br>[standard]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>vector_real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>derAvAfterMax</strong> (<em>real</em>) - the weighted average of the derivative after the maximum amplitude</li>
<li><strong>maxDerBeforeMax</strong> (<em>real</em>) - the maximum derivative before the maximum amplitude</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm returns two descriptors that are based on the derivative of a signal envelope.</p>
<p>The first descriptor is calculated after the maximum value of the input signal occurred. It is the average of the signal's derivative weighted by its amplitude. This coefficient helps discriminating impulsive sounds, which have a steep release phase, from non-impulsive sounds. The smaller the value the more impulsive.</p>
<p>The second descriptor is the maximum derivative, before the maximum value of the input signal occurred. This coefficient helps discriminating sounds that have a smooth attack phase, and therefore a smaller value than sounds with a fast attack.</p>
<p>This algorithm is meant to be fed by the outputs of the Envelope algorithm. If used in streaming mode, RealAccumulator should be connected in between.
An exception is thrown if the input signal is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Dissonance<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks (must be sorted by frequency)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks (must be sorted by frequency</li>
</td><td class="col-xs-2">
<li><strong>dissonance</strong> (<em>real</em>) - the dissonance of the audio signal (0 meaning completely consonant, and 1 meaning completely dissonant)</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the sensory dissonance (to distinguish from musical or theoretical dissonance) of an audio signal given its spectral peaks. Sensory dissonance measures perceptual roughness of the sound and is based on the roughness of its spectral peaks. Given the spectral peaks, the algorithm estimates total dissonance by summing up the normalized dissonance values for each pair of peaks. These values are computed using dissonance curves, which define dissonace between two spectral peaks according to their frequency and amplitude relations. The dissonance curves are based on perceptual experiments conducted in [1].
Exceptions are thrown when the size of the input vectors are not equal or if input frequencies are not ordered ascendantly</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] R. Plomp and W. J. M. Levelt, &quot;Tonal Consonance and Critical
Bandwidth,&quot; The Journal of the Acoustical Society of America, vol. 38,
no. 4, pp. 548–560, 1965.</p>
<p>[2] Critical Band - Handbook for Acoustic Ecology
<a class="reference external" href="http://www.sfu.ca/sonic-studio/handbook/Critical_Band.html">http://www.sfu.ca/sonic-studio/handbook/Critical_Band.html</a></p>
<p class="last">[3] Bark Scale -  Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Bark_scale">http://en.wikipedia.org/wiki/Bark_scale</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DistributionShape<br>[standard]

</th><td class="col-xs-2">
<li><strong>centralMoments</strong> (<em>vector_real</em>) - the central moments of a distribution</li>
</td><td class="col-xs-2">
<li><strong>spread</strong> (<em>real</em>) - the spread (variance) of the distribution</li>
<li><strong>skewness</strong> (<em>real</em>) - the skewness of the distribution</li>
<li><strong>kurtosis</strong> (<em>real</em>) - the kurtosis of the distribution</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the spread (variance), skewness and kurtosis excess of an array of Reals given its central moments (see CentralMoments algorithm). These extracted features are good indicators of the shape of the distribution.
The size of the input array must be at least 5. An exception will be thrown otherwise.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004.</p>
<p>[2] Variance - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Variance">http://en.wikipedia.org/wiki/Variance</a></p>
<p>[3] Skewness - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Skewness">http://en.wikipedia.org/wiki/Skewness</a></p>
<p class="last">[4] Kurtosis - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Kurtosis">http://en.wikipedia.org/wiki/Kurtosis</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Duration<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>duration</strong> (<em>real</em>) - the duration of the signal [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the total length of a signal recording in seconds.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DynamicComplexity<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>dynamicComplexity</strong> (<em>real</em>) - the dynamic complexity coefficient</li>
<li><strong>loudness</strong> (<em>real</em>) - an estimate of the loudness [dB]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>real ∈ (0, ∞), default = 0.2</em>) :</dt>
<dd><p class="first last">the frame size [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The dynamic complexity is the average absolute deviation from the global
loudness level estimate on the dB scale. It is related to the dynamic
range and to the amount of fluctuation in loudness present in a recording.</p>
<p>Silence at the beginning and at the end of a track are ignored in the
computation in order not to deteriorate the results.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] S. Streich, Music complexity: a multi-faceted description of audio
content, UPF, Barcelona, Spain, 2007.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EasyLoader<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>downmix</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the mixing type for stereo files</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>endTime</strong> (<em>real ∈ [0, ∞), default = 1e+06</em>) :</dt>
<dd><p class="first last">the end time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>replayGain</strong> (<em>real ∈ (-∞, ∞), default = -6</em>) :</dt>
<dd><p class="first last">the value of the replayGain that should be used to normalize the signal [dB]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the output sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTime</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file, this algorithm outputs the raw audio data, downmixed to mono. The audio is resampled in case the given sampling rate does not match the sampling rate of the input signal and is normalized by the given replayGain value.</p>
<p>This algorithm uses MonoLoader and therefore inherits all of its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Replay Gain - A Proposed Standard,</dt>
<dd><a class="reference external" href="http://replaygain.hydrogenaudio.org">http://replaygain.hydrogenaudio.org</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EffectiveDuration<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>effectiveDuration</strong> (<em>real</em>) - the effective duration of the signal [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>thresholdRatio</strong> (<em>real ∈ [0, 1], default = 0.4</em>) :</dt>
<dd><p class="first last">the ratio of the envelope maximum to be used as the threshold</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the effective duration of an envelope signal. The effective duration is a measure of the time the signal is perceptually meaningful. This is approximated by the time the envelope is above or equal to a given threshold and is above the -90db noise floor. This measure allows to distinguish percussive sounds from sustained sounds but depends on the signal length.
By default, this algorithm uses 40% of the envelope maximum as the threshold which is suited for short sounds. Note, that the 0% thresold corresponds to the duration of signal above -90db noise floor, while the 100% thresold corresponds to the number of times the envelope takes its maximum value.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Energy<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>energy</strong> (<em>real</em>) - the energy of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the energy of an array of Reals.</p>
<p>The input array should not be empty or an exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EnergyBand<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input frequency spectrum</li>
</td><td class="col-xs-2">
<li><strong>energyBand</strong> (<em>real</em>) - the energy in the frequency band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startCutoffFrequency</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start frequency from which to sum the energy [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>stopCutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the stop frequency to which to sum the energy [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the spectral energy of the given frequency band, including both start and stop cutoff frequencies.
Note that exceptions will be thrown when input spectrum is empty and if startCutoffFrequency is greater than startCutoffFrequency.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EnergyBandRatio<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>energyBandRatio</strong> (<em>real</em>) - the energy ratio of the specified band over the total energy</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startFrequency</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the frequency from which to start summing the energy [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>stopFrequency</strong> (<em>real ∈ [0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the frequency up to which to sum the energy [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the ratio of the spectral energy in the range [startFrequency, stopFrequency] over the total energy.</p>
<p>An exception is thrown when startFrequency is larger than stopFrequency
or the input spectrum is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Entropy<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (cannot contain negative values, and must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>entropy</strong> (<em>real</em>) - the entropy of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the Shannon entropy of an array. Entropy can be used to quantify the peakiness of a distribution. This has been used for voiced/unvoiced decision in automatic speech recognition.</p>
<p>Entropy cannot be computed neither on empty arrays nor arrays which contain negative values. In such cases, exceptions will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] H. Misra, S. Ikbal, H. Bourlard and H. Hermansky, &quot;Spectral entropy
based feature for robust ASR,&quot; in IEEE International Conference on
Acoustics, Speech, and Signal Processing (ICASSP'04).</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Envelope<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the resulting envelope of the signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>applyRectification</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether to apply rectification (envelope based on the absolute value of signal)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>attackTime</strong> (<em>real ∈ [0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the attack time of the first order lowpass in the attack phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>releaseTime</strong> (<em>real ∈ [0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the release time of the first order lowpass in the release phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the envelope of a signal by applying a non-symmetric lowpass filter on a signal. By default it rectifies the signal, but that is optional.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, Digital Audio Signal Processing,
John Wiley &amp; Sons Ltd, 1997, ch.7</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EqloudLoader<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>downmix</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the mixing type for stereo files</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>endTime</strong> (<em>real ∈ [0, ∞), default = 1e+06</em>) :</dt>
<dd><p class="first last">the end time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>replayGain</strong> (<em>real ∈ (-∞, ∞), default = -6</em>) :</dt>
<dd><p class="first last">the value of the replayGain [dB] that should be used to normalize the signal [dB]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ {32000, 44100, 48000}, default = 44100</em>) :</dt>
<dd><p class="first last">the output sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTime</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file this algorithm outputs the raw audio data downmixed to mono. Audio is resampled in case the given sampling rate does not match the sampling rate of the input signal and normalized by the given replayGain gain. In addition, audio data is filtered through an equal-loudness filter.</p>
<p>This algorithm uses MonoLoader and thus inherits all of its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Replay Gain - A Proposed Standard,</dt>
<dd><a class="reference external" href="http://replaygain.hydrogenaudio.org">http://replaygain.hydrogenaudio.org</a>  [2] Replay Gain - Equal Loudness Filter,
<a class="reference external" href="http://replaygain.hydrogenaudio.org/equal_loudness.html">http://replaygain.hydrogenaudio.org/equal_loudness.html</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EqualLoudness<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ {32000, 44100, 48000}, default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements an equal-loudness filter. The human ear does not perceive sounds of all frequencies as having equal loudness, and to account for this, the signal is filtered by an inverted approximation of the equal-loudness curves. Technically, the filter is a cascade of a 10th order Yulewalk filter with a 2nd order Butterworth high pass filter.</p>
<p>This algorithm depends on the IIR algorithm. Any requirements of the IIR algorithm are imposed for this algorithm. This algorithm is only defined for the sampling rates specified in parameters. It will throw an exception if attempting to configure with any other sampling rate.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Replay Gain - Equal Loudness Filter,
<a class="reference external" href="http://replaygain.hydrogenaudio.org/proposal/equal_loudness.html">http://replaygain.hydrogenaudio.org/proposal/equal_loudness.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ERBBands<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energies/magnitudes of each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">an upper-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ (1, ∞), default = 1025</em>) :</dt>
<dd><p class="first last">the size of the spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 50</em>) :</dt>
<dd><p class="first last">a lower-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ (1, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the number of output bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {energy, magnitude}, default = energy</em>) :</dt>
<dd><p class="first last">compute energies or magnitudes</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>width</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">filter width with respect to ERB</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes energies/magnitudes in bands spaced on an Equivalent Rectangular Bandwidth (ERB) scale, given a spectrum. It applies a frequency domain filterbank using gammatone filters. Adapted from matlab code in:  D. P. W. Ellis (2009). 'Gammatone-like spectrograms', web resource [1].</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] <a class="reference external" href="http://www.ee.columbia.edu/~dpwe/resources/matlab/gammatonegram/">http://www.ee.columbia.edu/~dpwe/resources/matlab/gammatonegram/</a></p>
<p class="last">[2] B. C. Moore and B. R. Glasberg, &quot;Suggested formulae for calculating
auditory-filter bandwidths and excitation patterns,&quot; Journal of the
Acoustical Society of America, vol. 74, no. 3, pp. 750–753, 1983.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Extractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>pool</strong> (<em>pool</em>) - the pool where to store the results</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>dynamics</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">compute dynamics' features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>dynamicsFrameSize</strong> (<em>integer ∈ (0, ∞), default = 88200</em>) :</dt>
<dd><p class="first last">the frame size for level dynamics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>dynamicsHopSize</strong> (<em>integer ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the hop size for level dynamics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>highLevel</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">compute high level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowLevel</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">compute low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowLevelFrameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowLevelHopSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>midLevel</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">compute mid level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>namespace</strong> (<em>string, default = &quot;&quot;</em>) :</dt>
<dd><p class="first last">the main namespace under which to store the results</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>relativeIoi</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">compute relative inter onset intervals</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>rhythm</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">compute rhythm features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tonalFrameSize</strong> (<em>integer ∈ (0, ∞), default = 4096</em>) :</dt>
<dd><p class="first last">the frame size for low level tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tonalHopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hop size for low level tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tuning</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">compute tuning frequency</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts all low level, mid level and high level features from an audio signal and stores them in a pool.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FadeDetection<br>[standard]

</th><td class="col-xs-2">
<li><strong>rms</strong> (<em>vector_real</em>) - rms values array</li>
</td><td class="col-xs-2">
<li><strong>fadeIn</strong> (<em>matrix_real</em>) - 2D-array containing start/stop timestamps corresponding to fade-ins [s] (ordered chronologically)</li>
<li><strong>fadeOut</strong> (<em>matrix_real</em>) - 2D-array containing start/stop timestamps corresponding to fade-outs [s] (ordered chronologically)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffHigh</strong> (<em>real ∈ (0, 1], default = 0.85</em>) :</dt>
<dd><p class="first last">fraction of the average RMS to define the maximum threshold</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffLow</strong> (<em>real ∈ [0, 1), default = 0.2</em>) :</dt>
<dd><p class="first last">fraction of the average RMS to define the minimum threshold</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ (0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">the rate of frames used in calculation of the RMS [frames/s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minLength</strong> (<em>real ∈ (0, ∞), default = 3</em>) :</dt>
<dd><p class="first last">the minimum length to consider a fade-in/out [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes two arrays containing the start/stop points of fade-ins and fade-outs detected in an audio file. The main hypothesis for the detection is that an increase or decrease of the RMS over time in an audio file corresponds to a fade-in or fade-out, repectively. Minimum and maximum mean-RMS-thresholds are used to define where fade-in and fade-outs occur.</p>
<p>An exception is thrown if the input &quot;rms&quot; is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Fade (audio engineering) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Fade-in">http://en.wikipedia.org/wiki/Fade-in</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FFT<br>[standard]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the FFT of the input frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the expected size of the input frame. This is purely optional and only targeted at optimizing the creation time of the FFT object</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the positive complex STFT (Short-term Fourier transform) of an array of Reals using the FFT algorithm. The resulting fft has a size of (s/2)+1, where s is the size of the input frame.
At the moment FFT can only be computed on frames which size is even and non zero, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Fast Fourier transform - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Fft">http://en.wikipedia.org/wiki/Fft</a></p>
<p class="last">[2] Fast Fourier Transform -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/FastFourierTransform.html">http://mathworld.wolfram.com/FastFourierTransform.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Flatness<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>flatness</strong> (<em>real</em>) - the flatness (ratio between the geometric and the arithmetic mean of the input array)</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the flatness of an array, which is defined as the ratio between the geometric mean and the arithmetic mean.</p>
<p>Flatness is undefined for empty input and negative values, therefore an exception is thrown in any both cases.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FlatnessDB<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>flatnessDB</strong> (<em>real</em>) - the flatness dB</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the flatness of an array, which is defined as the ratio between the geometric mean and the arithmetic mean, and it converts it to dB scale.</p>
<p>Specifically, it can be used to compute spectral flatness [1,2], which is a measure of how noise-like a sound is, as opposed to being tone-like. The meaning of tonal in this context is in the sense of the amount of peaks or resonant structure in a power spectrum, as opposed to flat spectrum of a white noise. A high spectral flatness (approaching 1.0 for white noise) indicates that the spectrum has a similar amount of power in all spectral bands — this would sound similar to white noise, and the graph of the spectrum would appear relatively flat and smooth. A low spectral flatness (approaching 0.0 for a pure tone) indicates that the spectral power is concentrated in a relatively small number of bands — this would typically sound like a mixture of sine waves, and the spectrum would appear &quot;spiky&quot;</p>
<p>The size of the input array must be greater than 0. If the input array is empty an exception will be thrown. This algorithm uses the Flatness algorithm and thus inherits its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</p>
<p class="last">[2] Spectral flatness -  Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Spectral_flatness">http://en.wikipedia.org/wiki/Spectral_flatness</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FlatnessSFX<br>[standard]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>vector_real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>flatness</strong> (<em>real</em>) - the flatness coefficient</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the flatness coefficient of a signal envelope.</p>
<p>There are two thresholds defined: a lower one at 20% and an upper one at 95%. The thresholds yield two values: one value which has 20% of the total values underneath, and one value which has 95% of the total values underneath. The flatness coefficient is then calculated as the ratio of these two values. This algorithm is meant to be plugged after Envelope algorithm, however in streaming mode a RealAccumulator algorithm should be connected in between the two.
In the current form the algorithm can't be calculated in streaming mode, since it would violate the streaming mode policy of having low memory consumption.</p>
<p>An exception is thrown if the input envelope is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Flux<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>flux</strong> (<em>real</em>) - the spectral flux of the input spectrum</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>halfRectify</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">half-rectify the differences in each spectrum bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>norm</strong> (<em>string ∈ {L1, L2}, default = L2</em>) :</dt>
<dd><p class="first last">the norm to use for difference computation</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm calculates the spectral flux of a given spectrum. Flux is defined as the L2-norm [1] or L1-norm [2] of the difference between two consecutive frames of the magnitude spectrum. The frames have to be of the same size in order to yield a meaningful result. The default L2-norm is used more commonly.</p>
<p>An exception is thrown if the size of the input spectrum does not equal the previous input spectrum's size.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Tzanetakis, G., Cook, P., &quot;Multifeature Audio Segmentation for
Browsing and Annotation&quot;, Proceedings of the 1999 IEEE Workshop on
Applications of Signal Processing to Audio and Acoustics, New Paltz,
NY, USA, 1999, W99 1-4</p>
<p>[2] S. Dixon, &quot;Onset detection revisited&quot;, in International Conference on
Digital Audio Effects (DAFx'06), 2006, vol. 120, pp. 133-137.</p>
<p class="last">[3] <a class="reference external" href="http://en.wikipedia.org/wiki/Spectral_flux">http://en.wikipedia.org/wiki/Spectral_flux</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FrameCutter<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the buffer from which to read data</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the frame to write to</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the output frame size</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ [1, ∞), default = 512</em>) :</dt>
<dd><p class="first last">the hop size between frames</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lastFrameToEndOfFile</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether the beginning of the last frame should reach the end of file. Only applicable if startFromZero is true</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startFromZero</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether to start the first frame at time 0 if true, or -frameSize/2 otherwise (zero-centered)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>validFrameThresholdRatio</strong> (<em>real ∈ [0, 1], default = 0</em>) :</dt>
<dd><p class="first last">frames smaller than this ratio will be discarded, those larger will be zero-padded to make a full frame (i.e. a value of 0 will never discard frames and a value of 1 will only keep frames that are of length 'frameSize')</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an input buffer this algorithm will return a frame (slice) of constant size every time it is called, and then jump a constant amount of samples in the future.
When no more frames can be extracted from the input buffer, it will return empty frames
If any frame could not be complete, because we start before the beginning of the input buffer or go past its end, the output frame will be zero-padded.</p>
<p>The rationale for deciding which is the last frame is the following: we should return as many frames as needed to consume all the information contained in the buffer, but no more.
This translates into 2 different conditions, depending on whether the algorithm has been configured with startFromZero = true or startFromZero = false:</p>
<blockquote>
<ul class="simple">
<li>startFromZero = true: a frame is the last one, whenever we are at or beyond the end of the stream. The last frame will be zero-padded if its size is less than &quot;frameSize&quot;</li>
<li>startFromZero = false: a frame is the last one if and only if the center of that frame is at or beyond the end of the stream</li>
</ul>
</blockquote>
<p>then it is the last one
In both cases, if the start of a frame is past the end of the buffer, we don't return it and stop processing, meaning that the previous frame that we returned was the last one.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FrameGenerator<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">

</td><td class="col-xs-2">

</td><td class="col-xs-5">

</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FrameToReal<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the output audio samples</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing the overlap-add process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the overlap-add function is computed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm converts a sequence of input audio signal frames into a sequence of audio samples.</p>
<p>Empty input signals will raise an exception.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FrequencyBands<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must be greater than size one)</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy in each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [0, 50, 100, 150, 200, 300, 400, 510, 630, 770, 920, 1080, 1270, 1480, 1720, 2000, 2320, 2700, 3150, 3700, 4400, 5300, 6400, 7700, 9500, 12000, 15500, 20500, 27000]</em>) :</dt>
<dd><p class="first last">list of frequency ranges in to which the spectrum is divided (these must be in ascending order and connot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the energy of an input spectrum for an arbitrary number of non overlapping frequency bands. For each band the power-spectrum (mag-squared) is summed.</p>
<p>Parameter &quot;frequencyBands&quot; must contain at least 2 frequencies, they all must be positive and must be ordered ascentdantly, otherwise an exception will be thrown. FrequencyBands is only defined for spectra, which size is greater than 1.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Frequency Range - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Frequency_band">http://en.wikipedia.org/wiki/Frequency_band</a></p>
<p class="last">[2] Band - Handbook For Acoustic Ecology,
<a class="reference external" href="http://www.sfu.ca/sonic-studio/handbook/Band.html">http://www.sfu.ca/sonic-studio/handbook/Band.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
GaiaTransform<br>[standard]

</th><td class="col-xs-2">
<li><strong>pool</strong> (<em>pool</em>) - aggregated pool of extracted values</li>
</td><td class="col-xs-2">
<li><strong>pool</strong> (<em>pool</em>) - pool resulting from the transformation of the gaia point</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>history</strong> (<em>string</em>) :</dt>
<dd><p class="first last">gaia2 history filename</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Applies a given Gaia2 transformation history to a given pool. It first converts the pool into a gaia2::Point suitable for the history, applies the history, and converts back the resulting point into an essentia Pool. In particular, it allows classification.</p>
<p>Note that in order to enable this algorithm it is necessary to install Gaia2 library before building Essentia.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Gaia - A library for similarity in high-dimensional spaces,
<a class="reference external" href="http://github.com/MTG/gaia">http://github.com/MTG/gaia</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
GeometricMean<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>geometricMean</strong> (<em>real</em>) - the geometric mean of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the geometric mean of an array of positive Reals.</p>
<p>An exception is thrown if the input array does not contain strict positive numbers or the array is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</p>
<p class="last">[2] Geometric Mean -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/GeometricMean.html">http://mathworld.wolfram.com/GeometricMean.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
GFCC<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energies in ERB bands</li>
<li><strong>gfcc</strong> (<em>vector_real</em>) - the gammatone feature cepstrum coefficients</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the upper bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the lower bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ [1, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the number of bands in the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberCoefficients</strong> (<em>integer ∈ [1, ∞), default = 13</em>) :</dt>
<dd><p class="first last">the number of output cepstrum coefficients</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the equivalent of MFCCs but using a gammatone filterbank (ERBBands) scaled on an Equivalent Rectangular Bandwidth (ERB) scale. These coefficients could be called 'Gammatone Feature Cepstral Coefficients.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Y. Shao, Z. Jin, D. Wang, and S. Srinivasan, &quot;An auditory-based feature
for robust speech recognition,&quot; in IEEE International Conference on
Acoustics, Speech, and Signal Processing (ICASSP’09), 2009,
pp. 4625-4628.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HarmonicBpm<br>[standard]

</th><td class="col-xs-2">
<li><strong>bpms</strong> (<em>vector_real</em>) - list of bpm candidates</li>
</td><td class="col-xs-2">
<li><strong>harmonicBpms</strong> (<em>vector_real</em>) - a list of bpms which are harmonically related to the bpm parameter</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bpm</strong> (<em>integer ∈ [1, ∞), default = 60</em>) :</dt>
<dd><p class="first last">the bpm used to find its harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">bpm threshold below which greatest common divisors are discarded</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, ∞), default = 5</em>) :</dt>
<dd><p class="first last">percentage tolerance to consider two bpms are equal or equal to a harmonic</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts bpms that are harmonically related to the tempo given by the 'bpm' parameter.
The algorithm assumes a certain bpm is harmonically related to parameter bpm, when the greatest common divisor between both bpms is greater than threshold.
The 'tolerance' parameter is needed in order to consider if two bpms are related. For instance, 120, 122 and 236 may be related or not depending on how much tolerance is given</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Greatest common divisor - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Greatest_common_divisor">http://en.wikipedia.org/wiki/Greatest_common_divisor</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HarmonicMask<br>[standard]

</th><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the input frame</li>
<li><strong>pitch</strong> (<em>real</em>) - an estimate of the fundamental frequency of the signal [Hz]</li>
</td><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the output frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>attenuation</strong> (<em>real ∈ [-∞, ∞), default = -200</em>) :</dt>
<dd><p class="first last">attenuation in dB's of the muted pitched component. If value is positive the pitched component is attenuated (muted), if the value is negative the pitched component is soloed (i.e. background component is attenuated).</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>binWidth</strong> (<em>integer ∈ [0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">number of bins per harmonic partials applied to the mask. This will depend on the internal FFT size</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm applies a spectral mask to remove a pitched source component from the signal. It computes first an harmonic mask corresponding to the input pitch and applies the mask to the input FFT to remove that pitch. The bin width determines how many spectral bins are masked per harmonic partial.
An attenuation value in dB determines the amount of suppression of the pitched component w.r.t the background for the case of muting. A negative attenuation value allows soloing the pitched component.</p>
<p>References:</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HarmonicPeaks<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz] (ascending order)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks (ascending frequency order)</li>
<li><strong>pitch</strong> (<em>real</em>) - an estimate of the fundamental frequency of the signal [Hz]</li>
</td><td class="col-xs-2">
<li><strong>harmonicFrequencies</strong> (<em>vector_real</em>) - the frequencies of harmonic peaks [Hz]</li>
<li><strong>harmonicMagnitudes</strong> (<em>vector_real</em>) - the magnitudes of harmonic peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the number of harmonics to return including F0</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ (0, 0.5), default = 0.2</em>) :</dt>
<dd><p class="first last">the allowed ratio deviation from ideal harmonics</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm finds the harmonic peaks of a signal given its spectral peaks and its fundamental frequency.
Note:</p>
<blockquote>
<ul class="simple">
<li>&quot;tolerance&quot; parameter defines the allowed fixed deviation from ideal harmonics, being a percentage over the F0. For example: if the F0 is 100Hz you may decide to allow a deviation of 20%, that is a fixed deviation of 20Hz; for the harmonic series it is: [180-220], [280-320], [380-420], etc.</li>
<li>If &quot;pitch&quot; is zero, it means its value is unknown, or the sound is unpitched, and in that case the HarmonicPeaks algorithm returns an empty vector.</li>
<li>The output frequency and magnitude vectors are of size &quot;maxHarmonics&quot;. If a particular harmonic was not found among spectral peaks, its ideal frequency value is output together with 0 magnitude.</li>
</ul>
</blockquote>
<p>This algorithm is intended to receive its &quot;frequencies&quot; and &quot;magnitudes&quot; inputs from the SpectralPeaks algorithm.</p>
<blockquote>
<ul class="simple">
<li>When input vectors differ in size or are empty, an exception is thrown. Input vectors must be ordered by ascending frequency excluding DC components and not contain duplicates, otherwise an exception is thrown.</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Harmonic Spectrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Harmonic_spectrum">http://en.wikipedia.org/wiki/Harmonic_spectrum</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HFC<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>hfc</strong> (<em>real</em>) - the high-frequency coefficient</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞], default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {Masri, Jensen, Brossier}, default = Masri</em>) :</dt>
<dd><p class="first last">the type of HFC coefficient to be computed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the High Frequency Content of a signal spectrum.
It can be computed according to the following techniques:</p>
<blockquote>
<ul class="simple">
<li>'Masri' (default) which does: sum |X(n)|^2*k,</li>
<li>'Jensen' which does: sum |X(n)|*k^2</li>
<li>'Brossier' which does: sum |X(n)|*k</li>
</ul>
</blockquote>
<p>Exception is thrown for empty input spectra.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] P. Masri and A. Bateman, “Improved modelling of attack transients in
music analysis-resynthesis,” in Proceedings of the International
Computer Music Conference, 1996, pp. 100–103.</p>
<p>[2] K. Jensen and T. H. Andersen, “Beat estimation on the beat,” in
Applications of Signal Processing to Audio and Acoustics, 2003 IEEE
Workshop on., 2003, pp. 87–90.</p>
<p class="last">[3] High frequency content measure - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/High_Frequency_Content_measure">http://en.wikipedia.org/wiki/High_Frequency_Content_measure</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HighPass<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 1st order IIR high-pass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, p. 40,
John Wiley &amp; Sons, 2002</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HighResolutionFeatures<br>[standard]

</th><td class="col-xs-2">
<li><strong>hpcp</strong> (<em>vector_real</em>) - the HPCPs, preferably of size &gt;= 120</li>
</td><td class="col-xs-2">
<li><strong>equalTemperedDeviation</strong> (<em>real</em>) - measure of the deviation of HPCP local maxima with respect to equal-tempered bins</li>
<li><strong>nonTemperedEnergyRatio</strong> (<em>real</em>) - ratio between the energy on non-tempered bins and the total energy</li>
<li><strong>nonTemperedPeaksEnergyRatio</strong> (<em>real</em>) - ratio between the energy on non-tempered peaks and the total energy</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxPeaks</strong> (<em>integer ∈ [1, ∞), default = 24</em>) :</dt>
<dd><p class="first last">maximum number of HPCP peaks to consider when calculating outputs</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes high-resolution chroma features from an HPCP vector. The vector's size must be a multiple of 12 and it is recommended that it be larger than 120. In otherwords, the HPCP's resolution should be 10 Cents or more.
The high-resolution features being computed are:</p>
<blockquote>
<ul class="simple">
<li>Equal-temperament deviation: a measure of the deviation of HPCP local maxima with respect to equal-tempered bins. This is done by:
a) Computing local maxima of HPCP vector
b) Computing the deviations from equal-tempered (abs) bins and their average</li>
<li>Non-tempered energy ratio: the ratio betwen the energy on non-tempered bins and the total energy, computed from the HPCP average</li>
<li>Non-tempered peak energy ratio: the ratio betwen the energy on non tempered peaks and the total energy, computed from the HPCP average</li>
</ul>
</blockquote>
<p>HighFrequencyFeatures is intended to be used in conjunction with HPCP algorithm. Any input vector which size is not a positive multiple of 12, will raise an exception.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez and P. Herrera, &quot;Comparative Analysis of Music Recordings
from Western and Non-Western traditions by Automatic Tonal Feature
Extraction,&quot; Empirical Musicology Review, vol. 3, pp. 140–156, 2008.</p>
<p class="last">[2] <a class="reference external" href="https://en.wikipedia.org/wiki/Equal_temperament">https://en.wikipedia.org/wiki/Equal_temperament</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HPCP<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><strong>hpcp</strong> (<em>vector_real</em>) - the resulting harmonic pitch class profile</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandPreset</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">enables whether to use a band preset</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonics</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">number of harmonics for frequency contribution, 0 indicates exclusive fundamental frequency contribution</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">the maximum frequency that contributes to the HPCP [Hz] (the difference between the max and split frequencies must not be less than 200.0 Hz)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxShifted</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether to shift the HPCP vector so that the maximum peak is at index 0</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the minimum frequency that contributes to the HPCP [Hz] (the difference between the min and split frequencies must not be less than 200.0 Hz)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>nonLinear</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">enables whether to apply a Jordi non-linear post-processing function to the output</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>normalized</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether to normalize the HPCP vector</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 440</em>) :</dt>
<dd><p class="first last">the reference frequency for semitone index calculation, corresponding to A3 [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [12, ∞), default = 12</em>) :</dt>
<dd><p class="first last">the size of the output HPCP (must be a positive nonzero multiple of 12)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>splitFrequency</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the split frequency for low and high bands, not used if bandPreset is false [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>weightType</strong> (<em>string ∈ {none, cosine, squaredCosine}, default = squaredCosine</em>) :</dt>
<dd><p class="first last">type of weighting function for determining frequency contribution</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>windowSize</strong> (<em>real ∈ (0, 12], default = 1</em>) :</dt>
<dd><p class="first last">the size, in semitones, of the window used for the weighting</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Computes a Harmonic Pitch Class Profile (HPCP), that is a k*12 dimensional vector which represents the intensities of the twelve (k==1) semitone pitch classes (corresponsing to notes from A to G#), or subdivisions of these (k&gt;1). It does this from the spectral peaks of a signal.
Regarding frequency parameters, exceptions are thrown if &quot;minFrequency&quot;, &quot;splitFrequency&quot; and &quot;maxFrequency&quot; are not separated by at least 200Hz from each other, requiring that &quot;maxFrequency&quot; be greater than &quot;splitFrequency&quot; and &quot;splitFrequency&quot; be greater than &quot;minFrequenc&quot;.Other exceptions are thrown if input vectors have different size, if parameter &quot;size&quot; is not a positive non-zero multiple of 12 or if &quot;windowSize&quot; is less than one hpcp bin (12/size).</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] T. Fujishima, &quot;Realtime Chord Recognition of Musical Sound: A System
Using Common Lisp Music,&quot; in International Computer Music Conference
(ICMC'99), pp. 464-467, 1999.
[2] E. Gómez, &quot;Tonal Description of Polyphonic Audio for Music Content
Processing,&quot; INFORMS Journal on Computing, vol. 18, no. 3, pp. 294–304,
2006.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
IFFT<br>[standard]

</th><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the input frame</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the IFFT of the input frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the expected size of the input frame. This is purely optional and only targeted at optimizing the creation time of the FFT object</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm calculates the inverse STFT (Short-term Fourier transform) of an array of complex values using the FFT algorithm. The resulting frame has a size of (s-1)*2, where s is the size of the input fft frame. The inverse Fourier transform is not defined for frames which size is less than 2 samples. Otherwise an exception is thrown.</p>
<p>An exception is thrown if the input's size is not larger than 1.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Fast Fourier transform - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Fft">http://en.wikipedia.org/wiki/Fft</a></p>
<p class="last">[2] Fast Fourier Transform -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/FastFourierTransform.html">http://mathworld.wolfram.com/FastFourierTransform.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
IIR<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>denominator</strong> (<em>vector_real, default = [1]</em>) :</dt>
<dd><p class="first last">the list of coefficients of the denominator. Often referred to as the A coefficient vector.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numerator</strong> (<em>vector_real, default = [1]</em>) :</dt>
<dd><p class="first last">the list of coefficients of the numerator. Often referred to as the B coefficient vector.</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a standard IIR filter. It filters the data in the input vector with the filter described by parameter vectors 'numerator' and 'denominator' to create the output filtered vector. In the litterature, the numerator is often referred to as the 'B' coefficients and the denominator as the 'A' coefficients.</p>
<dl class="docutils">
<dt>The filter is a Direct Form II Transposed implementation of the standard difference equation:</dt>
<dd>a(0)*y(n) = b(0)*x(n) + b(1)*x(n-1) + ... + b(nb-1)*x(n-nb+1) - a(1)*y(n-1) - ... - a(nb-1)*y(n-na+1)</dd>
</dl>
<p>This algorithm maintains a state which is the state of the delays. One should call the reset() method to reinitialize the state to all zeros.</p>
<p>An exception is thrown if the &quot;numerator&quot; or &quot;denominator&quot; parameters are empty. An exception is also thrown if the first coefficient of the &quot;denominator&quot; parameter is 0.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Smith, J.O.  Introduction to Digital Filters with Audio Applications,
<a class="reference external" href="http://ccrma-www.stanford.edu/~jos/filters/">http://ccrma-www.stanford.edu/~jos/filters/</a></p>
<p class="last">[2] Infinite Impulse Response - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/IIR">http://en.wikipedia.org/wiki/IIR</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Inharmonicity<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the harmonic peaks [Hz] (in ascending order)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the harmonic peaks (in frequency ascending order</li>
</td><td class="col-xs-2">
<li><strong>inharmonicity</strong> (<em>real</em>) - the inharmonicity of the audio signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the inharmonicity of a signal given its spectral peaks. The inharmonicity value is computed as an energy weighted divergence of the spectral components from their closest multiple of the fundamental frequency. The fundamental frequency is taken as the first spectral peak from the input. The inharmonicity value ranges from 0 (purely harmonic signal) to 1 (inharmonic signal).</p>
<p>Inharmonicity was designed to be fed by the output from the HarmonicPeaks algorithm. Note that DC components should be removed from the signal before obtaining its peaks. An exception is thrown if a peak is given at 0Hz.</p>
<p>An exception is thrown if frequency vector is not sorted in ascendently, if it contains duplicates or if any input vector is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004.</p>
<p class="last">[2] Inharmonicity - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Inharmonicity">http://en.wikipedia.org/wiki/Inharmonicity</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
InstantPower<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>power</strong> (<em>real</em>) - the instant power of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the instant power of an array. That is, the energy of the array over its size.</p>
<p>An exception is thrown when input array is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Intensity<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>intensity</strong> (<em>integer</em>) - the intensity value</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the input audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm classifies the input audio signal as either relaxed (-1), moderate (0), or aggressive (1).</p>
<p>Quality: outdated (non-reliable, poor accuracy).</p>
<p>An exception is thrown if empty input is provided because the &quot;intensity&quot; is not defined for that case.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Key<br>[standard]

</th><td class="col-xs-2">
<li><strong>pcp</strong> (<em>vector_real</em>) - the input pitch class profile</li>
</td><td class="col-xs-2">
<li><strong>key</strong> (<em>string</em>) - the estimated key, from A to G</li>
<li><strong>scale</strong> (<em>string</em>) - the scale of the key (major or minor)</li>
<li><strong>strength</strong> (<em>real</em>) - the strength of the estimated key</li>
<li><strong>firstToSecondRelativeStrength</strong> (<em>real</em>) - the relative strength difference between the best estimate and second best estimate of the key</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>numHarmonics</strong> (<em>integer ∈ [1, ∞), default = 4</em>) :</dt>
<dd><p class="first last">number of harmonics that should contribute to the polyphonic profile (1 only considers the fundamental harmonic)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pcpSize</strong> (<em>integer ∈ [12, ∞), default = 36</em>) :</dt>
<dd><p class="first last">number of array elements used to represent a semitone times 12 (this parameter is only a hint, during computation, the size of the input PCP is used instead)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>profileType</strong> (<em>string ∈ {diatonic, krumhansl, temperley, weichai, tonictriad, temperley2005, thpcp, shaath, gomez, noland, faraldo, pentatonic, edmm, edma}, default = temperley</em>) :</dt>
<dd><p class="first last">the type of polyphic profile to use for correlation calculation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>slope</strong> (<em>real ∈ [0, ∞), default = 0.6</em>) :</dt>
<dd><p class="first last">value of the slope of the exponential harmonic contribution to the polyphonic profile</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>usePolyphony</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">enables the use of polyphonic profiles to define key profiles (this includes the contributions from triads as well as pitch harmonics)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useThreeChords</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">consider only the 3 main triad chords of the key (T, D, SD) to build the polyphonic profiles</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Using pitch profile classes, this algorithm calculates the best matching key estimate for a given HPCP. The algorithm was severely adapted and changed from the original implementation for readability and speed.</p>
<p>Key will throw exceptions either when the input pcp size is not a positive multiple of 12 or if the key could not be found. Also if parameter &quot;scale&quot; is set to &quot;minor&quot; and the profile type is set to &quot;weichai&quot;</p>
<blockquote>
<p>Abouth the Key Profiles:</p>
<ul class="simple">
<li>'Diatonic' - binary profile with diatonic notes of both modes. Could be useful for ambient music or diatonic music which is not strictly 'tonal functional'.</li>
<li>'Tonic Triad' - just the notes of the major and minor chords. Exclusively for testing.</li>
<li>'Krumhansl' - reference key profiles after cognitive experiments with users. They should work generally fine for pop music.</li>
<li>'Temperley' - key profiles extracted from corpus analysis of euroclassical music. Therefore, they perform best on this repertoire (especially in minor).</li>
<li>'Shaath' -  profiles based on Krumhansl's specifically tuned to popular and electronic music.</li>
<li>'Noland' - profiles from Bach's 'Well Tempered Klavier'.</li>
<li>'edma' - automatic profiles extracted from corpus analysis of electronic dance music [3]. They normally perform better that Shaath's</li>
<li>'edmm' - automatic profiles extracted from corpus analysis of electronic dance music and manually tweaked according to heuristic observation. It will report major modes (which are poorly represented in EDM) as minor, but improve performance otherwise [3].</li>
<li>Other key profiles ('Faraldo', 'Pentatonic') are experimental and will be removed on due time.</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez, &quot;Tonal Description of Polyphonic Audio for Music Content
Processing,&quot; INFORMS Journal on Computing, vol. 18, no. 3, pp. 294–304,
2006.</p>
<p class="last">[2] D. Temperley, &quot;What's key for key? The Krumhansl-Schmuckler
key-finding algorithm reconsidered&quot;, Music Perception vol. 17, no. 1,
pp. 65-100, 1999.  [3] Á. Faraldo, E. Gómez, S. Jordà, P.Herrera, &quot;Key Estimation in Electronic
Dance Music. Proceedings of the 38th International Conference on information
Retrieval, Padova, 2016. (In Press.)</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
KeyExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>key</strong> (<em>string</em>) - See Key algorithm documentation</li>
<li><strong>scale</strong> (<em>string</em>) - See Key algorithm documentation</li>
<li><strong>strength</strong> (<em>real</em>) - See Key algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 4096</em>) :</dt>
<dd><p class="first last">the framesize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hopsize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tuningFrequency</strong> (<em>real ∈ (0, ∞), default = 440</em>) :</dt>
<dd><p class="first last">the tuning frequency of the input signal</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts tonal features</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Larm<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>larm</strong> (<em>real</em>) - the LARM loudness estimate [dB]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>attackTime</strong> (<em>real ∈ [0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the attack time of the first order lowpass in the attack phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>power</strong> (<em>real ∈ (-∞, ∞), default = 1.5</em>) :</dt>
<dd><p class="first last">the power used for averaging</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>releaseTime</strong> (<em>real ∈ [0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the release time of the first order lowpass in the release phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the long-term loudness of an audio signal. The LARM model is based on the asymmetrical low-pass filtering of the Peak Program Meter (PPM), combined with Revised Low-frequency B-weighting (RLB) and power mean calculations. LARM has shown to be a reliable and objective loudness estimate of music and speech.</p>
<p>It accepts a power parameter to define the exponential for computing the power mean. Note that if the parameter's value is 2, this algorithm would be equivalent to RMS and if 1, this algorithm would be the mean of the absolute value.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Skovenborg and S. H. Nielsen, &quot;Evaluation of different loudness
models with music and speech material,” in The 117th AES Convention, 2004.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Leq<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal (must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>leq</strong> (<em>real</em>) - the equivalent sound level estimate</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the Equivalent sound level (Leq) of an audio signal. The Leq measure can be derived from the Revised Low-frequency B-weighting (RLB) or from the raw signal as described in [1]. If the signal contains no energy, Leq defaults to essentias definition of silence which is -90dB.
This algorithm will throw an exception on empty input.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. A. Soulodre, &quot;Evaluation of Objective Loudness Meters,&quot; in
The 116th AES Convention, 2004.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LevelExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>vector_real</em>) - the loudness values</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 88200</em>) :</dt>
<dd><p class="first last">frame size to compute loudness</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">hop size to compute loudness</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts the loudness of an audio signal</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LogAttackTime<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal envelope (must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>logAttackTime</strong> (<em>real</em>) - the log (base 10) of the attack time [log10(s)]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startAttackThreshold</strong> (<em>real ∈ [0, 1], default = 0.2</em>) :</dt>
<dd><p class="first last">the percentage of the input signal envelope at which the starting point of the attack is considered</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>stopAttackThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">the percentage of the input signal envelope at which the ending point of the attack is considered</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the log (base 10) of the attack time of a signal envelope. The attack time is defined as the time duration from when the sound becomes perceptually audible to when it reaches its maximum intensity. By default, the start of the attack is estimated as the point where the signal envelope reaches 20% of its maximum value in order to account for possible noise presence. Also by default, the end of the attack is estimated as as the point where the signal envelope has reached 90% of its maximum value, in order to account for the possibility that the max value occurres after the logAttack, as in trumpet sounds.</p>
<p>With this said, LogAttackTime's input is intended to be fed by the output of the Envelope algorithm. In streaming mode, the RealAccumulator algorithm should be connected between Envelope and LogAttackTime.</p>
<p>Note that startAttackThreshold cannot be greater than stopAttackThreshold and the input signal should not be empty. In any of these cases an exception will be thrown.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Loudness<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the loudness of the input signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the loudness of a signal, which is defined by Steven's power law as its energy raised to the power of 0.67.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Energy (signal processing) - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</p>
<p>[2] Stevens' power law - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Stevens%27_power_law">http://en.wikipedia.org/wiki/Stevens%27_power_law</a></p>
<p class="last">[3] S. S. Stevens, Psychophysics. Transaction Publishers, 1975.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LoudnessEBUR128<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_stereosample</em>) - the input stereo audio signal</li>
</td><td class="col-xs-2">
<li><strong>momentaryLoudness</strong> (<em>vector_real</em>) - momentary loudness (over 400ms) (LUFS)</li>
<li><strong>shortTermLoudness</strong> (<em>vector_real</em>) - short-term loudness (over 3 seconds) (LUFS)</li>
<li><strong>integratedLoudness</strong> (<em>real</em>) - integrated loudness (overall) (LUFS)</li>
<li><strong>loudnessRange</strong> (<em>real</em>) - loudness range over an arbitrary long time interval [3] (dB, LU)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>real ∈ (0, 0.1], default = 0.1</em>) :</dt>
<dd><p class="first last">the hop size with which the loudness is computed [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes loudness descriptors in accordance with EBU R128 recommendation.
- The input stereo signal is preprocessed with a K-weighting filter [2] (see LoudnessEBUR128Filter algorithm), composed of two stages: a shelving filter and a high-pass filter (RLB-weighting curve).
- Momentary loudness is computed by integrating the sum of powers over a sliding rectangular window of 400 ms. The measurement is not gated.
- Short-term loudness is computed by integrating the sum of powers over a sliding rectangular window of 3 seconds. The measurement is not gated.
- Integrated loudness is a loudness value averaged over an arbitrary long time interval with gating of 400 ms blocks with two thresholds [2].</p>
<blockquote>
<ul class="simple">
<li>Absolute 'silence' gating threshold at -70 LUFS for the computation of the absolute-gated loudness level.</li>
<li>Relative gating threshold, 10 LU below the absolute-gated loudness level.</li>
</ul>
</blockquote>
<ul class="simple">
<li>Loudness range is computed from short-term loudness values. It is defined as the difference between the estimates of the 10th and 95th percentiles of the distribution of the loudness values with applied gating [3].<ul>
<li>Absolute 'silence' gating threshold at -70 LUFS for the computation of the absolute-gated loudness level.</li>
<li>Relative gating threshold, -20 LU below the absolute-gated loudness level.</li>
</ul>
</li>
</ul>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] EBU Tech 3341-2011. &quot;Loudness Metering: 'EBU Mode' metering to supplement
loudness normalisation in accordance with EBU R 128&quot;
[2] ITU-R BS.1770-2. &quot;Algorithms to measure audio programme loudness and true-peak audio level
[3] EBU Tech Doc 3342-2011. &quot;Loudness Range: A measure to supplement loudness
normalisation in accordance with EBU R 128&quot;
[4] <a class="reference external" href="http://tech.ebu.ch/loudness">http://tech.ebu.ch/loudness</a>
[5] <a class="reference external" href="http://en.wikipedia.org/wiki/LKFS">http://en.wikipedia.org/wiki/LKFS</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LoudnessVickers<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the Vickers loudness [dB]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ [44100, 44100], default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate of the input signal which is used to create the weight vector [Hz] (currently, this algorithm only works on signals with a sampling rate of 44100Hz)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes Vickers's loudness for a given audio signal. Currently, this algorithm only works for signals with a 44100Hz sampling rate. This algorithm is meant to be given frames of audio as input (not entire audio signals). The algorithm described in the paper performs a weighted average of the loudness value computed for each of the given frames, this step is left as a post processing step and is not performed by this algorithm.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Vickers, &quot;Automatic Long-term Loudness and Dynamics Matching,&quot; in
The 111th AES Convention, 2001.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LowLevelSpectralEqloudExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>dissonance</strong> (<em>vector_real</em>) - See Dissonance algorithm documentation</li>
<li><strong>sccoeffs</strong> (<em>vector_vector_real</em>) - See SpectralContrast algorithm documentation</li>
<li><strong>scvalleys</strong> (<em>vector_vector_real</em>) - See SpectralContrast algorithm documentation</li>
<li><strong>spectral_centroid</strong> (<em>vector_real</em>) - See Centroid algorithm documentation</li>
<li><strong>spectral_kurtosis</strong> (<em>vector_real</em>) - See DistributionShape algorithm documentation</li>
<li><strong>spectral_skewness</strong> (<em>vector_real</em>) - See DistributionShape algorithm documentation</li>
<li><strong>spectral_spread</strong> (<em>vector_real</em>) - See DistributionShape algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts a set of level spectral features for which it is recommended to apply a preliminary equal-loudness filter over an input audio signal (according to the internal evaluations conducted at Music Technology Group). To this end, you are expected to provide the output of EqualLoudness algorithm as an input for this algorithm. Still, you are free to provide an unprocessed audio input in the case you want to compute these features without equal-loudness filter.</p>
<p>Note that at present we do not dispose any reference to justify the necessity of equal-loudness filter. Our recommendation is grounded on internal evaluations conducted at Music Technology Group that have shown the increase in numeric robustness as a function of the audio encoders used (mp3, ogg, ...) for these features.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LowLevelSpectralExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>barkbands</strong> (<em>vector_vector_real</em>) - spectral energy at each bark band. See BarkBands alogithm</li>
<li><strong>barkbands_kurtosis</strong> (<em>vector_real</em>) - kurtosis from bark bands. See DistributionShape algorithm documentation</li>
<li><strong>barkbands_skewness</strong> (<em>vector_real</em>) - skewness from bark bands. See DistributionShape algorithm documentation</li>
<li><strong>barkbands_spread</strong> (<em>vector_real</em>) - spread from barkbands. See DistributionShape algorithm documentation</li>
<li><strong>hfc</strong> (<em>vector_real</em>) - See HFC algorithm documentation</li>
<li><strong>mfcc</strong> (<em>vector_vector_real</em>) - See MFCC algorithm documentation</li>
<li><strong>pitch</strong> (<em>vector_real</em>) - See PitchYinFFT algorithm documentation</li>
<li><strong>pitch_instantaneous_confidence</strong> (<em>vector_real</em>) - See PitchYinFFT algorithm documentation</li>
<li><strong>pitch_salience</strong> (<em>vector_real</em>) - See PitchSalience algorithm documentation</li>
<li><strong>silence_rate_20dB</strong> (<em>vector_real</em>) - See SilenceRate algorithm documentation</li>
<li><strong>silence_rate_30dB</strong> (<em>vector_real</em>) - See SilenceRate algorithm documentation</li>
<li><strong>silence_rate_60dB</strong> (<em>vector_real</em>) - See SilenceRate algorithm documentation</li>
<li><strong>spectral_complexity</strong> (<em>vector_real</em>) - See Spectral algorithm documentation</li>
<li><strong>spectral_crest</strong> (<em>vector_real</em>) - See Crest algorithm documentation</li>
<li><strong>spectral_decrease</strong> (<em>vector_real</em>) - See Decrease algorithm documentation</li>
<li><strong>spectral_energy</strong> (<em>vector_real</em>) - See Energy algorithm documentation</li>
<li><strong>spectral_energyband_low</strong> (<em>vector_real</em>) - Energy in band (20,150] Hz. See EnergyBand algorithm documentation</li>
<li><strong>spectral_energyband_middle_low</strong> (<em>vector_real</em>) - Energy in band (150,800] Hz.See EnergyBand algorithm documentation</li>
<li><strong>spectral_energyband_middle_high</strong> (<em>vector_real</em>) - Energy in band (800,4000] Hz. See EnergyBand algorithm documentation</li>
<li><strong>spectral_energyband_high</strong> (<em>vector_real</em>) - Energy in band (4000,20000] Hz. See EnergyBand algorithm documentation</li>
<li><strong>spectral_flatness_db</strong> (<em>vector_real</em>) - See flatnessDB algorithm documentation</li>
<li><strong>spectral_flux</strong> (<em>vector_real</em>) - See Flux algorithm documentation</li>
<li><strong>spectral_rms</strong> (<em>vector_real</em>) - See RMS algorithm documentation</li>
<li><strong>spectral_rolloff</strong> (<em>vector_real</em>) - See RollOff algorithm documentation</li>
<li><strong>spectral_strongpeak</strong> (<em>vector_real</em>) - See StrongPeak algorithm documentation</li>
<li><strong>zerocrossingrate</strong> (<em>vector_real</em>) - See ZeroCrossingRate algorithm documentation</li>
<li><strong>inharmonicity</strong> (<em>vector_real</em>) - See Inharmonicity algorithm documentation</li>
<li><strong>tristimulus</strong> (<em>vector_vector_real</em>) - See Tristimulus algorithm documentation</li>
<li><strong>oddtoevenharmonicenergyratio</strong> (<em>vector_real</em>) - See OddToEvenHarmonicEnergyRatio algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts all low level spectral features from an audio signal</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LowPass<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 1st order IIR low-pass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, p. 40,
John Wiley &amp; Sons, 2002</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LPC<br>[standard]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>lpc</strong> (<em>vector_real</em>) - the LPC coefficients</li>
<li><strong>reflection</strong> (<em>vector_real</em>) - the reflection coefficients</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>order</strong> (<em>integer ∈ [2, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the order of the LPC analysis (typically [8,14])</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {regular, warped}, default = regular</em>) :</dt>
<dd><p class="first last">the type of LPC (regular or warped)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the Linear Predictive Coefficients of a signal and the associated Reflection coefficients.</p>
<p>An exception is thrown if the &quot;order&quot; provided is larger than the size of the input signal.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Linear predictive coding - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Linear_predictive_coding">http://en.wikipedia.org/wiki/Linear_predictive_coding</a></p>
<p class="last">[2] J. Makhoul, &quot;Spectral analysis of speech by linear prediction,&quot; IEEE
Transactions on Audio and Electroacoustics, vol. 21, no. 3, pp. 140–148,
1973.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Magnitude<br>[standard]

</th><td class="col-xs-2">
<li><strong>complex</strong> (<em>vector_complex</em>) - the input vector of complex numbers</li>
</td><td class="col-xs-2">
<li><strong>magnitude</strong> (<em>vector_real</em>) - the magnitudes of the input vector</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the absolute value of each element in a vector of complex numbers.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Complex Modulus -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/ComplexModulus.html">http://mathworld.wolfram.com/ComplexModulus.html</a></p>
<p class="last">[2] Complex number - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Complex_numbers#Absolute_value.2C_conjugation_and_distance">http://en.wikipedia.org/wiki/Complex_numbers#Absolute_value.2C_conjugation_and_distance</a>.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MaxFilter<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - signal to be filtered</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - filtered output</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>causal</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">use casual filter (window is behind current element otherwise it is centered around)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>width</strong> (<em>integer ∈ [2, ∞), default = 3</em>) :</dt>
<dd><p class="first last">the window size, has to be odd if the window is centered</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Maximum filter for 1d signal (van Herk/Gil-Werman Algorithm).</p>
<dl class="docutils">
<dt>References:</dt>
<dd>TODO</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MaxMagFreq<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must have more than 1 element)</li>
</td><td class="col-xs-2">
<li><strong>maxMagFreq</strong> (<em>real</em>) - the frequency with the largest magnitude [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the frequency with the largest magnitude.
Note that a spectrum must contain at least two elements otherwise an exception is thrown</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MaxToTotal<br>[standard]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>vector_real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>maxToTotal</strong> (<em>real</em>) - the maximum amplitude position to total length ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the ratio between the index of the maximum value of the envelope of a signal and the total length of the envelope. This ratio shows how much the maximum amplitude is off-center. Its value is close to 0 if the maximum is close to the beginning (e.g. Decrescendo or Impulsive sounds), close to 0.5 if it is close to the middle (e.g. Delta sounds) and close to 1 if it is close to the end of the sound (e.g. Crescendo sounds). This algorithm is intended to be fed by the output of the Envelope algorithm</p>
<p>MaxToTotal will throw an exception if the input envelope is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Mean<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>mean</strong> (<em>real</em>) - the mean of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the mean of an array of Reals.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Median<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>median</strong> (<em>real</em>) - the median of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the median of an array of Reals. When there is an odd number of numbers, the median is simply the middle number. For example, the median of 2, 4, and 7 is 4. When there is an even number of numbers, the median is the mean of the two middle numbers. Thus, the median of the numbers 2, 4, 7, 12 is (4+7)/2 = 5.5. See [1] for more info.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Statistical Median -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/StatisticalMedian.html">http://mathworld.wolfram.com/StatisticalMedian.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MelBands<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy in mel bands</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">an upper-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ (1, ∞), default = 1025</em>) :</dt>
<dd><p class="first last">the size of the spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">a lower-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ (1, ∞), default = 24</em>) :</dt>
<dd><p class="first last">the number of output bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sample rate</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the energy in mel bands for a given spectrum. It applies a frequency-domain filterbank (MFCC FB-40, [1]), which consists of equal area triangular filters spaced according to the mel scale. The filterbank is normalized in such a way that the sum of coefficients for every filter equals one. It is recommended that the input &quot;spectrum&quot; be calculated by the Spectrum algorithm.</p>
<p>It is required that parameter &quot;highMelFrequencyBound&quot; not be larger than the Nyquist frequency, but must be larger than the parameter, &quot;lowMelFrequencyBound&quot;. Also, The input spectrum must contain at least two elements. If any of these requirements are violated, an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] T. Ganchev, N. Fakotakis, and G. Kokkinakis, &quot;Comparative evaluation
of various MFCC implementations on the speaker verification task,&quot; in
International Conference on Speach and Computer (SPECOM’05), 2005,
vol. 1, pp. 191–194.</p>
<p class="last">[2] Mel-frequency cepstrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient">http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MetadataReader<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>title</strong> (<em>string</em>) - the title of the track</li>
<li><strong>artist</strong> (<em>string</em>) - the artist of the track</li>
<li><strong>album</strong> (<em>string</em>) - the album on which this track appears</li>
<li><strong>comment</strong> (<em>string</em>) - the comment field stored in the tags</li>
<li><strong>genre</strong> (<em>string</em>) - the genre as stored in the tags</li>
<li><strong>tracknumber</strong> (<em>string</em>) - the track number</li>
<li><strong>date</strong> (<em>string</em>) - the date of publication</li>
<li><strong>tagPool</strong> (<em>pool</em>) - the pool with all tags that were found</li>
<li><strong>duration</strong> (<em>integer</em>) - the duration of the track, in seconds</li>
<li><strong>bitrate</strong> (<em>integer</em>) - the bitrate of the track [kb/s]</li>
<li><strong>sampleRate</strong> (<em>integer</em>) - the sample rate [Hz]</li>
<li><strong>channels</strong> (<em>integer</em>) - the number of channels</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>failOnError</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">if true, the algorithm throws an exception when encountering an error (e.g. trying to open an unsupported file format), otherwise the algorithm leaves all fields blank</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read the tags</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterMetadata</strong> (<em>bool, default = false</em>) :</dt>
<dd><p class="first last">if true, only add tags from filterMetadataTags to the pool</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterMetadataTags</strong> (<em>vector_string, default = []</em>) :</dt>
<dd><p class="first last">the list of tags to whitelist (original taglib names)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tagPoolName</strong> (<em>string, default = metadata.tags</em>) :</dt>
<dd><p class="first last">common prefix for tag descriptor names to use in tagPool</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs the metadata tags associated with audio files, as well as their audio properties (e.g. bitrate, length, etc.). Supported audio file types are:</p>
<blockquote>
<ul class="simple">
<li>mp3</li>
<li>flac</li>
<li>ogg</li>
</ul>
</blockquote>
<p>An exception is thrown if unsupported filetype is given or if the file does not exist.
Please observe that the .wav format is not supported. Also note that this algorithm incorrectly calculates the number of channels for a file in mp3 format only for versions less than 1.5 of taglib in Linux and less or equal to 1.5 in Mac OS X
If using this algorithm on Windows, you must ensure that the filename is encoded as UTF-8.
This algorithm also contains some heuristic to try to deal with encoding errors in the tags and tries to do the appropriate conversion if a problem was found (mostly twice latin1-&gt;utf8 conversion).</p>
<p>MetadataReader reads all metadata tags found in audio and stores them in the pool tagPool. Standard metadata tags found in audio files include strings mentioned in [1,2]. Tag strings are case-sensitive and they are converted to lower-case when stored to the pool. It is possible to filter these tags by using 'filterMetadataTags' parameter. This parameter should specify a white-list of tag strings as they are found in the audio file (e.g., &quot;ARTIST&quot;).</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] <a class="reference external" href="https://taglib.github.io/api/classTagLib_1_1PropertyMap.html#details">https://taglib.github.io/api/classTagLib_1_1PropertyMap.html#details</a></p>
<p class="last">[2] <a class="reference external" href="https://picard.musicbrainz.org/docs/mappings/">https://picard.musicbrainz.org/docs/mappings/</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Meter<br>[standard]

</th><td class="col-xs-2">
<li><strong>beatogram</strong> (<em>vector_vector_real</em>) - filtered matrix loudness</li>
</td><td class="col-xs-2">
<li><strong>meter</strong> (<em>real</em>) - the time signature</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm estimates the time signature of a given beatogram by finding the highest correlation between beats.</p>
<p>Quality: experimental (not evaluated, do not use)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MFCC<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energies in mel bands</li>
<li><strong>mfcc</strong> (<em>vector_real</em>) - the mel frequency cepstrum coefficients</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ (0, ∞), default = 11000</em>) :</dt>
<dd><p class="first last">the upper bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ (1, ∞), default = 1025</em>) :</dt>
<dd><p class="first last">the size of input spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the lower bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ [1, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the number of mel-bands in the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberCoefficients</strong> (<em>integer ∈ [1, ∞), default = 13</em>) :</dt>
<dd><p class="first last">the number of output mel coefficients</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the mel-frequency cepstrum coefficients.
As there is no standard implementation, the MFCC-FB40 is used by default:</p>
<blockquote>
<ul class="simple">
<li>filterbank of 40 bands from 0 to 11000Hz</li>
<li>take the log value of the spectrum energy in each mel band</li>
<li>DCT of the 40 bands down to 13 mel coefficients</li>
</ul>
</blockquote>
<p>There is a paper describing various MFCC implementations [1].</p>
<p>This algorithm depends on the algorithms MelBands and DCT and therefore inherits their parameter restrictions. An exception is thrown if any of these restrictions are not met. The input &quot;spectrum&quot; is passed to the MelBands algorithm and thus imposes MelBands' input requirements. Exceptions are inherited by MelBands as well as by DCT.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] T. Ganchev, N. Fakotakis, and G. Kokkinakis, &quot;Comparative evaluation
of various MFCC implementations on the speaker verification task,&quot; in
International Conference on Speach and Computer (SPECOM’05), 2005, vol. 1,
pp. 191–194.</p>
<p class="last">[2] Mel-frequency cepstrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient">http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MinToTotal<br>[standard]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>vector_real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>minToTotal</strong> (<em>real</em>) - the minimum amplitude position to total length ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the ratio between the index of the minimum value of the envelope of a signal and the total length of the envelope.</p>
<p>An exception is thrown if the input envelop is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MonoLoader<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>downmix</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the mixing type for stereo files</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the desired output sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file this algorithm outputs the raw audio data downmixed to mono. Audio is resampled in case the given sampling rate does not match the sampling rate of the input signal.</p>
<p>This algorithm uses AudioLoader and thus inherits all of its input requirements and exceptions.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MonoMixer<br>[standard]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_stereosample</em>) - the input stereo signal</li>
<li><strong>numberChannels</strong> (<em>integer</em>) - the number of channels of the input signal</li>
</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the downmixed signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the type of downmixing performed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a stereo signal, this algorithm downmixes the signal into a single channel. If the signal was already a monoaural, it is left unchanged.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] downmixing - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Downmixing">http://en.wikipedia.org/wiki/Downmixing</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MonoWriter<br>[standard]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the audio signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bitrate</strong> (<em>integer ∈ {32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160, 192, 224, 256, 320}, default = 192</em>) :</dt>
<dd><p class="first last">the audio bit rate for compressed formats [kbps]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the encoded file</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>format</strong> (<em>string ∈ {wav, aiff, mp3, ogg, flac}, default = wav</em>) :</dt>
<dd><p class="first last">the audio output format</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm writes a mono audio stream to a file.</p>
<p>Supported formats are wav, aiff, mp3, flac and ogg. An exception is thrown when other extensions are given. Note that to encode in mp3 format it is mandatory that ffmpeg was configured with mp3 enabled.</p>
<p>If the file specified by filename could not be opened or the header of the file omits channel's information, an exception is thrown.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MovingAverage<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ (1, ∞), default = 6</em>) :</dt>
<dd><p class="first last">the size of the window [audio samples]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements an FIR Moving Average filter. Because of its dependece on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Moving Average Filters, <a class="reference external" href="http://www.dspguide.com/ch15.htm">http://www.dspguide.com/ch15.htm</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MultiPitchKlapuri<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_vector_real</em>) - the estimated pitch values [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter for the salience function (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">spectral peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 1760</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency for salience function peaks (ignore peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 10</em>) :</dt>
<dd><p class="first last">number of considered harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates multiple pitch values corresponding to the melodic lines present in a polyphonic music signal (i.e. string quartet, piano). This implementation is based on the algorithm in [1]: In each frame, a set of possible fundamental frequency candidates is extracted based on the principle of harmonic summation. In an optimization stage, the number of harmonic sources (polyphony) is estimated and the final set of fundamental frequencies determined. In contrast to the pich salience function proposed in [2], this implementation uses the pitch salience function described in [1].
The output is a vector for each frame containing the estimated melody pitch values.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] A. Klapuri, &quot;Multiple Fundamental Frequency Estimation by Summing Harmonic
Amplitudes &quot;, International Society for Music Information Retrieval Conference
(2006).
[2] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MultiPitchMelodia<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_vector_real</em>) - the estimated pitch values [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of iterations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter for the salience function (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">spectral peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 2], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change during 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">time continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates multiple fundamental frequency contours from the input signal. It is a multi pitch version of the MELODIA algorithm described in [1]. While the algorithm is originally designed to extract melody in polyphonic music, this implementation is adapted for multiple sources. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. To this end, PitchSalienceFunction, PitchSalienceFunctionPeaks, PitchContours, and PitchContoursMonoMelody algorithms are employed. It is strongly advised to use the default parameter values which are optimized according to [1] (where further details are provided) except for minFrequency, maxFrequency, and voicingTolerance, which will depend on your application.</p>
<p>The output is a vector of estimated melody pitch values and a vector of confidence values.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</p>
<p>[2] <a class="reference external" href="http://mtg.upf.edu/technologies/melodia">http://mtg.upf.edu/technologies/melodia</a></p>
<p class="last">[3] <a class="reference external" href="http://www.justinsalamon.com/melody-extraction">http://www.justinsalamon.com/melody-extraction</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Multiplexer<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>data</strong> (<em>vector_vector_real</em>) - the frame containing the input values and/or input frames</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>numberRealInputs</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the number of inputs of type Real to multiplex</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberVectorRealInputs</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the number of inputs of type vector&lt;Real&gt; to multiplex</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns a single vector from a given number of real values and/or frames. Frames from different inputs are multiplexed onto a single stream in an alternating fashion.</p>
<p>This algorithm throws an exception if the number of input reals (or vector&lt;real&gt;) is less than the number specified in configuration parameters or if the user tries to acces an input which has not been specified.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Multiplexer - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Multiplexer">http://en.wikipedia.org/wiki/Multiplexer</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
NoiseAdder<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the output signal with the added noise</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>fixSeed</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">if true, 0 is used as the seed for generating random values</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>level</strong> (<em>integer ∈ (-∞, 0], default = -100</em>) :</dt>
<dd><p class="first last">power level of the noise generator [dB]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm adds some amount of noise to an input signal, and returns the resulting output signal. The average energy of the noise in dB is defined by the level parameter, and is generated using the Mersenne Twister random number generator.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Mersenne Twister: A random number generator (since 1997/10),
<a class="reference external" href="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html">http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html</a></p>
<p class="last">[2] Mersenne twister - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Mersenne_twister">http://en.wikipedia.org/wiki/Mersenne_twister</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
NoveltyCurve<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencyBands</strong> (<em>vector_vector_real</em>) - the frequency bands</li>
</td><td class="col-xs-2">
<li><strong>novelty</strong> (<em>vector_real</em>) - the novelty curve as a single vector</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ [1, ∞), default = 344.531</em>) :</dt>
<dd><p class="first last">the sampling rate of the input audio</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>normalize</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether to normalize each band's energy</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>weightCurve</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">vector containing the weights for each frequency band. Only if weightCurveType==supplied</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>weightCurveType</strong> (<em>string ∈ {flat, triangle, inverse_triangle, parabola, inverse_parabola, linear, quadratic, inverse_quadratic, supplied}, default = inverse_quadratic</em>) :</dt>
<dd><p class="first last">the type of weighting to be used for the bands novelty</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio signal, this algorithm computes the novelty curve, such as defined in [1].</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] P. Grosche and M. Müller, &quot;A mid-level representation for capturing
dominant tempo and pulse information in music recordings,&quot; in
International Society for Music Information Retrieval Conference
(ISMIR’09), 2009, pp. 189–194.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
NoveltyCurveFixedBpmEstimator<br>[standard]

</th><td class="col-xs-2">
<li><strong>novelty</strong> (<em>vector_real</em>) - the novelty curve of the audio signal</li>
</td><td class="col-xs-2">
<li><strong>bpms</strong> (<em>vector_real</em>) - the bpm candidates sorted by magnitude</li>
<li><strong>amplitudes</strong> (<em>vector_real</em>) - the magnitude of each bpm candidate</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer, default = 512</em>) :</dt>
<dd><p class="first last">the hopSize used to computeh the novelty curve from the original signal</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxBpm</strong> (<em>real ∈ (0, ∞), default = 560</em>) :</dt>
<dd><p class="first last">the maximum bpm to look for</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minBpm</strong> (<em>real ∈ (0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">the minimum bpm to look for</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ [1, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate original audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ (0, 100], default = 3</em>) :</dt>
<dd><p class="first last">tolerance (in percentage) for considering bpms to be equal</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given the novelty curve (see NoveltyCurve algorithm), this algorithm outputs a histogram of the most probable bpms assuming the signal has constant tempo.This algorithm is based on the autocorrelation of the novelty curve and should only be used for signals that have a constant tempo or as a first tempo estimator to be used  in conjunction with other algorithms such as BpmHistogram.It is a simplified version of the algorithm described in [1] as, in order to predict the best BPM candidate,  it computes autocorrelation of the entire novelty curve instead of analyzing it on frames and histogramming the peaks over frames.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Aylon and N. Wack, &quot;Beat detection using plp,&quot; in Music Information
Retrieval Evaluation Exchange (MIREX’10), 2010.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OddToEvenHarmonicEnergyRatio<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the harmonic peaks (at least two frequencies in frequency ascending order)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the harmonic peaks (at least two magnitudes in frequency ascending order)</li>
</td><td class="col-xs-2">
<li><strong>oddToEvenHarmonicEnergyRatio</strong> (<em>real</em>) - the ratio between the odd and even harmonic energies of the given harmonic peaks</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the ratio between a signal's odd and even harmonic energy given the signal's harmonic peaks. The odd to even harmonic energy ratio is a measure allowing to distinguish odd-harmonic-energy predominant sounds (such as from a clarinet) from equally important even-harmonic-energy sounds (such as from a trumpet). The required harmonic frequencies and magnitudes can be computed by the HarmonicPeaks algorithm.
In the case when the even energy is zero, which may happen when only even harmonics where found or when only one peak was found, the algorithm outputs the maximum real number possible. Therefore, this algorithm should be used in conjunction with the harmonic peaks algorithm.
If no peaks are supplied, the algorithm outputs a value of one, assuming either the spectrum was flat or it was silent.</p>
<p>An exception is thrown if the input frequency and magnitude vectors have different size. Finally, an exception is thrown if the frequency and magnitude vectors are not ordered by ascending frequency.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] K. D. Martin and Y. E. Kim, &quot;Musical instrument identification:
A pattern-recognition approach,&quot; The Journal of the Acoustical Society of
America, vol. 104, no. 3, pp. 1768–1768, 1998.</p>
<p class="last">[2] K. Ringgenberg et al., &quot;Musical Instrument Recognition,&quot;
<a class="reference external" href="http://cnx.org/content/col10313/1.3/pdf">http://cnx.org/content/col10313/1.3/pdf</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OnsetDetection<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
<li><strong>phase</strong> (<em>vector_real</em>) - the phase vector corresponding to this spectrum--used only by the &quot;complex&quot; method</li>
</td><td class="col-xs-2">
<li><strong>onsetDetection</strong> (<em>real</em>) - the value of the detection function in the current frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>method</strong> (<em>string ∈ {hfc, complex, complex_phase, flux, melflux, rms}, default = hfc</em>) :</dt>
<dd><p class="first last">the method used for onset detection</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs an onset detection function useful for describing onset occurrences. The output of this algorithm should be post-processed in order to determine whether the frame contains an onset or not. Namely, it could be fed to the Onsets algorithm. It is recommended that the input &quot;spectrum&quot; is generated by the Spectrum algorithm.
Four methods are available:</p>
<blockquote>
<ul class="simple">
<li>'HFC', the High Frequency Content detection function which accurately detects percussive events (see HFC algorithm for details).</li>
<li>'complex', the Complex-Domain spectral difference function [1] taking into account changes in magnitude and phase. It emphasizes note onsets either as a result of significant change in energy in the magnitude spectrum, and/or a deviation from the expected phase values in the phase spectrum, caused by a change in pitch.</li>
<li>'complex_phase', the simplified Complex-Domain spectral difference function [2] taking into account phase changes, weighted by magnitude. TODO:It reacts better on tonal sounds such as bowed string, but tends to over-detect percussive events.</li>
<li>'flux', the Spectral Flux detection function which characterizes changes in magnitude spectrum. See Flux algorithm for details.</li>
<li>'melflux', the spectral difference function, similar to spectral flux, but using half-rectified energy changes in Mel-frequency bands of the spectrum [3].</li>
<li>'rms', the difference function, measuring the half-rectified change of the RMS of the magnitude spectrum (i.e., measuring overall energy flux) [4].</li>
</ul>
</blockquote>
<p>If using the 'HFC' detection function, make sure to adhere to HFC's input requirements when providing an input spectrum. Input vectors of different size or empty input spectra will raise exceptions.
If using the 'complex' detection function, suggested parameters for computation of &quot;spectrum&quot; and &quot;phase&quot; are 44100Hz sample rate, frame size of 1024 and hopSize of 512 samples, which results in a resolution of 11.6ms, and a Hann window.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Bello, Juan P., Chris Duxbury, Mike Davies, and Mark Sandler, On the
use of phase and energy for musical onset detection in the complex domain,
Signal Processing Letters, IEEE 11, no. 6 (2004): 553-556.</p>
<p>[2] P. Brossier, J. P. Bello, and M. D. Plumbley, &quot;Fast labelling of notes
in music signals,&quot; in International Symposium on Music Information
Retrieval (ISMIR’04), 2004, pp. 331–336.</p>
<p>[3] D. P. W. Ellis, &quot;Beat Tracking by Dynamic Programming,&quot; Journal of
New Music Research, vol. 36, no. 1, pp. 51–60, 2007.</p>
<p class="last">[4] J. Laroche, &quot;Efficient Tempo and Beat Tracking in Audio Recordings,&quot;
JAES, vol. 51, no. 4, pp. 226–233, 2003.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OnsetDetectionGlobal<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>onsetDetections</strong> (<em>vector_real</em>) - the frame-wise values of the detection function</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing onset detection function</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 512</em>) :</dt>
<dd><p class="first last">the hop size for computing onset detection function</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>method</strong> (<em>string ∈ {infogain, beat_emphasis}, default = infogain</em>) :</dt>
<dd><p class="first last">the method used for onset detection</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs an onset detection function useful for describing onset occurrences. Detection values are computed frame-wisely given an input signal. The output of this algorithm should be post-processed in order to determine whether the frame contains an onset or not. Namely, it could be fed to the Onsets algorithm.
The following method are available:</p>
<blockquote>
<ul class="simple">
<li>'infogain', the spectral difference measured by the modified information gain [1]. For each frame, it accounts for energy change in between preceding and consecutive frames, histogrammed together, in order to suppress short-term variations on frame-by-frame basis.</li>
<li>'beat_emphasis', the beat emphasis function [1]. This function is a linear combination of onset detection functions (complex spectral differences) in a number of sub-bands, weighted by their beat strength computed over the entire input signal.</li>
</ul>
</blockquote>
<p>Note:</p>
<blockquote>
<ul class="simple">
<li>'infogain' onset detection has been optimized for the default sampleRate=44100Hz, frameSize=2048, hopSize=512.</li>
<li>'beat_emphasis' is optimized for a fixed resolution of 11.6ms, which corresponds to the default sampleRate=44100Hz, frameSize=1024, hopSize=512.</li>
</ul>
<p>Optimal performance of beat detection with TempoTapDegara is not guaranteed for other settings.</p>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] S. Hainsworth and M. Macleod, &quot;Onset detection in musical audio
signals,&quot; in International Computer Music Conference (ICMC’03), 2003,
pp. 163–6.</p>
<p class="last">[2] M. E. P. Davies, M. D. Plumbley, and D. Eck, &quot;Towards a musical beat
emphasis function,&quot; in IEEE Workshop on Applications of Signal Processing
to Audio and Acoustics, 2009. WASPAA  ’09, 2009, pp. 61–64.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OnsetRate<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>onsets</strong> (<em>vector_real</em>) - the positions of detected onsets [s]</li>
<li><strong>onsetRate</strong> (<em>real</em>) - the number of onsets per second</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>Given an audio signal, this algorithm outputs the rate at which onsets occur and the onsets' position in time. Onset detection functions are computed using both high frequency content and complex-domain methods available in OnsetDetection algorithm. See OnsetDetection for more information.
Please note that due to a dependence on the Onsets algorithm, this algorithm is only valid for audio signals with a sampling rate of 44100Hz.
This algorithm throws an exception if the input signal is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Onsets<br>[standard]

</th><td class="col-xs-2">
<li><strong>detections</strong> (<em>matrix_real</em>) - matrix containing onset detection functions--rows represent the values of different detection functions and columns represent different frames of audio (i.e. detections[i][j] represents the value of the ith detection function for the jth frame of audio)</li>
<li><strong>weights</strong> (<em>vector_real</em>) - the weighting coefficicients for each detection function, must be the same as the first dimension of &quot;detections&quot;</li>
</td><td class="col-xs-2">
<li><strong>onsets</strong> (<em>vector_real</em>) - the onset times [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>alpha</strong> (<em>real ∈ [0, 1], default = 0.1</em>) :</dt>
<dd><p class="first last">the proportion of the mean included to reject smaller peaks--filters very short onsets</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>delay</strong> (<em>integer ∈ (0, ∞), default = 5</em>) :</dt>
<dd><p class="first last">the number of frames used to compute the threshold--size of short-onset filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ (0, ∞), default = 86.1328</em>) :</dt>
<dd><p class="first last">frames per second</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>silenceThreshold</strong> (<em>real ∈ [0, 1], default = 0.02</em>) :</dt>
<dd><p class="first last">the threshold for silence</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes onset times in seconds from an array of detection functions extracted from an audio file.</p>
<p>The main operations are:</p>
<blockquote>
<ul class="simple">
<li>normalizing detection functions,</li>
<li>summing detection functions into a global detection function,</li>
<li>smoothing the global detection function,</li>
<li>thresholding the global detection function for silence,</li>
<li>finding the possible onsets using an adaptative threshold,</li>
<li>cleaning operations on the vector of possible onsets,</li>
<li>onsets time conversion.</li>
</ul>
</blockquote>
<p>Note:</p>
<blockquote>
<ul class="simple">
<li>This algorithm has been optimized for a frameRate of 44100.0/512.0.</li>
<li>At least one Detection function must be supplied at input.</li>
<li>The number of weights must match the number of detection functions.</li>
</ul>
</blockquote>
<p>As mentioned above, the &quot;frameRate&quot; parameter expects a value of 44100/512 (the default), but will work with other values, although the quality of the results is not guaranteed then. An exception is also thrown if the input &quot;detections&quot; matrix is empty. Finally, an exception is thrown if the size of the &quot;weights&quot; input does not equal the first dimension of the &quot;detections&quot; matrix.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] P. Brossier, J. P. Bello, and M. D. Plumbley, &quot;Fast labelling of notes
in music signals,” in International Symposium on Music Information
Retrieval (ISMIR’04), 2004, pp. 331–336.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OverlapAdd<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the windowed input audio frame</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the output overlap-add audio signal frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing the overlap-add process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the overlap-add function is computed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<div class="system-message">
<p class="system-message-title">System Message: INFO/1 (<tt class="docutils">&lt;stdin&gt;</tt>, line 26)</p>
Possible title underline, too short for the title.
Treating it as ordinary text because it's so short.</div>
<p>This algorithm returns the output of an overlap-add process of a sequence of input audio signal frames. It considers that the input audio frames are windowed audio signals. Giving the size of the frame and the hop size, overlapping and adding consecutive frames with produce a continuous signal.
.</p>
<p>Empty input signals will raise an exception.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Overlap–add method - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Overlap-add_method">http://en.wikipedia.org/wiki/Overlap-add_method</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Panning<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrumLeft</strong> (<em>vector_real</em>) - left channel's spectrum</li>
<li><strong>spectrumRight</strong> (<em>vector_real</em>) - right channel's spectrum</li>
</td><td class="col-xs-2">
<li><strong>panningCoeffs</strong> (<em>matrix_real</em>) - parameters that define the panning curve at each frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>averageFrames</strong> (<em>integer ∈ [0, ∞), default = 43</em>) :</dt>
<dd><p class="first last">number of frames to take into account for averaging</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numBands</strong> (<em>integer ∈ [1, ∞), default = 1</em>) :</dt>
<dd><p class="first last">number of mel bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numCoeffs</strong> (<em>integer ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of coefficients used to define the panning curve at each frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>panningBins</strong> (<em>integer ∈ (1, ∞), default = 512</em>) :</dt>
<dd><p class="first last">size of panorama histogram (in bins)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>warpedPanorama</strong> (<em>bool ∈ {false, true}, default = true</em>) :</dt>
<dd><p class="first last">if true, warped panorama is applied, having more resolution in the center area</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm characterizes panorama distribution by comparing spectra from the left and right channels. The panning coefficients are extracted by:</p>
<ul class="simple">
<li>determining the spatial location of frequency bins given left and right channel spectra;</li>
<li>computing panorama histogram weighted by the energy of frequency bins, averaging it across frames and normalizing;</li>
<li>converting the normalized histogram into panning coefficients (IFFT of the log-histogram).</li>
</ul>
<p>The resulting coefficients will show peaks on the initial bins for left panned audio, and right panning will appear as peaks in the upper bins.</p>
<p>Since panning can vary very rapidly from one frame to the next, the coefficients can be averaged over a time window of several frames by specifying &quot;averageFrames&quot; parameter. If a single vector of panning coefficients for the whole audio input is required, &quot;averageFrames&quot; should correspond to the length of audio input. In standard mode, sequential runs of compute() method on each frame are required for averaging across frames.</p>
<p>Application: music classification, in particular genre classification [2].</p>
<p>Note: At present time, the original algorithm has not been tested in multi-band mode. That is, numBands must remain 1.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez, P. Herrera, P. Cano, J. Janer, J. Serrà, J. Bonada,
S. El-Hajj, T. Aussenac, and G. Holmberg, &quot;Music similarity systems and
methods using descriptors,” U.S. Patent WO 2009/0012022009.</p>
<p class="last">[2] Guaus, E. (2009). Audio content processing for automatic music genre
classification: descriptors, databases, and classifiers. PhD Thesis.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PCA<br>[standard]

</th><td class="col-xs-2">
<li><strong>poolIn</strong> (<em>pool</em>) - the pool where to get the spectral contrast feature vectors</li>
</td><td class="col-xs-2">
<li><strong>poolOut</strong> (<em>pool</em>) - the pool where to store the transformed feature vectors</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>dimensions</strong> (<em>integer ∈ [0,  ∞), default = 0</em>) :</dt>
<dd><p class="first last">number of dimension to reduce the input to</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>namespaceIn</strong> (<em>string, default = spectral contrast</em>) :</dt>
<dd><p class="first last">will look for this namespace in poolIn</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>namespaceOut</strong> (<em>string, default = spectral contrast pca</em>) :</dt>
<dd><p class="first last">will save to this namespace in poolOut</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Karhunen Loeve Transform || Principal Component Analysis based on the covariance matrix of the signal.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Principal component analysis - Wikipedia, the free enciclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Principal_component_analysis">http://en.wikipedia.org/wiki/Principal_component_analysis</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PeakDetection<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>positions</strong> (<em>vector_real</em>) - the positions of the peaks</li>
<li><strong>amplitudes</strong> (<em>vector_real</em>) - the amplitudes of the peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>interpolate</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">boolean flag to enable interpolation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxPeaks</strong> (<em>integer ∈ [1, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the maximum number of returned peaks</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxPosition</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum value of the range to evaluate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minPosition</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the minimum value of the range to evaluate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>orderBy</strong> (<em>string ∈ {position, amplitude}, default = position</em>) :</dt>
<dd><p class="first last">the ordering type of the output peaks (ascending by position or descending by value)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the input range</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ (-∞, ∞), default = -1e+06</em>) :</dt>
<dd><p class="first last">peaks below this given threshold are not output</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The peak detection algorithm detects local maxima (peaks) in a data array.
The algorithm finds positive slopes and detects a peak when the slope changes sign and the peak is above the threshold.
It optionally interpolates using parabolic curve fitting.</p>
<p>Exceptions are thrown if parameter &quot;minPosition&quot; is greater than parameter &quot;maxPosition&quot;, also if the size of the input array is less than 2 elements.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Peak Detection,
<a class="reference external" href="http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html">http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContours<br>[standard]

</th><td class="col-xs-2">
<li><strong>peakBins</strong> (<em>vector_vector_real</em>) - frame-wise array of cent bins corresponding to pitch salience function peaks</li>
<li><strong>peakSaliences</strong> (<em>vector_vector_real</em>) - frame-wise array of values of salience function peaks</li>
</td><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 2], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change durig 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">time continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm tracks a set of predominant pitch contours from an audio signal. This algorithm is intended to receive its &quot;frequencies&quot; and &quot;magnitudes&quot; inputs from the PitchSalienceFunctionPeaks algorithm outputs aggregated over all frames in the sequence. The output is a vector of estimated melody pitch values.</p>
<p>When input vectors differ in size, an exception is thrown. Input vectors must not contain negative salience values otherwise an exception is thrown. Avoiding erroneous peak duplicates (peaks of the same cent bin) is up to the user's own control and is highly recommended, but no exception will be thrown.</p>
<p>Recommended processing chain: (see [1]): EqualLoudness -&gt; frame slicing with sample rate = 44100, frame size = 2048, hop size = 128 -&gt; Windowing with Hann, x4 zero padding -&gt; Spectrum -&gt; SpectralPeaks -&gt; PitchSalienceFunction (10 cents bin resolution) -&gt; PitchSalienceFunctionPeaks.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContourSegmentation<br>[standard]

</th><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - estimated pitch contour [Hz]</li>
<li><strong>signal</strong> (<em>vector_real</em>) - input audio signal</li>
</td><td class="col-xs-2">
<li><strong>onset</strong> (<em>vector_real</em>) - note onset times [s]</li>
<li><strong>duration</strong> (<em>vector_real</em>) - note durations [s]</li>
<li><strong>MIDIpitch</strong> (<em>vector_real</em>) - quantized MIDI pitch value</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">hop size of the extracted pitch</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDur</strong> (<em>real ∈ (0, ∞), default = 0.1</em>) :</dt>
<dd><p class="first last">minimum note duration [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchDistanceThreshold</strong> (<em>integer ∈ (0, ∞), default = 60</em>) :</dt>
<dd><p class="first last">pitch threshold for note segmentation [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>rmsThreshold</strong> (<em>integer ∈ (-∞, 0), default = -2</em>) :</dt>
<dd><p class="first last">zscore threshold for note segmentation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>integer ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">sample rate of the audio signal</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tuningFreq</strong> (<em>integer ∈ (0, 22000), default = 440</em>) :</dt>
<dd><p class="first last">tuning reference frequency  [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm converts a pitch sequence estimated from an audio signal into a set of discrete note event. Each note is defined by its onset time, duration and MIDI pitch value, quantized to the equal tempered scale.</p>
<p>Note segmentation is performed based on pitch contour characteristics (island building) and signal RMS. Notes below an adjustable minimum duration are rejected.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] R. J. McNab et al., &quot;Signal processing for melody transcription,&quot; in Proc.
Proc. 19th Australasian Computer Science Conf., 1996</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContoursMelody<br>[standard]

</th><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of the start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - vector of estimated pitch values (i.e., melody) [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">Estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (Hz)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voiceVibrato</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">detect voice vibrato</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voicingTolerance</strong> (<em>real ∈ [-1.0, 1.4], default = 0.2</em>) :</dt>
<dd><p class="first last">allowed deviation below the average contour mean salience of all contours (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm converts a set of pitch contours into a sequence of predominant f0 values in Hz by taking the value of the most predominant contour in each frame.
This algorithm is intended to receive its &quot;contoursBins&quot;, &quot;contoursSaliences&quot;, and &quot;contoursStartTimes&quot; inputs from the PitchContours algorithm. The &quot;duration&quot; input corresponds to the time duration of the input signal. The output is a vector of estimated pitch values and a vector of confidence values.</p>
<p>Note that &quot;pitchConfidence&quot; can be negative in the case of &quot;guessUnvoiced&quot;=True: the absolute values represent the confidence, negative values correspond to segments for which non-salient contours where selected, zero values correspond to non-voiced segments.</p>
<p>When input vectors differ in size, or &quot;numberFrames&quot; is negative, an exception is thrown. Input vectors must not contain negative start indices nor negative bin and salience values otherwise an exception is thrown.</p>
<p>Recommended processing chain: (see [1]): EqualLoudness -&gt; frame slicing with sample rate = 44100, frame size = 2048, hop size = 128 -&gt; Windowing with Hann, x4 zero padding -&gt; Spectrum -&gt; SpectralPeaks -&gt; PitchSalienceFunction -&gt; PitchSalienceFunctionPeaks -&gt; PitchContours.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContoursMonoMelody<br>[standard]

</th><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of the start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - vector of estimated pitch values (i.e., melody) [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">Estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (Hz)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm converts a set of pitch contours into a sequence of f0 values in Hz by taking the value of the most salient contour in each frame.
In contrast to pitchContoursMelody, it assumes a single source.
This algorithm is intended to receive its &quot;contoursBins&quot;, &quot;contoursSaliences&quot;, and &quot;contoursStartTimes&quot; inputs from the PitchContours algorithm. The &quot;duration&quot; input corresponds to the time duration of the input signal. The output is a vector of estimated pitch values and a vector of confidence values.</p>
<p>Note that &quot;pitchConfidence&quot; can be negative in the case of &quot;guessUnvoiced&quot;=True: the absolute values represent the confidence, negative values correspond to segments for which non-salient contours where selected, zero values correspond to non-voiced segments.</p>
<p>When input vectors differ in size, or &quot;numberFrames&quot; is negative, an exception is thrown. Input vectors must not contain negative start indices nor negative bin and salience values otherwise an exception is thrown.</p>
<p>Recommended processing chain: (see [1]): EqualLoudness -&gt; frame slicing with sample rate = 44100, frame size = 2048, hop size = 128 -&gt; Windowing with Hann, x4 zero padding -&gt; Spectrum -&gt; SpectralPeaks -&gt; PitchSalienceFunction -&gt; PitchSalienceFunctionPeaks -&gt; PitchContours.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContoursMultiMelody<br>[standard]

</th><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of the start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_vector_real</em>) - vector of estimated pitch values (i.e., melody) [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">Estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (Hz)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm post-processes a set of pitch contours into a sequence of mutliple f0 values in Hz.
This algorithm is intended to receive its &quot;contoursBins&quot;, &quot;contoursSaliences&quot;, and &quot;contoursStartTimes&quot; inputs from the PitchContours algorithm. The &quot;duration&quot; input corresponds to the time duration of the input signal. The output is a vector of estimated pitch values</p>
<p>When input vectors differ in size, or &quot;numberFrames&quot; is negative, an exception is thrown. Input vectors must not contain negative start indices nor negative bin and salience values otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchFilter<br>[standard]

</th><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - vector of pitch values for the input frames [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - vector of pitch confidence values for the input frames</li>
</td><td class="col-xs-2">
<li><strong>pitchFiltered</strong> (<em>vector_real</em>) - vector of corrected pitch values [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>confidenceThreshold</strong> (<em>integer ∈ [0, ∞), default = 36</em>) :</dt>
<dd><p class="first last">ratio between the average confidence of the most confident chunk and the minimum allowed average confidence of a chunk</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minChunkSize</strong> (<em>integer ∈ [0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">minumum number of frames in non-zero pitch chunks</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useAbsolutePitchConfidence</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">treat negative pitch confidence values as positive (use with melodia guessUnvoiced=True)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm corrects the fundamental frequency estimations for a sequence of frames given pitch values together with their confidence values (e.g., by removing non-confident parts and spurious jumps in pitch, and applying octave corrections).</p>
<p>They can be computed with the PitchYinFFT, PitchYin, or PredominantPitchMelodia algorithms.
If you use PredominantPitchMelodia with guessUnvoiced=True, set useAbsolutePitchConfidence=True.</p>
<p>The algorithm can be used for any type of monophonic and heterophonic music.</p>
<p>The original algorithm [1] was proposed to be used for Makam music and employs signal&quot;energy&quot; of frames instead of pitch confidence.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] B. Bozkurt, &quot;An Automatic Pitch Analysis Method for Turkish Maqam
Music,&quot; Journal of New Music Research. 37(1), 1-13.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchMelodia<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the estimated pitch values [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of iterations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter for the salience function (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">spectral peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 2], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change during 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">time continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency corresponding to the melody of a monophonic music signal (i.e. solo violin, solo singing voice). It implements the MELODIA algorithm described in [1]. While the algorithm is originally designed to extract the predominant melody from polyphonic music, this implementation is adapted for monophonic signals. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. To this end, PitchSalienceFunction, PitchSalienceFunctionPeaks, PitchContours, and PitchContoursMonoMelody algorithms are employed. It is strongly advised to use the default parameter values which are optimized according to [1] (where further details are provided) except for minFrequency and maxFrequency, which will depend on your application.</p>
<p>The output is a vector of estimated melody pitch values and a vector of confidence values.</p>
<p>It is recommended to apply EqualLoudness on the input signal (see [1]) as a pre-processing stage before running this algorithm.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</p>
<p>[2] <a class="reference external" href="http://mtg.upf.edu/technologies/melodia">http://mtg.upf.edu/technologies/melodia</a></p>
<p class="last">[3] <a class="reference external" href="http://www.justinsalamon.com/melody-extraction">http://www.justinsalamon.com/melody-extraction</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchSalience<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>pitchSalience</strong> (<em>real</em>) - the pitch salience (normalized from 0 to 1)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highBoundary</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">until which frequency we are looking for the minimum (must be smaller than half sampleRate) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowBoundary</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">from which frequency we are looking for the maximum (must not be larger than highBoundary) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the pitch salience of a spectrum. The pitch salience is given by the ratio of the highest auto correlation value of the spectrum to the non-shifted auto correlation value. Pitch salience was designed as quick measure of tone sensation. Unpitched sounds (non-musical sound effects) and pure tones have an average pitch salience value close to 0 whereas sounds containing several harmonics in the spectrum tend to have a higher value.</p>
<p>Note that this algorithm may give better results when used with low sampling rates (i.e. 8000) as the information in the bands musically meaningful will have more relevance.</p>
<p>This algorithm uses AutoCorrelation on the input &quot;spectrum&quot; and thus inherits its input requirements and exceptions. An exception is thrown at configuration time if &quot;lowBoundary&quot; is larger than &quot;highBoundary&quot; and/or if &quot;highBoundary&quot; is not smaller than half &quot;sampleRate&quot;. At computation time, an exception is thrown if the input spectrum is empty. Also note that feeding silence to this algorithm will return zero.</p>
<p>Application: characterizing percussive sounds.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Ricard &quot;Towards computational morphological description of sound.
DEA pre-thesis research work, Universitat Pompeu Fabra, Barcelona, 2004.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchSalienceFunction<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><strong>salienceFunction</strong> (<em>vector_real</em>) - array of the quantized pitch salience values</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>real ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the pitch salience function of a signal frame given its spectral peaks. The salience function covers a pitch range of nearly five octaves (i.e., 6000 cents), starting from the &quot;referenceFrequency&quot;, and is quantized into cent bins according to the specified &quot;binResolution&quot;. The salience of a given frequency is computed as the sum of the weighted energies found at integer multiples (harmonics) of that frequency.</p>
<p>This algorithm is intended to receive its &quot;frequencies&quot; and &quot;magnitudes&quot; inputs from the SpectralPeaks algorithm. The output is a vector of salience values computed for the cent bins. The 0th bin corresponds to the specified &quot;referenceFrequency&quot;.</p>
<p>When input vectors differ in size or are empty, an exception is thrown. Input vectors must contain positive frequencies and not contain negative magnitudes otherwise an exception is thrown. It is highly recommended to avoid erroneous peak duplicates (peaks of the same frequency occuring more than ones), but it is up to the user's own control and no exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchSalienceFunctionPeaks<br>[standard]

</th><td class="col-xs-2">
<li><strong>salienceFunction</strong> (<em>vector_real</em>) - the array of salience function values corresponding to cent frequency bins</li>
</td><td class="col-xs-2">
<li><strong>salienceBins</strong> (<em>vector_real</em>) - the cent bins corresponding to salience function peaks</li>
<li><strong>salienceValues</strong> (<em>vector_real</em>) - the values of salience function peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 1760</em>) :</dt>
<dd><p class="first last">the maximum frequency to evaluate (ignore peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the minimum frequency to evaluate (ignore peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the peaks of a given pitch salience function.</p>
<p>This algorithm is intended to receive its &quot;salienceFunction&quot; input from the PitchSalienceFunction algorithm. The peaks are detected using PeakDetection algorithm. The outputs are two arrays of bin numbers and salience values corresponding to the peaks.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Salamon, J., &amp; Gómez E. (2012).  Melody Extraction from Polyphonic Music Signals using Pitch Contour Characteristics.</dt>
<dd>IEEE Transactions on Audio, Speech and Language Processing. 20(6), 1759-1770.</dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchYin<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal frame</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>real</em>) - detected pitch [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>real</em>) - confidence with which the pitch was detected [0,1]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [2, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">number of samples in the input frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>interpolate</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">enable interpolation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">sampling rate of the input spectrum [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, 1], default = 0.15</em>) :</dt>
<dd><p class="first last">tolerance for peak detection</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency from a given spectrum. It is an implementation of the Yin algorithm [1] for computations in the time domain.</p>
<p>An exception is thrown if an empty signal is provided.</p>
<p>Please note that if &quot;pitchConfidence&quot; is zero, &quot;pitch&quot; is undefined and should not be used for other algorithms.
Also note that a null &quot;pitch&quot; is never ouput by the algorithm and that &quot;pitchConfidence&quot; must always be checked out.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] De Cheveigné, A., &amp; Kawahara, H. &quot;YIN, a fundamental frequency estimator
for speech and music. The Journal of the Acoustical Society of America,
111(4), 1917-1930, 2002.</p>
<p class="last">[2] Pitch detection algorithm - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Pitch_detection_algorithm">http://en.wikipedia.org/wiki/Pitch_detection_algorithm</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchYinFFT<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (preferably created with a hann window)</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>real</em>) - detected pitch [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>real</em>) - confidence with which the pitch was detected [0,1]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [2, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">number of samples in the input spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>interpolate</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">boolean flag to enable interpolation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">sampling rate of the input spectrum [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency corresponding to the melody of a monophonic music signal (i.e. solo violin or solo singing voice). It is an implementation of YinFFT algorithm [1], which is an optimized version of Yin algorithm for computation in the frequency domain. It is recommended to window the input spectrum with a Hann window. The raw spectrum can be computed with the Spectrum algorithm.</p>
<p>An exception is thrown if an empty spectrum is provided.</p>
<p>Please note that if &quot;pitchConfidence&quot; is zero, &quot;pitch&quot; is undefined and should not be used for other algorithms.
Also note that a null &quot;pitch&quot; is never ouput by the algorithm and that &quot;pitchConfidence&quot; must always be checked out.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] P. M. Brossier, &quot;Automatic Annotation of Musical Audio for Interactive
Applications,” QMUL, London, UK, 2007.</p>
<p class="last">[2] Pitch detection algorithm - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Pitch_detection_algorithm">http://en.wikipedia.org/wiki/Pitch_detection_algorithm</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PolarToCartesian<br>[standard]

</th><td class="col-xs-2">
<li><strong>magnitude</strong> (<em>vector_real</em>) - the magnitude vector</li>
<li><strong>phase</strong> (<em>vector_real</em>) - the phase vector</li>
</td><td class="col-xs-2">
<li><strong>complex</strong> (<em>vector_complex</em>) - the resulting complex vector</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm converts an array of complex numbers from its polar form to its cartesian form through the Euler formula:</dt>
<dd><dl class="first last docutils">
<dt>z = x + i*y = |z|(cos(α) + i sin(α))</dt>
<dd>where x = Real part, y = Imaginary part,
and |z| = modulus = magnitude, α = phase</dd>
</dl>
</dd>
</dl>
<p>An exception is thrown if the size of the magnitude vector does not match the size of the phase vector.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Polar coordinate system - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Polar_coordinates">http://en.wikipedia.org/wiki/Polar_coordinates</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PoolAggregator<br>[standard]

</th><td class="col-xs-2">
<li><strong>input</strong> (<em>pool</em>) - the input pool</li>
</td><td class="col-xs-2">
<li><strong>output</strong> (<em>pool</em>) - a pool containing the aggregate values of the input pool</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>defaultStats</strong> (<em>vector_string, default = [&quot;mean&quot;, &quot;var&quot;, &quot;min&quot;, &quot;max&quot;, &quot;median&quot;]</em>) :</dt>
<dd><p class="first last">the default statistics to be computed for each descriptor in the input pool</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>exceptions</strong> (<em>map_vector_string, default = {}</em>) :</dt>
<dd><p class="first last">a mapping between descriptor names (no duplicates) and the types of statistics to be computed for those descriptors (e.g. { lowlevel.bpm : [min, max], lowlevel.gain : [var, min, dmean] })</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm performs statistical aggregation on a Pool and places the results of the aggregation into a new Pool. Supported statistical units are:</dt>
<dd>'min' (minimum),
'max' (maximum),
'median'
'mean'
'var' (variance),
'skew' (skewness),
'kurt' (kurtosis),
'dmean' (mean of the derivative),
'dvar' (variance of the derivative),
'dmean2' (mean of the second derivative),
'dvar2' (variance of the second derivative),
'cov' (covariance), and
'icov' (inverse covariance).
'copy' (verbatim copy of descriptor, no aggregation; exclusive: cannot be performed with any other statistical units).
'value' (copy of the descriptor, but the value is placed under the name '&lt;descriptor name&gt;.value')</dd>
</dl>
<p>These statistics can be computed for single dimensional vectors in a Pool, with the exception of 'cov' and 'icov'. All of the above statistics can be
computed for two dimensional vectors in the Pool. With the exception of 'cov' and 'icov', two-dimensional statistics are calculated by aggregating
each column and placing the result into a vector of the same size as the size of each vector in the input Pool. The previous implies that each
vector in the pool (under a particular descriptor of course) must have equal size. This implication also applies for 'cov' and 'icov'.</p>
<p>An additional restriction for using the 'icov' statistic is that the covariance matrix for a particular descriptor must be invertible. The 'cov' and 'icov' aggregation statistics each return a square matrix with dimension equal to the length of the vectors under the given descriptor.</p>
<p>Please also note that only the absolute values of the first and second derivates are considered when calculating the mean ('dmean' and 'dmean2') as well as for the variance ('dvar' and 'dvar2'). This is to avoid a trivial solution for the mean.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PowerMean<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (must contain only positive real numbers)</li>
</td><td class="col-xs-2">
<li><strong>powerMean</strong> (<em>real</em>) - the power mean of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>power</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the power to which to elevate each element before taking the mean</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the Power Mean of an array of Reals. It accepts one parameter, p, which is the power (or order or degree) of the Power Mean. Note that if p=-1, the Power Mean is equal to the Harmonic Mean, if p=0, the Power Mean is equal to the Geometric Mean, if p=1, the Power Mean is equal to the Arithmetic Mean, if p=2, the Power Mean is equal to the Root Mean Square.</p>
<p>Exceptions are thrown if input array either is empty or it contains non positive numbers.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Power Mean -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/PowerMean.html">http://mathworld.wolfram.com/PowerMean.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PowerSpectrum<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>powerSpectrum</strong> (<em>vector_real</em>) - the power spectrum of the input signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the expected size of the input frame (this is purely optional and only targeted at optimizing the creation time of the FFT object)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the power spectrum of an array of Reals. The resulting power spectrum is of the same size as the incoming frame.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Power Spectrum - from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/PowerSpectrum.html">http://mathworld.wolfram.com/PowerSpectrum.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PredominantMelody<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the estimated pitch values [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of iterations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter for the salience function (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">spectral peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 2], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change during 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">time continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voiceVibrato</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">detect voice vibrato</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voicingTolerance</strong> (<em>real ∈ [-1.0, 1.4], default = 0.2</em>) :</dt>
<dd><p class="first last">allowed deviation below the average contour mean salience of all contours (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency of the predominant melody in the input signal. It implements the MELODIA algorithm described in [1]. The algorithm is specifically suited to extract melody in polyphonic music, but also works for monophonic signals. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. To this end, PitchSalienceFunction, PitchSalienceFunctionPeaks, PitchContours, and PitchContoursMelody algorithms are employed. It is strongly advised to use the default parameter values which are optimized according to [1] (where further details are provided) except for minFrequency, maxFrequency, and voicingTolerance, which will depend on your application.</p>
<p>The output is a vector of estimated melody pitch values and a vector of confidence values. The first value corresponds to the beginning of the input signal (time 0).</p>
<p>It is recommended to apply EqualLoudness on the input signal (see [1]) as a pre-processing stage before running this algorithm.</p>
<p>Note that &quot;pitchConfidence&quot; can be negative in the case of &quot;guessUnvoiced&quot;=True: the absolute values represent the confidence, negative values correspond to segments for which non-salient contours where selected, zero values correspond to non-voiced segments.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</p>
<p>[2] <a class="reference external" href="http://mtg.upf.edu/technologies/melodia">http://mtg.upf.edu/technologies/melodia</a></p>
<p class="last">[3] <a class="reference external" href="http://www.justinsalamon.com/melody-extraction">http://www.justinsalamon.com/melody-extraction</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PredominantPitchMelodia<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the estimated pitch values [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of iterations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter for the salience function (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">spectral peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 2], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change during 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">time continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voiceVibrato</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">detect voice vibrato</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voicingTolerance</strong> (<em>real ∈ [-1.0, 1.4], default = 0.2</em>) :</dt>
<dd><p class="first last">allowed deviation below the average contour mean salience of all contours (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency of the predominant melody from polyphonic music signals (i.e. the singing voice melody in an accompanied singing recording). It implements the MELODIA algorithm described in [1]. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. It furthermore determines for each frame, if the predominant melody is present or not. To this end, PitchSalienceFunction, PitchSalienceFunctionPeaks, PitchContours, and PitchContoursMelody algorithms are employed. It is strongly advised to use the default parameter values which are optimized according to [1] (where further details are provided) except for minFrequency, maxFrequency, and voicingTolerance, which will depend on your application.</p>
<p>The output is a vector of estimated melody pitch values and a vector of confidence values. The first value corresponds to the beginning of the input signal (time 0).</p>
<p>It is recommended to apply EqualLoudness on the input signal (see [1]) as a pre-processing stage before running this algorithm.</p>
<p>Note that &quot;pitchConfidence&quot; can be negative in the case of &quot;guessUnvoiced&quot;=True: the absolute values represent the confidence, negative values correspond to segments for which non-salient contours where selected, zero values correspond to non-voiced segments.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</p>
<p>[2] <a class="reference external" href="http://mtg.upf.edu/technologies/melodia">http://mtg.upf.edu/technologies/melodia</a></p>
<p class="last">[3] <a class="reference external" href="http://www.justinsalamon.com/melody-extraction">http://www.justinsalamon.com/melody-extraction</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RawMoments<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>rawMoments</strong> (<em>vector_real</em>) - the (raw) moments of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the first 5 raw moments of an array of Reals. The output array is of size 6 because the zero-ith moment is used for padding so that the first moment corresponds to index 1.</p>
<dl class="docutils">
<dt>Note:</dt>
<dd>This algorithm has a range parameter, which usually represents a frequency (results will range from 0 to range). For a spectral centroid, the range should be equal to samplerate / 2. For an audio centroid, the frequency range should be equal to (audio_size-1) / samplerate.</dd>
</dl>
<p>An exception is thrown if the input array's size is smaller than 2.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Raw Moment -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/RawMoment.html">http://mathworld.wolfram.com/RawMoment.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ReplayGain<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal (must be longer than 0.05ms)</li>
</td><td class="col-xs-2">
<li><strong>replayGain</strong> (<em>real</em>) - the distance to the suitable average replay level (~-31dbB) defined by SMPTE [dB]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the input audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the Replay Gain loudness value of the audio. The algorithm is described in detail at [1]. The value returned is the 'standard' ReplayGain value, not the value with 6dB preamplification as it is computed by lame, mp3gain, vorbisgain, and all widely used ReplayGain programs.</p>
<p>This algorithm is only defined for input signals which size is larger than 0.05ms, otherwise an exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Replay Gain - A Proposed Standard, <a class="reference external" href="http://replaygain.hydrogenaudio.org">http://replaygain.hydrogenaudio.org</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Resample<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the resampled signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>inputSampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the input signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>outputSampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the output signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>quality</strong> (<em>integer ∈ [0, 4], default = 1</em>) :</dt>
<dd><p class="first last">the quality of the conversion, 0 for best quality</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm resamples the input signal to the desired sampling rate.</p>
<p>This algorithm is only supported if essentia has been compiled with Real=float, otherwise it will throw an exception. It may also throw an exception if there is an internal error in the SRC library during conversion.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Secret Rabbit Code, <a class="reference external" href="http://www.mega-nerd.com/SRC">http://www.mega-nerd.com/SRC</a></p>
<p class="last">[2] Resampling - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Resampling">http://en.wikipedia.org/wiki/Resampling</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmDescriptors<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>beats_position</strong> (<em>vector_real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>bpm</strong> (<em>real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>bpm_estimates</strong> (<em>vector_real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>bpm_intervals</strong> (<em>vector_real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>first_peak_bpm</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>first_peak_spread</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>first_peak_weight</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>second_peak_bpm</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>second_peak_spread</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>second_peak_weight</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>this algorithm computes low level rhythm features</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>bpm</strong> (<em>real</em>) - the tempo estimation [bpm]</li>
<li><strong>ticks</strong> (<em>vector_real</em>) -  the estimated tick locations [s]</li>
<li><strong>estimates</strong> (<em>vector_real</em>) - the bpm estimation per frame [bpm]</li>
<li><strong>bpmIntervals</strong> (<em>vector_real</em>) - list of beats interval [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameHop</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the number of feature frames separating two evaluations</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the number audio samples used to compute a feature</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">the number of audio samples per features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lastBeatInterval</strong> (<em>real ∈ [0, ∞), default = 0.1</em>) :</dt>
<dd><p class="first last">the minimum interval between last beat and end of file [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberFrames</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the number of feature frames to buffer on</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tempoHints</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the optional list of initial beat locations, to favor the detection of pre-determined tempo period and beats alignment [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, ∞), default = 0.24</em>) :</dt>
<dd><p class="first last">the minimum interval between two consecutive beats [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useBands</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether or not to use band energy as periodicity function</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useOnset</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether or not to use onsets as periodicity function</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the tempo in bpm from an input signal, as well as the beat locations. The algorithm combines several periodicity functions and estimates beats using TempoTap and TempoTapTicks. It combines:
- onset detection functions based on high-frequency content (see OnsetDetection)
- complex-domain spectral difference function (see OnsetDetection)
- periodicity function based on energy bands (see FrequencyBands, TempoScaleBands)</p>
<p>Note that this algorithm is outdated in terms of beat tracking accuracy, and it is highly recommended to use RhythmExtractor2013 instead.</p>
<p>Quality: outdated (use RhythmExtractor2013 instead).</p>
<p>An exception is thrown if neither &quot;useOnset&quot; nor &quot;useBands&quot; are enabled (i.e. set to true).</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmExtractor2013<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>bpm</strong> (<em>real</em>) - the tempo estimation [bpm]</li>
<li><strong>ticks</strong> (<em>vector_real</em>) -  the estimated tick locations [s]</li>
<li><strong>confidence</strong> (<em>real</em>) - confidence with which the ticks are detected (ignore this value if using 'degara' method)</li>
<li><strong>estimates</strong> (<em>vector_real</em>) - the list of bpm estimates characterizing the bpm distribution for the signal [bpm]</li>
<li><strong>bpmIntervals</strong> (<em>vector_real</em>) - list of beats interval [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>method</strong> (<em>string ∈ {multifeature, degara}, default = multifeature</em>) :</dt>
<dd><p class="first last">the method used for beat tracking</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the beat locations and the confidence of their estimation given an input signal, as well as its tempo in bpm. The beat locations can be computed using:</p>
<blockquote>
<ul class="simple">
<li>'multifeature', the BeatTrackerMultiFeature algorithm</li>
<li>'degara', the BeatTrackerDegara algorithm (note that there is no confidence estimation for this method, the output confidence value is always 0)</li>
</ul>
</blockquote>
<p>See BeatTrackerMultiFeature and  BeatTrackerDegara algorithms for more details.</p>
<p>Note that the algorithm requires the sample rate of the input signal to be 44100 Hz in order to work correctly.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmTransform<br>[standard]

</th><td class="col-xs-2">
<li><strong>melBands</strong> (<em>vector_vector_real</em>) - the energy in the melbands</li>
</td><td class="col-xs-2">
<li><strong>rhythm</strong> (<em>vector_vector_real</em>) - consecutive frames in the rhythm domain</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">the frame size to compute the rhythm trasform</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 32</em>) :</dt>
<dd><p class="first last">the hop size to compute the rhythm transform</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The Rhythm Transform algorithm is based on the rhythm transform as described in [1]. It computes a rhythmical representation of the input signal in the rhythm domain much like FFT computes a representation in the frequency domain. Additionally features as rhythmic centroid and MFCCs can be calculated from this rhythmic representation.
Note that parameters &quot;frameSize&quot; and &quot;hopSize&quot; are defined for the rhythm transformation (FFT transform on the rhythm space) and have a different meaning than the sizes in the temporal dimension.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Guaus and P. Herrera, &quot;The rhythm transform: towards a generic
rhythm description,&quot; in International Computer Music Conference (ICMC’05),
2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RMS<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>rms</strong> (<em>real</em>) - the root mean square of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the Root Mean Square (quadratic mean) of an array of Reals.
RMS is not defined for empty arrays. In such case, an exception will be thrown
.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Root mean square - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Root_mean_square">http://en.wikipedia.org/wiki/Root_mean_square</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RollOff<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum (must have more than one elements)</li>
</td><td class="col-xs-2">
<li><strong>rollOff</strong> (<em>real</em>) - the roll-off frequency [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoff</strong> (<em>real ∈ (0, 1), default = 0.85</em>) :</dt>
<dd><p class="first last">the ratio of total energy to attain before yielding the roll-off frequency</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (used to normalize rollOff) [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the roll-off frequency of a spectrum. The roll-off frequency is defined as the frequency under which some percentage (cutoff) of the total energy of the spectrum is contained. The roll-off frequency can be used to distinguish between harmonic (below roll-off) and noisy sounds (above roll-off).</p>
<p>An exception is thrown if the input audio spectrum is smaller than 2.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SBic<br>[standard]

</th><td class="col-xs-2">
<li><strong>features</strong> (<em>matrix_real</em>) - extracted features matrix (rows represent features, and columns represent frames of audio)</li>
</td><td class="col-xs-2">
<li><strong>segmentation</strong> (<em>vector_real</em>) - a list of frame indices that indicate where a segment of audio begins/ends (the indices of the first and last frame are also added to the list at the beginning and end, respectively)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cpw</strong> (<em>real ∈ [0, ∞), default = 1.5</em>) :</dt>
<dd><p class="first last">complexity penalty weight</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inc1</strong> (<em>integer ∈ [1, ∞), default = 60</em>) :</dt>
<dd><p class="first last">first pass increment [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inc2</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">second pass increment [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minLength</strong> (<em>integer ∈ [1, ∞), default = 10</em>) :</dt>
<dd><p class="first last">minimum length of a segment [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>size1</strong> (<em>integer ∈ [1, ∞), default = 300</em>) :</dt>
<dd><p class="first last">first pass window size [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>size2</strong> (<em>integer ∈ [1, ∞), default = 200</em>) :</dt>
<dd><p class="first last">second pass window size [frames]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This descriptor segments the audio file into homogeneous portions using the Bayesian Information Criterion. The algorithm searches segments for which the feature vectors have the same probability distribution based on the implementation in [1]. The input matrix is assumed to have features along dim1 (horizontal) while frames along dim2 (vertical).</p>
<p>The segmentation is done in three phases: coarse segmentation, fine segmentation and segment validation. The first phase uses parameters 'size1' and 'inc1' to perform BIC segmentation. The second phase uses parameters 'size2' and 'inc2' to perform a local search for segmentation around the segmentation done by the first phase. Finally, the validation phase verifies that BIC differentials at segmentation points are positive as well as filters out any segments that are smaller than 'minLength'.</p>
<p>Because this algorithm takes as input feature vectors of frames, all units are in terms of frames. For example, if a 44100Hz audio signal is segmented as [0, 99, 199] with a frame size of 1024 and a hopsize of 512, this means, in the time domain, that the audio signal is segmented at [0s, 99*512/44100s, 199*512/44100s].</p>
<p>An exception is thrown if the input only contains one frame of features (i.e. second dimension is less than 2).</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Audioseg, <a class="reference external" href="http://audioseg.gforge.inria.fr">http://audioseg.gforge.inria.fr</a></p>
<p class="last">[2] G. Gravier, M. Betser, and M. Ben, Audio Segmentation Toolkit,
release 1.2, 2010. Available online:
<a class="reference external" href="https://gforge.inria.fr/frs/download.php/25187/audioseg-1.2.pdf">https://gforge.inria.fr/frs/download.php/25187/audioseg-1.2.pdf</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Scale<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the output audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>clipping</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">boolean flag whether to apply clipping or not</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>factor</strong> (<em>real ∈ [0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the multiplication factor by which the audio will be scaled</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxAbsValue</strong> (<em>real ∈ [0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum value above which to apply clipping</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm scales the audio by the specified factor, using clipping if required.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SilenceRate<br>[standard]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input frame</li>
</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>thresholds</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the threshold values</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a list of thresholds, this algorithm creates a equally-sized list of outputs and returns 1 on a given output whenever the instant power of the input frame is below the given output's respective threshold, and returns 0 otherwise. This is done for each frame with respect to all outputs. In other words, if a given frame's instant power is below several given thresholds, then each of the corresponding outputs will emit a 1.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SineModel<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must have more than 1 element)</li>
</td><td class="col-xs-2">
<li><strong>maxMagFreq</strong> (<em>real</em>) - the frequency with the largest magnitude [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the sine model without sine tracking.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SingleBeatLoudness<br>[standard]

</th><td class="col-xs-2">
<li><strong>beat</strong> (<em>vector_real</em>) - the sliced beat</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the beat's energy in the whole spectrum</li>
<li><strong>loudnessBandRatio</strong> (<em>vector_real</em>) - the beat's energy ratio on each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>beatDuration</strong> (<em>real ∈ (0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">the size of the window in which the beat will be restricted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beatWindowDuration</strong> (<em>real ∈ (0, ∞), default = 0.1</em>) :</dt>
<dd><p class="first last">the size of the window in which to look for the beginning of the beat [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [0, 200, 400, 800, 1600, 3200, 22000]</em>) :</dt>
<dd><p class="first last">the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>onsetStart</strong> (<em>string ∈ {sumEnergy,  peakEnergy}, default = sumEnergy</em>) :</dt>
<dd><p class="first last">criteria for finding the start of the beat</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the loudness of a single beat, on the whole frequency range and on each specified frequency band (bands by default: 0-200 Hz, 200-400 Hz, 400-800 Hz, 800-1600 Hz, 1600-3200 Hz, 3200-22000Hz, following E. Scheirer [1]). See the Loudness algorithm for a description of loudness.</p>
<p>This algorithm throws an exception either when parameter beatDuration is larger than beatWindowSize or when the size of the input beat is less than beatWindowSize plus beatDuration.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. D. Scheirer, &quot;Tempo and beat analysis of acoustic musical signals,&quot;
The Journal of the Acoustical Society of America, vol. 103, p. 588, 1998.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SingleGaussian<br>[standard]

</th><td class="col-xs-2">
<li><strong>matrix</strong> (<em>matrix_real</em>) - the input data matrix (e.g. the MFCC descriptor over frames)</li>
</td><td class="col-xs-2">
<li><strong>mean</strong> (<em>vector_real</em>) - the mean of the values</li>
<li><strong>covariance</strong> (<em>matrix_real</em>) - the covariance matrix</li>
<li><strong>inverseCovariance</strong> (<em>matrix_real</em>) - the inverse of the covariance matrix</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm implements the single gaussian method. For example, using the single gaussian on descriptors like MFCC with the symmetric Kullback-Leibler divergence might be a much better option than just the mean and variance of the descriptors over a whole signal.</p>
<p>An exception is thrown if the covariance of the input matrix is singular or if the input matrix is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Pampalk, &quot;Computational models of music similarity and their
application in music information retrieval,” Vienna University of
Technology, 2006.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Slicer<br>[standard]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_vector_real</em>) - the frames of the sliced input signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>endTimes</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of end times for the slices you want to extract</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTimes</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of start times for the slices you want to extract</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeUnits</strong> (<em>string ∈ {samples, seconds}, default = seconds</em>) :</dt>
<dd><p class="first last">the units of time of the start and end times</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns a vector of slices, which start and end times are given as parameters.</p>
<p>The parameters, &quot;startTimes&quot; and &quot;endTimes&quot; must be coherent. If these parameters differ in size, an exception is thrown. If a particular startTime is larger than its corresponding endTime, an exception is thrown.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralComplexity<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>spectralComplexity</strong> (<em>real</em>) - the spectral complexity of the input spectrum</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>real ∈ [0, ∞), default = 0.005</em>) :</dt>
<dd><p class="first last">the minimum spectral-peak magnitude that contributes to spectral complexity</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the spectral complexity of an spectrum of Reals. The spectral complexity is based on the number of peaks in the input spectrum.</p>
<p>It is recommended that the input &quot;spectrum&quot; be computed by the Spectrum algorithm. The input &quot;spectrum&quot; is passed to the SpectralPeaks algorithm and thus inherits its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] C. Laurier, O. Meyers, J. Serrà, M. Blech, P. Herrera, and X. Serra,
&quot;Indexing music by mood: design and integration of an automatic
content-based annotator,&quot; Multimedia Tools and Applications, vol. 48,
no. 1, pp. 161–184, 2009.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralContrast<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>spectralContrast</strong> (<em>vector_real</em>) - the spectral contrast coefficients</li>
<li><strong>spectralValley</strong> (<em>vector_real</em>) - the magnitudes of the valleys</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [2, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the size of the fft frames</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ (0, ∞), default = 11000</em>) :</dt>
<dd><p class="first last">the upper bound of the highest band</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the lower bound of the lowest band</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>neighbourRatio</strong> (<em>real ∈ (0, 1], default = 0.4</em>) :</dt>
<dd><p class="first last">the ratio of the bins in the sub band used to calculate the peak and valley</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ (0, ∞), default = 6</em>) :</dt>
<dd><p class="first last">the number of bands in the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>staticDistribution</strong> (<em>real ∈ [0, 1], default = 0.15</em>) :</dt>
<dd><p class="first last">the ratio of the bins to distribute equally</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The Spectral Contrast feature is based on the Octave Based Spectral Contrast feature as described in [1]. The version implemented here is a modified version to improve discriminative power and robustness. The modifications are described in [2].</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] D.-N. Jiang, L. Lu, H.-J. Zhang, J.-H. Tao, and L.-H. Cai, &quot;Music type
classification by spectral contrast feature,&quot; in IEEE International
Conference on Multimedia and Expo (ICME’02), 2002, vol. 1, pp. 113–116.</p>
<p class="last">[2] V. Akkermans, J. Serrà, and P. Herrera, &quot;Shape-based spectral contrast
descriptor,&quot; in Sound and Music Computing Conference (SMC’09), 2009,
pp. 143–148.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralPeaks<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">peaks below this given threshold are not outputted</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">the maximum frequency of the range to evaluate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxPeaks</strong> (<em>integer ∈ [1, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the maximum number of returned peaks</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the minimum frequency of the range to evaluate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>orderBy</strong> (<em>string ∈ {frequency, magnitude}, default = frequency</em>) :</dt>
<dd><p class="first last">the ordering type of the outputted peaks (ascending by frequency or descending by magnitude)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts peaks from a spectrum. It is important to note that the peak algorithm is independent of an input that is linear or in dB, so one has to adapt the threshold to fit with the type of data fed to it. The algorithm relies on PeakDetection algorithm which is run with parabolic interpolation [1]. The exactness of the peak-searching depends heavily on the windowing type. It gives best results with dB input, a blackman-harris 92dB window and interpolation set to true. According to [1], spectral peak frequencies tend to be about twice as accurate when dB magnitude is used rather than just linear magnitude. For further information about the peak detection, see the description of the PeakDetection algorithm.</p>
<p>It is recommended that the input &quot;spectrum&quot; be computed by the Spectrum algorithm. This algorithm uses PeakDetection. See documentation for possible exceptions and input requirements on input &quot;spectrum&quot;.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Peak Detection,
<a class="reference external" href="http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html">http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralWhitening<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio linear spectrum</li>
<li><strong>frequencies</strong> (<em>vector_real</em>) - the spectral peaks' linear frequencies</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the spectral peaks' linear magnitudes</li>
</td><td class="col-xs-2">
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the whitened spectral peaks' linear magnitudes</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">max frequency to apply whitening to [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Performs spectral whitening of spectral peaks of a given spectrum. The algorithm works in dB scale, but the conversion is done by the algorithm so input should be in linear scale. The concept of 'whitening' refers to 'white noise' or a non-zero flat spectrum. It first computes a spectral envelope similar to the 'true envelope' in [1], and then modifies the amplitude of each peak relative to the envelope. For example, the predominant peaks will have a value close to 0dB because they are very close to the envelope. On the other hand, minor peaks between significant peaks will have lower amplitudes such as -30dB.</p>
<p>The input &quot;frequencies&quot; and &quot;magnitudes&quot; can be computed using the SpectralPeaks algorithm.</p>
<p>An exception is thrown if the input frequency and magnitude input vectors are of different size.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] A. Röbel and X. Rodet, &quot;Efficient spectral envelope estimation and its
application to pitch shifting and envelope preservation,&quot; in International
Conference on Digital Audio Effects (DAFx’05), 2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Spectrum<br>[standard]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the magnitude spectrum of the input audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the expected size of the input audio signal (this is an optional parameter to optimize memory allocation)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm calculates the magnitude spectrum of an array of Reals. The resulting magnitude spectrum has a size which is half the size of the input array plus one.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Frequency spectrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Frequency_spectrum">http://en.wikipedia.org/wiki/Frequency_spectrum</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Spline<br>[standard]

</th><td class="col-xs-2">
<li><strong>x</strong> (<em>real</em>) - the input coordinate (x-axis)</li>
</td><td class="col-xs-2">
<li><strong>y</strong> (<em>real</em>) - the value of the spline at x</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>beta1</strong> (<em>real ∈ [0, ∞], default = 1</em>) :</dt>
<dd><p class="first last">the skew or bias parameter (only available for type beta)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beta2</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the tension parameter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {b, beta, quadratic}, default = b</em>) :</dt>
<dd><p class="first last">the type of spline to be computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>xPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the x-coordinates where data is specified (the points must be arranged in ascending order and cannot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>yPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the y-coordinates to be interpolated (i.e. the known data)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Evaluates a piecewise spline of type b, beta or quadratic.
The input value, i.e. the point at which the spline is to be evaluated typically should be between xPoins[0] and xPoinst[size-1]. If the value lies outside this range, extrapolation is used.
Regarding spline types:</p>
<blockquote>
<ul class="simple">
<li>B: evaluates a cubic B spline approximant.</li>
<li>Beta: evaluates a cubic beta spline approximant. For beta splines parameters 'beta1' and 'beta2' can be supplied. For no bias set beta1 to 1 and for no tension set beta2 to 0. Note that if beta1=1 and beta2=0, the cubic beta becomes a cubic B spline. On the other hand if beta1=1 and beta2 is large the beta spline turns into a linear spline.</li>
<li>Quadratic: evaluates a piecewise quadratic spline at a point. Note that size of input must be odd.</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Spline interpolation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Spline_interpolation">http://en.wikipedia.org/wiki/Spline_interpolation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StartStopSilence<br>[standard]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frames</li>
</td><td class="col-xs-2">
<li><strong>startFrame</strong> (<em>integer</em>) - number of the first non-silent frame</li>
<li><strong>stopFrame</strong> (<em>integer</em>) - number of the last non-silent frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>integer ∈ (-∞, 0]), default = -60</em>) :</dt>
<dd><p class="first last">the threshold below which average energy is defined as silence [dB]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs the frame at which sound begins and the frame at which sound ends.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StereoDemuxer<br>[standard]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>vector_stereosample</em>) - the audio signal</li>
</td><td class="col-xs-2">
<li><strong>left</strong> (<em>vector_real</em>) - the left channel of the audio signal</li>
<li><strong>right</strong> (<em>vector_real</em>) - the right channel of the audio signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>Given a stereo signal, this algorithm outputs left and right channel separately.If the signal is monophonic, it outputs a zero signal on the right channel.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StrongDecay<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>strongDecay</strong> (<em>real</em>) - the strong decay</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the Strong Decay of an audio signal. The Strong Decay is built from the non-linear combination of the signal energy and the signal temporal centroid, the latter being the balance of the absolute value of the signal. A signal containing a temporal centroid near its start boundary and a strong energy is said to have a strong decay.</p>
<p>This algorithm is not defined for zero signals (i.e. silence) nor when the signal's size is less than two, as it could not compute its centroid.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] F. Gouyon and P. Herrera, &quot;Exploration of techniques for automatic
labeling of audio drum tracks instruments,&quot; in MOSART: Workshop on Current
Directions in Computer Music, 2001.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StrongPeak<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must be greater than one element and cannot contain negative values)</li>
</td><td class="col-xs-2">
<li><strong>strongPeak</strong> (<em>real</em>) - the Strong Peak ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the Strong Peak from an audio spectrum. The Strong Peak is defined as the ratio between the spectrum's maximum peak's magnitude and the &quot;bandwidth&quot; of the peak above a threshold (half its amplitude). This ratio reveals whether the spectrum presents a very &quot;pronounced&quot; maximum peak (i.e. the thinner and the higher the maximum of the spectrum is, the higher the ratio value).</p>
<p>Note that &quot;bandwidth&quot; is defined as the width of the peak in the log10-frequency domain. This is different than as implemented in [1]. Using the log10-frequency domain allows this algorithm to compare strong peaks at lower frequencies with those from higher frequencies.</p>
<p>An exception is thrown if the input spectrum contains less than two elements.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] F. Gouyon and P. Herrera, &quot;Exploration of techniques for automatic
labeling of audio drum tracks instruments,” in MOSART: Workshop on Current
Directions in Computer Music, 2001.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SuperFluxExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>onsets</strong> (<em>vector_real</em>) - the onsets times</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>combine</strong> (<em>real ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">time threshold for double onsets detections(ms)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>ratioThreshold</strong> (<em>real ∈ [0, ∞), default = 16</em>) :</dt>
<dd><p class="first last">ratio threshold for peak-picking compared to novelty_signal/novelty_average, 0  disable it ,  for low energy onsets</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">threshold for peak peaking compared to the difference of novelty_signal and average_signal ,  for peaking onsets in ambien noise</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm extracts onsets from audio file following SuperFlux algorithm [1] adapted from python code available in [2]</dt>
<dd>[1] &quot;Maximum Filter Vibrato Suppression for Onset Detection&quot; by Sebastian Böck and Gerhard Widmer in Proceedings of the 16th International Conference on Digital Audio Effects (DAFx-13), Maynooth, Ireland, September 2013                                                       [2] <a class="reference external" href="https://github.com/CPJKU/SuperFlux/">https://github.com/CPJKU/SuperFlux/</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SuperFluxNovelty<br>[standard]

</th><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_vector_real</em>) - the input bands spectrogram</li>
</td><td class="col-xs-2">
<li><strong>Differences</strong> (<em>real</em>) - SuperFluxNovelty input</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binWidth</strong> (<em>integer ∈ [3, ∞), default = 3</em>) :</dt>
<dd><p class="first last">height(n of frequency bins) of the SuperFluxNoveltyFilter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameWidth</strong> (<em>integer ∈ (0, ∞), default = 2</em>) :</dt>
<dd><p class="first last">differenciate with the N-th previous frame</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Novelty curve from Superflux algorithm (see SuperFluxExtractor for references)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SuperFluxPeaks<br>[standard]

</th><td class="col-xs-2">
<li><strong>novelty</strong> (<em>vector_real</em>) - the input novelty</li>
</td><td class="col-xs-2">
<li><strong>peaks</strong> (<em>vector_real</em>) - the input novelty</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>combine</strong> (<em>real ∈ (0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">ms for onset combination</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ (0, ∞), default = 172</em>) :</dt>
<dd><p class="first last">frameRate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pre_avg</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">use N miliseconds past information for moving average</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pre_max</strong> (<em>real ∈ (0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">use N miliseconds past information for moving maximum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>ratioThreshold</strong> (<em>real ∈ [0, ∞), default = 16</em>) :</dt>
<dd><p class="first last">ratio threshold for peak-picking compared to novelty_signal/novelty_average, 0  disable it ,  for low energy onsets</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">threshold for peak peaking compared to the difference of novelty_signal and average_signal ,  for peaking onsets in ambien noise</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Peak peaking from Superflux algorithm (see SuperFluxExtractor for references)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TCToTotal<br>[standard]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>vector_real</em>) - the envelope of the signal (its length must be greater than 1</li>
</td><td class="col-xs-2">
<li><strong>TCToTotal</strong> (<em>real</em>) - the temporal centroid to total length ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the ratio of the temporal centroid to the total length of a signal envelope. This ratio shows how the sound is 'balanced'. Its value is close to 0 if most of the energy lies at the beginning of the sound (e.g. decrescendo or impulsive sounds), close to 0.5 if the sound is symetric (e.g. 'delta unvarying' sounds), and close to 1 if most of the energy lies at the end of the sound (e.g. crescendo sounds).</p>
<p>Please note that the TCToTotal ratio is not defined for a zero signal (a signal consisting of only zeros), nor it is defined for a signal of less than 2 elements.An exception is thrown if the given envelope's size is not larger than 1. And also if the integral of the input envelope is 0 (i.e. envelope is only zeros or if its sum is 0).</p>
<p>This algorithm is intended to be plugged after the Envelope algorithm</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoScaleBands<br>[standard]

</th><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the audio power spectrum divided into bands</li>
</td><td class="col-xs-2">
<li><strong>scaledBands</strong> (<em>vector_real</em>) - the output bands after scaling</li>
<li><strong>cumulativeBands</strong> (<em>real</em>) - cumulative sum of the output bands before scaling</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandsGain</strong> (<em>vector_real, default = [2, 3, 2, 1, 1.20000004768, 2, 3, 2.5]</em>) :</dt>
<dd><p class="first last">gain for each bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameTime</strong> (<em>real ∈ (0, ∞), default = 512</em>) :</dt>
<dd><p class="first last">the frame rate in samples</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes features for tempo tracking. The output features should be used with the TempoTap algorithm. See standard_rhythmextractor_tempotap in examples folder.</p>
<p>An exception is thrown if less than 1 band is given. An exception is also thrown if the there are not an equal number of bands given as band-gains given.</p>
<p>Quality: outdated (the associated TempoTap algorithm is outdated, however it can be potentially used as an onset detection function for other tempo estimation algorithms although no evaluation has been done)</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Algorithm by Fabien Gouyon and Simon Dixon. There is no reference at
the time of this writing.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTap<br>[standard]

</th><td class="col-xs-2">
<li><strong>featuresFrame</strong> (<em>vector_real</em>) - input temporal features of a frame</li>
</td><td class="col-xs-2">
<li><strong>periods</strong> (<em>vector_real</em>) - list of tempo estimates found for each input feature, in frames</li>
<li><strong>phases</strong> (<em>vector_real</em>) - list of initial phase candidates found for each input feature, in frames</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameHop</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">number of feature frames separating two evaluations</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">number of audio samples in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">fastest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">slowest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberFrames</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">number of feature frames to buffer on</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tempoHints</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">optional list of initial beat locations, to favor the detection of pre-determined tempo period and beats alignment [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the periods and phases of a periodic signal, represented by a sequence of values of any number of detection functions, such as energy bands, onsets locations, etc. It requires to be sequentially run on a vector of such values (&quot;featuresFrame&quot;) for each particular audio frame in order to get estimations related to that frames. The estimations are done for each detection function separately, utilizing the latest &quot;frameHop&quot; frames, including the present one, to compute autocorrelation. Empty estimations will be returned until enough frames are accumulated in the algorithm's buffer.
The algorithm uses elements of the following beat-tracking methods:</p>
<blockquote>
<ul class="simple">
<li>BeatIt, elaborated by Fabien Gouyon and Simon Dixon (input features) [1]</li>
<li>Multi-comb filter with Rayleigh weighting, Mathew Davies [2]</li>
</ul>
</blockquote>
<p>Parameter &quot;maxTempo&quot; should be 20bpm larger than &quot;minTempo&quot;, otherwise an exception is thrown. The same applies for parameter &quot;frameHop&quot;, which should not be greater than numberFrames. If the supplied &quot;tempoHints&quot; did not match any realistic bpm value, an exeception is thrown.</p>
<p>This algorithm is thought to provide the input for TempoTapTicks algorithm. The &quot;featureFrame&quot; vectors can be formed by Multiplexer algorithm in the case of combining different features.</p>
<p>Quality: outdated (use TempoTapDegara instead)</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] F. Gouyon, &quot;A computational approach to rhythm description: Audio
features for the computation of rhythm periodicity functions and their use
in tempo induction and music content processing,&quot; UPF, Barcelona, Spain,
2005.</p>
<p class="last">[2] M. Davies and M. Plumbley, &quot;Causal tempo tracking of audio,&quot; in
International Symposium on Music Information Retrieval (ISMIR'04), 2004.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTapDegara<br>[standard]

</th><td class="col-xs-2">
<li><strong>onsetDetections</strong> (<em>vector_real</em>) - the input frame-wise vector of onset detection values</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) - the list of resulting ticks [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">fastest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">slowest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>resample</strong> (<em>string ∈ {none, x2, x3, x4}, default = none</em>) :</dt>
<dd><p class="first last">use upsampling of the onset detection function (may increase accuracy)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRateODF</strong> (<em>real ∈ (0, ∞), default = 86.1328</em>) :</dt>
<dd><p class="first last">the sampling rate of the onset detection function [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates beat positions given an onset detection function.  The detection function is partitioned into 6-second frames with a 1.5-second increment, and the autocorrelation is computed for each frame, and is weighted by a tempo preference curve [2]. Periodicity estimations are done frame-wisely, searching for the best match with the Viterbi algorith [3]. The estimated periods are then passed to the probabilistic beat tracking algorithm [1], which computes beat positions.</p>
<p>Note that the input values of the onset detection functions must be non-negative otherwise an exception is thrown. Parameter &quot;maxTempo&quot; should be 20bpm larger than &quot;minTempo&quot;, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Degara, N., Rua, E. A., Pena, A., Torres-Guijarro, S., Davies, M. E., &amp; Plumbley, M. D. (2012). Reliability-informed beat tracking of musical signals. Audio, Speech, and Language Processing, IEEE Transactions on, 20(1), 290-301.
[2] Davies, M. E., &amp; Plumbley, M. D. (2007). Context-dependent beat tracking of musical audio. Audio, Speech, and Language Processing, IEEE Transactions on, 15(3), 1009-1020.
[3] Stark, A. M., Davies, M. E., &amp; Plumbley, M. D. (2009, September). Real-time beatsynchronous analysis of musical audio. In 12th International Conference on Digital Audio Effects (DAFx-09), Como, Italy.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTapMaxAgreement<br>[standard]

</th><td class="col-xs-2">
<li><strong>tickCandidates</strong> (<em>vector_vector_real</em>) - the tick candidates estimated using different beat trackers (or features) [s]</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) - the list of resulting ticks [s]</li>
<li><strong>confidence</strong> (<em>real</em>) - confidence with which the ticks were detected [0, 5.32]</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm estimates beat positions and confidence of their estimation based on the maximum mutual agreement between given beat postion candidates, estimated by different beat trackers (or using different features) [1,2].</p>
<p>Note that the input tick times should be in ascending order and that they cannot contain negative values otherwise an exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. R. Zapata, A. Holzapfel, M. E. Davies, J. L. Oliveira, and
F. Gouyon, &quot;Assigning a confidence threshold on automatic beat annotation
in large datasets,&quot; in International Society for Music Information
Retrieval Conference (ISMIR’12), 2012.</p>
<p class="last">[2] A. Holzapfel, M. E. Davies, J. R. Zapata, J. L. Oliveira, and
F. Gouyon, &quot;Selective sampling for beat tracking evaluation,&quot; IEEE
Transactions on Audio, Speech, and Language Processing, vol. 13, no. 9,
pp. 2539-2548, 2012.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTapTicks<br>[standard]

</th><td class="col-xs-2">
<li><strong>periods</strong> (<em>vector_real</em>) - tempo period candidates for the current frame, in frames</li>
<li><strong>phases</strong> (<em>vector_real</em>) - tempo ticks phase candidates for the current frame, in frames</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) - the list of resulting ticks [s]</li>
<li><strong>matchingPeriods</strong> (<em>vector_real</em>) - list of matching periods [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameHop</strong> (<em>integer ∈ (0, ∞), default = 512</em>) :</dt>
<dd><p class="first last">number of feature frames separating two evaluations</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">number of audio samples per features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm builds the list of ticks from the period and phase candidates given by the TempoTap algorithm.</p>
<p>Quality: outdated (use TempoTapDegara instead)</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] F. Gouyon, &quot;A computational approach to rhythm description: Audio
features for the computation of rhythm periodicity functions and their use
in tempo induction and music content processing,&quot; UPF, Barcelona, Spain,
2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TonalExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>chords_changes_rate</strong> (<em>real</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_histogram</strong> (<em>vector_real</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_key</strong> (<em>string</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_number_rate</strong> (<em>real</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_progression</strong> (<em>vector_string</em>) - See ChordsDetection algorithm documentation</li>
<li><strong>chords_scale</strong> (<em>string</em>) - See ChordsDetection algorithm documentation</li>
<li><strong>chords_strength</strong> (<em>vector_real</em>) - See ChordsDetection algorithm documentation</li>
<li><strong>hpcp</strong> (<em>vector_vector_real</em>) - See HPCP algorithm documentation</li>
<li><strong>hpcp_highres</strong> (<em>vector_vector_real</em>) - See HPCP algorithm documentation</li>
<li><strong>key_key</strong> (<em>string</em>) - See Key algorithm documentation</li>
<li><strong>key_scale</strong> (<em>string</em>) - See Key algorithm documentation</li>
<li><strong>key_strength</strong> (<em>real</em>) - See Key algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 4096</em>) :</dt>
<dd><p class="first last">the framesize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hopsize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tuningFrequency</strong> (<em>real ∈ (0, ∞), default = 440</em>) :</dt>
<dd><p class="first last">the tuning frequency of the input signal</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts tonal features</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TonicIndianArtMusic<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>tonic</strong> (<em>real</em>) - the estimated tonic frequency [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.85</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 512</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>real ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxTonicFrequency</strong> (<em>real ∈ [0, ∞), default = 375</em>) :</dt>
<dd><p class="first last">the maximum allowed tonic frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTonicFrequency</strong> (<em>real ∈ [0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed tonic frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered hamonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberSaliencePeaks</strong> (<em>integer ∈ [1,  15], default = 5</em>) :</dt>
<dd><p class="first last">number of top peaks of the salience function which should be considered for constructing histogram</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the tonic frequency of the lead artist in Indian art music. It uses multipitch representation of the audio signal (pitch salience) to compute a histogram using which the tonic is identified as one of its peak. The decision is made based on the distance between the prominent peaks, the classification is done using a decision tree.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon, S. Gulati, and X. Serra, &quot;A Multipitch Approach to Tonic
Identification in Indian Classical Music,&quot; in International Society for
Music Information Retrieval Conference (ISMIR’12), 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TriangularBands<br>[standard]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must be greater than size one)</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy in each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [21.533203125, 43.06640625, 64.599609375, 86.1328125, 107.666015625, 129.19921875, 150.732421875, 172.265625, 193.798828125, 215.33203125, 236.865234375, 258.3984375, 279.931640625, 301.46484375, 322.998046875, 344.53125, 366.064453125, 387.59765625, 409.130859375, 430.6640625, 452.197265625, 473.73046875, 495.263671875, 516.796875, 538.330078125, 559.86328125, 581.396484375, 602.9296875, 624.462890625, 645.99609375, 667.529296875, 689.0625, 710.595703125, 732.12890625, 753.662109375, 775.1953125, 796.728515625, 839.794921875, 861.328125, 882.861328125, 904.39453125, 925.927734375, 968.994140625, 990.52734375, 1012.06054688, 1055.12695312, 1076.66015625, 1098.19335938, 1141.25976562, 1184.32617188, 1205.859375, 1248.92578125, 1270.45898438, 1313.52539062, 1356.59179688, 1399.65820312, 1442.72460938, 1485.79101562, 1528.85742188, 1571.92382812, 1614.99023438, 1658.05664062, 1701.12304688, 1765.72265625, 1808.7890625, 1873.38867188, 1916.45507812, 1981.0546875, 2024.12109375, 2088.72070312, 2153.3203125, 2217.91992188, 2282.51953125, 2347.11914062, 2411.71875, 2497.8515625, 2562.45117188, 2627.05078125, 2713.18359375, 2799.31640625, 2885.44921875, 2950.04882812, 3036.18164062, 3143.84765625, 3229.98046875, 3316.11328125, 3423.77929688, 3509.91210938, 3617.578125, 3725.24414062, 3832.91015625, 3940.57617188, 4069.77539062, 4177.44140625, 4306.640625, 4435.83984375, 4565.0390625, 4694.23828125, 4844.97070312, 4974.16992188, 5124.90234375, 5275.63476562, 5426.3671875, 5577.09960938, 5749.36523438, 5921.63085938, 6093.89648438, 6266.16210938, 6459.9609375, 6653.75976562, 6847.55859375, 7041.35742188, 7256.68945312, 7450.48828125, 7687.35351562, 7902.68554688, 8139.55078125, 8376.41601562, 8613.28125, 8871.6796875, 9130.078125, 9388.4765625, 9668.40820312, 9948.33984375, 10249.8046875, 10551.2695312, 10852.734375, 11175.7324219, 11498.7304688, 11843.2617188, 12187.7929688, 12553.8574219, 12919.921875, 13285.9863281, 13673.5839844, 14082.7148438, 14491.8457031, 14922.5097656, 15353.1738281, 15805.3710938, 16257.5683594]</em>) :</dt>
<dd><p class="first last">list of frequency ranges into which the spectrum is divided (these must be in ascending order and connot contain duplicates),each triangle is build as x(i-1)=, x(i)=1, x(i+1)=0 over i, the resulting number of bands is size of input array - 2</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>log</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">taking log10 (1 + magnitude) in each band</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the energy of an input spectrum for an arbitrary number of overlapping Triangular frequency bands. For each band the power-spectrum (mag-squared) is summed.</p>
<p>Parameter &quot;TriangularBands&quot; must contain at least 2 frequencies, they all must be positive and must be ordered ascentdantly, otherwise an exception will be thrown. TriangularBands is only defined for spectrum, which size is greater than 1.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Trimmer<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the trimmed signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>endTime</strong> (<em>real ∈ [0, ∞), default = 1e+06</em>) :</dt>
<dd><p class="first last">the end time of the slice you want to extract [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the input audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTime</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start time of the slice you want to extract [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio signal, this algorithm it extracts a slice of the signal between startTime and endTime.
Giving &quot;startTime&quot; greater than &quot;endTime&quot; will raise an exception.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Tristimulus<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the harmonic peaks ordered by frequency</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the harmonic peaks ordered by frequency</li>
</td><td class="col-xs-2">
<li><strong>tristimulus</strong> (<em>vector_real</em>) - a three-element vector that measures the mixture of harmonics of the given spectrum</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the tristimulus of a signal given its harmonic peaks. The tristimulus has been introduced as a timbre equivalent to the color attributes in the vision. The tristimulus is composed of three different types of energy ratio allowing for a fine-grained description of the first harmonic of the spectrum, which are perceptually more salient.</p>
<p>Tristimulus is intended to be fed by the output of the HarmonicPeaks algorithm. The algorithm throws an exception when the input frequencies are not in ascending order and/or if the input vectors are of different sizes.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Tristimulus (audio) - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Tristimulus_(audio">http://en.wikipedia.org/wiki/Tristimulus_(audio</a>)</p>
<p class="last">[2] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TuningFrequency<br>[standard]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><strong>tuningFrequency</strong> (<em>real</em>) - the tuning frequency [Hz]</li>
<li><strong>tuningCents</strong> (<em>real</em>) - the deviation from 440 Hz (between -35 to 65 cents)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>resolution</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">resolution in cents (logarithmic scale, 100 cents = 1 semitone) for tuning frequency determination</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a sequence/set of spectral peaks, this algorithm estimates the tuning frequency of a given song. The result is the tuning frequency in Hz, and its distance from 440Hz in cents. This version is slightly adapted from the original algorithm by Emilia Gomez, but gives the same results.</p>
<p>Input vectors should have the same size, otherwise an exception is thrown. This algorithm should be given the outputs of the spectral peaks algorithm.</p>
<p>Application: Western vs non-western music classification, key estimation, HPCP computation, tonal similarity.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Gómez, &quot;Key estimation from polyphonic audio,&quot; in Music Information
Retrieval Evaluation Exchange (MIREX’05), 2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TuningFrequencyExtractor<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>tuningFrequency</strong> (<em>vector_real</em>) - the computed tuning frequency</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 4096</em>) :</dt>
<dd><p class="first last">the frameSize for computing tuning frequency</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hopsize for computing tuning frequency</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts the tuning frequency of an audio signal</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
UnaryOperator<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array transformed by unary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {identity, abs, log10, log, ln, lin2db, db2lin, sin, cos, sqrt, square}, default = identity</em>) :</dt>
<dd><p class="first last">the type of the unary operator to apply to input array</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a vector of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>log and ln are equivalent to the natural logarithm</li>
<li>for log, ln, log10 and lin2db, x is clipped to 1e-30 for x&lt;1e-30</li>
<li>for x&lt;0, sqrt(x) is invalid</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
UnaryOperatorStream<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array transformed by unary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>scale</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">multiply result by factor</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>shift</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">shift result by value (add value)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {identity, abs, log10, log, ln, lin2db, db2lin, sin, cos, sqrt, square}, default = identity</em>) :</dt>
<dd><p class="first last">the type of the unary operator to apply to input array</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a vector of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>log and ln are equivalent to the natural logarithm</li>
<li>for log, ln, log10 and lin2db, x is clipped to 1e-30 for x&lt;1e-30</li>
<li>for x&lt;0, sqrt(x) is invalid</li>
<li>scale and shift parameters define linear transformation to be applied to the resulting elements</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Variance<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>variance</strong> (<em>real</em>) - the variance of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the variance of an array of Reals.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Vibrato<br>[standard]

</th><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the pitch trajectory [Hz].</li>
</td><td class="col-xs-2">
<li><strong>vibratoFrequency</strong> (<em>vector_real</em>) - estimated vibrato frquency [Hz]; zero if no vibrato was detected.</li>
<li><strong>vibratoExtend</strong> (<em>vector_real</em>) - estimated vibrato frquency [Hz]; zero if no vibrato was detected.</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxExtend</strong> (<em>real ∈ (0, ∞), default = 250</em>) :</dt>
<dd><p class="first last">maximum considered vibrato extend [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 8</em>) :</dt>
<dd><p class="first last">maximum considered vibrato frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minExtend</strong> (<em>real ∈ (0, ∞), default = 50</em>) :</dt>
<dd><p class="first last">minimum considered vibrato extend [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">minimum considered vibrato frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 344.531</em>) :</dt>
<dd><p class="first last">sample rate of the input pitch contour</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a pitch contour [Hz], this algorithm detects the presence of vibrato and estimates the corresponding parameters. The result is the vibrato frequency in Hz and the extend (peak to peak) in cents. If no vibrato is detected in a frame, the output of both values is zero.</p>
<p>This algorithm should be given the outputs of a pitch estimator, i.e. PredominantMelody, PitchYinFFT or PitchMelodia and the corresponding sample rate with which it was computed.</p>
<p>The algorithm is an extended version of the vocal vibrato detection in PerdominantMelody.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
WarpedAutoCorrelation<br>[standard]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the array to be analyzed</li>
</td><td class="col-xs-2">
<li><strong>warpedAutoCorrelation</strong> (<em>vector_real</em>) - the warped auto-correlation vector</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxLag</strong> (<em>integer ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum lag for which the auto-correlation is computed (inclusive) (must be smaller than signal size)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the warped auto-correlation of an audio signal. The implementation is an adapted version of K. Schmidt's implementation of the matlab algorithm from the 'warped toolbox' by Aki Harma and Matti Karjalainen found [2]. For a detailed explanation of the algorithm, see [1].
This algorithm is only defined for positive lambda = 1.0674*sqrt(2.0*atan(0.00006583*sampleRate)/PI) - 0.1916, thus it will throw an exception when the supplied sampling rate does not pass the requirements.
If maxLag is larger than the size of the input array, an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] A. Härmä, M. Karjalainen, L. Savioja, V. Välimäki, U. K. Laine, and
J. Huopaniemi, &quot;Frequency-Warped Signal Processing for Audio Applications,&quot;
JAES, vol. 48, no. 11, pp. 1011–1031, 2000.</p>
<p class="last">[2] WarpTB - Matlab Toolbox for Warped DSP
<a class="reference external" href="http://www.acoustics.hut.fi/software/warp">http://www.acoustics.hut.fi/software/warp</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Windowing<br>[standard]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the windowed audio frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [2, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the window size</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {hamming, hann, triangular, square, blackmanharris62, blackmanharris70, blackmanharris74, blackmanharris92}, default = hann</em>) :</dt>
<dd><p class="first last">the window type, which can be 'hamming', 'hann', 'triangular', 'square' or 'blackmanharrisXX'</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>zeroPadding</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the size of the zero-padding</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>zeroPhase</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">a boolean value that enables zero-phase windowing</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm applies windowing to audio signals.
It optionally applies zero-phase windowing and optionally adds zero-padding.
The resulting windowed frame size is equal to the incoming frame size plus the number of padded zeros.
The available windows are normalized (to have an area of 1) and then scaled by a factor of 2.</p>
<p>An exception is thrown if the size of the frame is less than 2.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] F. J. Harris, &quot;On the use of windows for harmonic analysis with the
discrete Fourier transform, Proceedings of the IEEE, vol. 66, no. 1,
pp. 51-83, Jan. 1978</p>
<p class="last">[2] Window function - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Window_function">http://en.wikipedia.org/wiki/Window_function</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
YamlInput<br>[standard]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>pool</strong> (<em>pool</em>) - Pool of deserialized values</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">Input filename</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>format</strong> (<em>string ∈ {json, yaml}, default = yaml</em>) :</dt>
<dd><p class="first last">whether to the input file is in JSON or YAML format</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm deserializes a file formatted in YAML to a Pool. This file can be serialized back into a YAML file using the YamlOutput algorithm. See the documentation for YamlOutput for more information on the specification of the YAML file.</p>
<p>Note: If an empty sequence is encountered (i.e. &quot;[]&quot;), this algorithm will assume it was intended to be a sequence of Reals and will add it to the output pool accordingly. This only applies to sequences which contain empty sequences. Empty sequences (which are not subsequences) are not possible in a Pool and therefore will be ignored if encountered (i.e. foo: [] (ignored), but foo: [[]] (added as a vector of one empty vector of reals).</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
YamlOutput<br>[standard]

</th><td class="col-xs-2">
<li><strong>pool</strong> (<em>pool</em>) - Pool to serialize into a YAML formatted file</li>
</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>doubleCheck</strong> (<em>bool, default = false</em>) :</dt>
<dd><p class="first last">whether to double-check if the file has been correctly written to the disk</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string, default = -</em>) :</dt>
<dd><p class="first last">output filename (use '-' to emit to stdout)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>format</strong> (<em>string ∈ {json, yaml}, default = yaml</em>) :</dt>
<dd><p class="first last">whether to output data in JSON or YAML format</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>indent</strong> (<em>integer, default = 4</em>) :</dt>
<dd><p class="first last">(json only) how many characters to indent each line, or 0 for no newlines</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>writeVersion</strong> (<em>bool, default = true</em>) :</dt>
<dd><p class="first last">whether to write the essentia version to the output file</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm emits a YAML or JSON representation of a Pool.</p>
<p>Each descriptor key in the Pool is decomposed into different nodes of the YAML (JSON) format by splitting on the '.' character. For example a Pool that looks like this:</p>
<blockquote>
foo.bar.some.thing: [23.1, 65.2, 21.3]</blockquote>
<p>will be emitted as:</p>
<blockquote>
<dl class="docutils">
<dt>metadata:</dt>
<dd><dl class="first last docutils">
<dt>essentia:</dt>
<dd>version: &lt;version-number&gt;</dd>
</dl>
</dd>
<dt>foo:</dt>
<dd><dl class="first last docutils">
<dt>bar:</dt>
<dd><dl class="first last docutils">
<dt>some:</dt>
<dd>thing: [23.1, 65.2, 21.3]</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ZeroCrossingRate<br>[standard]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>zeroCrossingRate</strong> (<em>real</em>) - the zero-crossing rate</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [0, ∞], default = 0</em>) :</dt>
<dd><p class="first last">the threshold which will be taken as the zero axis in both positive and negative sign</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the zero-crossing rate of an audio signal. It is the number of sign changes between consecutive signal values divided by the total number of values. Noisy signals tend to have higher zero-crossing rate.
In order to avoid small variations around zero caused by noise, a threshold around zero is given to consider a valid zerocrosing whenever the boundary is crossed.</p>
<p>Empty input signals will raise an exception.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Zero Crossing - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Zero-crossing_rate">http://en.wikipedia.org/wiki/Zero-crossing_rate</a></p>
<p class="last">[2] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AfterMaxToBeforeMaxEnergyRatio<br>[streaming]

</th><td class="col-xs-2">
<li><strong>pitch</strong> (<em>real</em>) - the array of pitch values [Hz]</li>
</td><td class="col-xs-2">
<li><strong>afterMaxToBeforeMaxEnergyRatio</strong> (<em>real</em>) - the ratio between the pitch energy after the pitch maximum to the pitch energy                   before the pitch maximum</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the ratio between the pitch energy after the pitch maximum and the pitch energy before the pitch maximum. Sounds having an monotonically ascending pitch or one unique pitch will show a value of (0,1], while sounds having a monotonically descending pitch will show a value of [1,∞). In case there is no energy before the max pitch, the algorithm will return the energy after the maximum pitch.</p>
<p>The algorithm throws exception when input is either empty or contains only zeros.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AllPass<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandwidth</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the bandwidth of the filter [Hz] (used only for 2nd-order filters)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>order</strong> (<em>integer ∈ {1, 2}, default = 1</em>) :</dt>
<dd><p class="first last">the order of the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a IIR all-pass filter of order 1 or 2. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, p. 43,
John Wiley &amp; Sons, 2002</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AudioLoader<br>[streaming]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>stereosample</em>) - the input audio signal</li>
<li><strong>sampleRate</strong> (<em>real</em>) - the sampling rate of the audio signal [Hz]</li>
<li><strong>numberChannels</strong> (<em>integer</em>) - the number of channels</li>
<li><strong>md5</strong> (<em>string</em>) - the MD5 checksum of raw undecoded audio payload</li>
<li><strong>bit_rate</strong> (<em>integer</em>) - the bit rate of the input audio, as reported by the decoder codec</li>
<li><strong>codec</strong> (<em>string</em>) - the codec that is used to decode the input audio</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>computeMD5</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">compute the MD5 checksum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file this algorithm loads an audio file and outputs the raw signal data, the samplerate and the number of channels. Supported formats are: wav, aiff, flac (not supported on Windows), ogg and mp3.</p>
<p>This algorithm will throw an exception if it hasn't been properly configured which normally is due to not specifying a valid filename. Invalid names comprise those with extensions different than the supported  formats and non existent files.
Note: ogg files are decoded in reverse phase, due to be using ffmpeg library.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] WAV - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Wav">http://en.wikipedia.org/wiki/Wav</a></dd>
<dt>[2] Audio Interchange File Format - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Aiff">http://en.wikipedia.org/wiki/Aiff</a></dd>
<dt>[3] Free Lossless Audio Codec - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Flac">http://en.wikipedia.org/wiki/Flac</a></dd>
<dt>[4] Vorbis - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Vorbis">http://en.wikipedia.org/wiki/Vorbis</a></dd>
<dt>[5] MP3 - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Mp3">http://en.wikipedia.org/wiki/Mp3</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AudioOnsetsMarker<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal mixed with bursts at onset locations</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>onsets</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of onset locations [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the output signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {beep, noise}, default = beep</em>) :</dt>
<dd><p class="first last">the type of sound to be added on the event</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm creates a wave file in which a given audio signal is mixed with a series of time onsets. The sonification of the onsets can be heard as beeps, or as short white noise pulses if configured to do so.</p>
<p>This algorithm will throw an exception if parameter &quot;filename&quot; is not supplied</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AudioWriter<br>[streaming]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>stereosample</em>) - the input audio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bitrate</strong> (<em>integer ∈ {32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160, 192, 224, 256, 320}, default = 192</em>) :</dt>
<dd><p class="first last">the audio bit rate for compressed formats [kbps]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the encoded file</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>format</strong> (<em>string ∈ {wav, aiff, mp3, ogg, flac}, default = wav</em>) :</dt>
<dd><p class="first last">the audio output format</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm encodes an input signal into a stereo audio file.</p>
<p>Supported formats are wav, aiff, mp3, flac and ogg.</p>
<p>An exception is thrown when other extensions are given. Note that to encode in mp3 format it is mandatory that ffmpeg was configured with mp3 enabled.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
AutoCorrelation<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the array to be analyzed</li>
</td><td class="col-xs-2">
<li><strong>autoCorrelation</strong> (<em>vector_real</em>) - the autocorrelation vector</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>normalization</strong> (<em>string ∈ {standard, unbiased}, default = standard</em>) :</dt>
<dd><p class="first last">type of normalization to compute: either 'standard' (default) or 'unbiased'</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the autocorrelation vector of a signal.
It uses the version most commonly used in signal processing, which doesn't remove the mean from the observations.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Autocorrelation -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/Autocorrelation.html">http://mathworld.wolfram.com/Autocorrelation.html</a></p>
<p class="last">[2] Autocorrelation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Autocorrelation">http://en.wikipedia.org/wiki/Autocorrelation</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BandPass<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandwidth</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the bandwidth of the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 2nd order IIR band-pass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, 2nd edition, p. 55,
John Wiley &amp; Sons, 2011</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BandReject<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandwidth</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the bandwidth of the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 2nd order IIR band-reject filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, 2nd edition, p. 55,
John Wiley &amp; Sons, 2011</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BarkBands<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy of the bark bands</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ [1, 28], default = 27</em>) :</dt>
<dd><p class="first last">the number of desired barkbands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ [0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the spectral energy contained in a given number of bands, which correspond to an extrapolation of the Bark band scale [1]:
[0.0, 50.0, 100.0, 150.0, 200.0, 300.0, 400.0, 510.0, 630.0, 770.0, 920.0, 1080.0, 1270.0, 1480.0, 1720.0, 2000.0, 2320.0, 2700.0, 3150.0, 3700.0, 4400.0, 5300.0, 6400.0, 7700.0, 9500.0, 12000.0, 15500.0, 20500.0, 27000.0]</p>
<p>For each bark band the power-spectrum (mag-squared) is summed. The first two bands [0,100] and [100,200] have been split in half for better resolution. It was observed that beat detection is better when this is done.</p>
<p>This algorithm uses FrequencyBands and thus inherits its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] The Bark Frequency Scale,
<a class="reference external" href="http://ccrma.stanford.edu/~jos/bbt/Bark_Frequency_Scale.html">http://ccrma.stanford.edu/~jos/bbt/Bark_Frequency_Scale.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BarkExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>barkbands</strong> (<em>vector_real</em>) - spectral energy at each bark band. See BarkBands alogithm</li>
<li><strong>barkbands_kurtosis</strong> (<em>real</em>) - kurtosis from bark bands. See DistributionShape algorithm documentation</li>
<li><strong>barkbands_skewness</strong> (<em>real</em>) - skewness from bark bands. See DistributionShape algorithm documentation</li>
<li><strong>barkbands_spread</strong> (<em>real</em>) - spread from barkbands. See DistributionShape algorithm documentation</li>
<li><strong>spectral_crest</strong> (<em>real</em>) - See Crest algorithm documentation</li>
<li><strong>spectral_flatness_db</strong> (<em>real</em>) - See flatnessDB algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts some Bark bands based spectral features from an audio signal</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Beatogram<br>[streaming]

</th><td class="col-xs-2">
<li><strong>loudness</strong> (<em>vector_real</em>) - the loudness at each beat</li>
<li><strong>loudnessBandRatio</strong> (<em>vector_vector_real</em>) - matrix of loudness ratios at each band and beat</li>
</td><td class="col-xs-2">
<li><strong>beatogram</strong> (<em>vector_vector_real</em>) - filtered matrix loudness</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 16</em>) :</dt>
<dd><p class="first last">number of beats for dynamic filtering</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm filters the loudness matrix given by BeatsLoudness algorithm in order to keep only the most salient beat band representation.
This algorithm has been found to be useful for estimating time signatures.</p>
<p>Quality: experimental (not evaluated, do not use)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BeatsLoudness<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the beat's energy in the whole spectrum</li>
<li><strong>loudnessBandRatio</strong> (<em>vector_real</em>) - the ratio of the beat's energy in each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>beatDuration</strong> (<em>real ∈ (0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">the duration of the window in which the beat will be restricted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beatWindowDuration</strong> (<em>real ∈ (0, ∞), default = 0.1</em>) :</dt>
<dd><p class="first last">the duration of the window in which to look for the beginning of the beat (centered around the positions in 'beats') [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beats</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of beat positions (each position is in seconds)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [0, 200, 400, 800, 1600, 3200, 22000]</em>) :</dt>
<dd><p class="first last">the list of bands to compute energy ratios [Hz</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Calculates the loudness computed only on the beats, both on the whole frequency range and on each specified frequency band. See the Loudness algorithm for a description of loudness and SingleBeatLoudness for a more detailed explanation.</p>
<p>Note that the algorithm will output empty results in the case if no beats are specified in the &quot;beats&quot; parameter.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BeatTrackerDegara<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - input signal</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>real</em>) - the estimated tick locations [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the beat locations given an input signal. It computes 'complex spectral difference' onset detection function and utilizes the beat tracking algorithm (TempoTapDegara) to extract beats [1]. The algorithm works with the optimized settings of 2048/1024 frame/hop size for the computation of the detection function, with its posterior x2 resampling.) While it has a lower accuracy than BeatTrackerMultifeature (see the evaluation results in [2]), its computational speed is significantly higher, which makes reasonable to apply this algorithm for batch processings of large amounts of audio signals.</p>
<p>Note that the algorithm requires the audio input with the 44100 Hz sampling rate in order to function correctly.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] N. Degara, E. A. Rua, A. Pena, S. Torres-Guijarro, M. E. Davies, and
M. D. Plumbley, &quot;Reliability-informed beat tracking of musical signals,&quot;
IEEE Transactions on Audio, Speech, and Language Processing, vol. 20,
no. 1, pp. 290–301, 2012.</p>
<p class="last">[2] J. Zapata, M.E.P. Davies and E. Gómez, &quot;Multi Feature Beat tracker,&quot;
submitted article to IEEE TSALP, 2013.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BeatTrackerMultiFeature<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - input signal</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>real</em>) - the estimated tick locations [s]</li>
<li><strong>confidence</strong> (<em>real</em>) - confidence of the beat tracker [0, 5.32]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the beat locations given an input signal. It computes a number of onset detection functions and estimates beat location candidates from them using TempoTapDegara algorithm. Thereafter the best candidates are selected using TempoTapMaxAgreement. The employed detection functions, and the optimal frame/hop sizes used for their computation are:</p>
<blockquote>
<ul class="simple">
<li>complex spectral difference (see 'complex' method in OnsetDetection algorithm, 2048/1024 with posterior x2 upsample or the detection function)</li>
<li>energy flux (see 'rms' method in OnsetDetection algorithm, the same settings)</li>
<li>spectral flux in Mel-frequency bands (see 'melflux' method in OnsetDetection algorithm, the same settings)</li>
<li>beat emphasis function (see 'beat_emphasis' method in OnsetDetectionGlobal algorithm, 2048/512)</li>
<li>spectral flux between histogrammed spectrum frames, measured by the modified information gain (see 'infogain' method in OnsetDetectionGlobal algorithm, 2048/512)</li>
</ul>
</blockquote>
<p>You can follow these guidelines [2] to assess the quality of beats estimation based on the computed confidence value:</p>
<blockquote>
<ul class="simple">
<li>[0, 1)      very low confidence, the input signal is hard for the employed candidate beat trackers</li>
<li>[1, 1.5]    low confidence</li>
<li>(1.5, 3.5]  good confidence, accuracy around 80% in AMLt measure</li>
<li>(3.5, 5.32] excellent confidence</li>
</ul>
</blockquote>
<p>Note that the algorithm requires the audio input with the 44100 Hz sampling rate in order to function correctly.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Zapata, M. Davies and E. Gómez, &quot;Multi-feature beat tracker,&quot;
IEEE/ACM Transactions on Audio, Speech and Language Processing. 22(4),
816-825, 2014</p>
<p class="last">[2] J.R. Zapata, A. Holzapfel, M.E.P. Davies, J.L. Oliveira, F. Gouyon,
&quot;Assigning a confidence threshold on automatic beat annotation in large
datasets&quot;, International Society for Music Information Retrieval Conference
(ISMIR'12), pp. 157-162, 2012</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BinaryOperator<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array1</strong> (<em>vector_real</em>) - the first operand input array</li>
<li><strong>array2</strong> (<em>vector_real</em>) - the second operand input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the array containing the result of binary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {add, subtract, multiply, divide}, default = add</em>) :</dt>
<dd><p class="first last">the type of the binary operator to apply to the input arrays</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given two vectors of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>using this algorithm in streaming mode can cause diamond shape graphs which have not been tested with the current scheduler. There is NO GUARANTEE of its correct work for diamond shape graphs.</li>
<li>for y&lt;0, x/y is invalid</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BinaryOperatorStream<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array1</strong> (<em>real</em>) - the first operand input array</li>
<li><strong>array2</strong> (<em>real</em>) - the second operand input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>real</em>) - the array containing the result of binary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {add, subtract, multiply, divide}, default = add</em>) :</dt>
<dd><p class="first last">the type of the binary operator to apply to the input arrays</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given two vectors of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>using this algorithm in streaming mode can cause diamond shape graphs which have not been tested with the current scheduler. There is NO GUARANTEE of its correct work for diamond shape graphs.</li>
<li>for y&lt;0, x/y is invalid</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BPF<br>[streaming]

</th><td class="col-xs-2">
<li><strong>x</strong> (<em>real</em>) - the input coordinate (x-axis)</li>
</td><td class="col-xs-2">
<li><strong>y</strong> (<em>real</em>) - the output coordinate (y-axis)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>xPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the x-coordinates of the points forming the break-point function (the points must be arranged in ascending order and cannot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>yPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the y-coordinates of the points forming the break-point function</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>A break point function linearly interpolates between discrete xy-coordinates to construct a continuous function.</p>
<p>Exceptions are thrown when the size the vectors specified in parameters is not equal and at least they contain two elements. Also if the parameter vector for x-coordinates is not sorted ascendantly. A break point function cannot interpolate outside the range specified in parameter &quot;xPoints&quot;. In that case an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Linear interpolation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Linear_interpolation">http://en.wikipedia.org/wiki/Linear_interpolation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BpmHistogram<br>[streaming]

</th><td class="col-xs-2">
<li><strong>novelty</strong> (<em>real</em>) - the novelty curve</li>
</td><td class="col-xs-2">
<li><strong>bpm</strong> (<em>real</em>) - the mean of the most salient tempo</li>
<li><strong>bpmCandidates</strong> (<em>vector_real</em>) - the list of bpm candidates</li>
<li><strong>bpmMagnitudes</strong> (<em>vector_real</em>) - the strength of bpm candidates</li>
<li><strong>tempogram</strong> (<em>matrix_real</em>) - the bpm spectrogram</li>
<li><strong>frameBpms</strong> (<em>vector_real</em>) - the bpm at each frame that is most related to the mean bpm</li>
<li><strong>ticks</strong> (<em>vector_real</em>) - the list of ticks' positions [s]</li>
<li><strong>ticksMagnitude</strong> (<em>vector_real</em>) - the strength of the ticks</li>
<li><strong>sinusoid</strong> (<em>vector_real</em>) - the sinusoid whose peaks indicate the ticks' positions</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bpm</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">bpm to induce a certain tempo tracking. Zero if unknown</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>constantTempo</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether to consider constant tempo. Set to true when inducina specific tempo</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ [1, ∞), default = 86.1328</em>) :</dt>
<dd><p class="first last">the sampling rate of the novelty curve [frame/s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>real ∈ [1, ∞), default = 4</em>) :</dt>
<dd><p class="first last">the minimum length to compute the fft [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxBpm</strong> (<em>real ∈ (0, ∞), default = 560</em>) :</dt>
<dd><p class="first last">the maximum bpm to consider</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxPeaks</strong> (<em>integer ∈ (0, ∞], default = 50</em>) :</dt>
<dd><p class="first last">the number of peaks to be considered at each spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minBpm</strong> (<em>real ∈ [0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">the minimum bpm to consider</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>overlap</strong> (<em>integer ∈ (0, ∞), default = 16</em>) :</dt>
<dd><p class="first last">the overlap factor</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tempoChange</strong> (<em>real ∈ [0, ∞), default = 5</em>) :</dt>
<dd><p class="first last">the minimum length to consider a change in tempo as stable [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>weightByMagnitude</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether to consider peaks' magnitude when building the histogram</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>windowType</strong> (<em>string, default = hann</em>) :</dt>
<dd><p class="first last">the window type to be used when computing the fft</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>zeroPadding</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">zero padding factor to compute the fft [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given the novelty curve (see NoveltyCurve algorithm), this algorithm outputs a histogram of the most probable bpms and their magnitudes as a measure of strength. It also outputs the mean of the strongest bpm present in the signal. In addition it outputs the bpm at each frame which is most similar to the mean bpm, a half-wave rectified sinusoid whose peaks represent the ticks of the audio signal and their amplitude.
The sampleRate parameter refers to the framerate at which the novelty curve has been computed, thus the audio sampling rate divided by the hopsize at which the audio signal was processed.
The outputs of the algorithm are the following:</p>
<blockquote>
<ul class="simple">
<li>bpm: is the mean of the most salient bpm.</li>
<li>bpmCandidates: list of the strongest bpms present in the signal.</li>
<li>bpmMagnitudes: list containing the normalized strength of each of the bpms from the previous output. These two outputs can be used to construct a histogram and take your own decision when mean bpm is wrong.</li>
<li>tempogram: kind of a spectrogram indexed by bpm where the value at each index is the magnitude of the bpm. Very useful for detecting tempo variations and for plotting the evolution of tempi.</li>
<li>frameBpms: list containing the candidate bpms at each frame that are most similar to the meanBpm. If no candidates are found to be similar to the mean bpm, the meanBpm will be kept unless &quot;tempoChange&quot; seconds have triggered a variation in the tempo.</li>
<li>ticks: outputs the ticks' positions in seconds.</li>
<li>ticksMagnitude: returns the magnitude of each tick. The higher value the higher probabylity to be correct.</li>
<li>sinusoid: outputs a sinusoidal model of the tick's positions. The previous outputs are based on detecting the peaks of this half-wave rectified sinusoid. If needed, one should be able to drive its own peak detection algorithm on this sinusoid in order to obtain its own ticks. Beware that due to overlap factors the last few ticks may exceed the length of the audio signal. Therfore, this output should always be checked against the length of the audio signal.</li>
</ul>
</blockquote>
<p>Although the algorithm tries to find the beats that best fit to the mean bpm, the tempo is not assumed to be constant unless specified in the corresponding parameter.  For this reason and if the tempo differs too much from frame to frame, there may be phase discontinuities when constructing the sinusoid which can yield to too many ticks. When this occurs, one can use the sinusoid output to recursively run this algorithm until the ticks stabilize. At this point it may be useful to induce/infer a specific bpm and set the constant tempo parameter to true.
Another useful trick, is to run the algorithm one time to get an estimation of the bpm and rerun it with a frameSize parameter which is a multiple of the mean bpm.</p>
<p>NOTE that using RhythmExtractor2013 is recommended in order to extract beats, as it was found to perform better in evaluations.</p>
<p>Quality: outdated (use RhythmExtractor2013 instead, still this algorithm might be useful when working with other onset detection functions apart from NoveltyCurve)</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] P. Grosche and M. Müller, &quot;A mid-level representation for capturing
dominant tempo and pulse information in music recordings,&quot; in
International Society for Music Information Retrieval Conference
(ISMIR’09), 2009, pp. 189–194.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BpmHistogramDescriptors<br>[streaming]

</th><td class="col-xs-2">
<li><strong>bpmIntervals</strong> (<em>vector_real</em>) - the list of bpm intervals [s]</li>
</td><td class="col-xs-2">
<li><strong>firstPeakBPM</strong> (<em>real</em>) - value for the highest peak [bpm]</li>
<li><strong>firstPeakWeight</strong> (<em>real</em>) - weight of the highest peak</li>
<li><strong>firstPeakSpread</strong> (<em>real</em>) - spread of the highest peak</li>
<li><strong>secondPeakBPM</strong> (<em>real</em>) - value for the second highest peak [bpm]</li>
<li><strong>secondPeakWeight</strong> (<em>real</em>) - weight of the second highest peak</li>
<li><strong>secondPeakSpread</strong> (<em>real</em>) - spread of the second highest peak</li>
<li><strong>histogram</strong> (<em>vector_real</em>) - bpm histogram [bpm]</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes beats per minute histogram and its statistics for the highest and second highest peak.
Note: histogram vector contains occurance frequency for each bpm value, 0-th element corresponds to 0 bpm value.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
BpmRubato<br>[streaming]

</th><td class="col-xs-2">
<li><strong>beats</strong> (<em>vector_real</em>) - list of detected beat ticks [s]</li>
</td><td class="col-xs-2">
<li><strong>rubatoStart</strong> (<em>vector_real</em>) - list of timestamps where the start of a rubato region was detected [s]</li>
<li><strong>rubatoStop</strong> (<em>vector_real</em>) - list of timestamps where the end of a rubato region was detected [s]</li>
<li><strong>rubatoNumber</strong> (<em>integer</em>) - number of detected rubato regions</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>longRegionsPruningTime</strong> (<em>real ∈ [0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">time for the longest constant tempo region inside a rubato region [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>shortRegionsMergingTime</strong> (<em>real ∈ [0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">time for the shortest constant tempo region from one tempo region to another [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, 1], default = 0.08</em>) :</dt>
<dd><p class="first last">minimum tempo deviation to look for</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the locations of large tempo changes from a list of beat ticks.</p>
<p>An exception is thrown if the input beats are not in ascending order and/or if the input beats contain duplicate values.</p>
<p>Quality: experimental (non-reliable, poor accuracy).</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Tempo Rubato - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Rubato">http://en.wikipedia.org/wiki/Rubato</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CartesianToPolar<br>[streaming]

</th><td class="col-xs-2">
<li><strong>complex</strong> (<em>vector_complex</em>) - the complex input vector</li>
</td><td class="col-xs-2">
<li><strong>magnitude</strong> (<em>vector_real</em>) - the magnitude vector</li>
<li><strong>phase</strong> (<em>vector_real</em>) - the phase vector</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm converts an array of complex numbers from its cartesian form to its polar form using the Euler formula:</dt>
<dd><dl class="first last docutils">
<dt>z = x + i*y = |z|(cos(α) + i sin(α))</dt>
<dd>where x = Real part, y = Imaginary part,
and |z| = modulus = magnitude, α = phase in (-π,π]</dd>
</dl>
</dd>
</dl>
<p>It returns the magnitude and the phase as 2 separate vectors.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Polar Coordinates -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/PolarCoordinates.html">http://mathworld.wolfram.com/PolarCoordinates.html</a></p>
<p class="last">[2] Polar coordinate system - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Polar_coordinates">http://en.wikipedia.org/wiki/Polar_coordinates</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CentralMoments<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>centralMoments</strong> (<em>vector_real</em>) - the central moments of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>mode</strong> (<em>string ∈ {pdf, sample}, default = pdf</em>) :</dt>
<dd><p class="first last">compute central moments considering array values as a probability density function over array index or as sample points of a distribution</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results in the 'pdf' mode</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the 0th, 1st, 2nd, 3rd and 4th central moments of an array (i.e. it returns a 5-tuple in which the index corresponds to the order of the moment).</p>
<p>Central moments cannot be computed on arrays which size is less than 2, in which case an exception is thrown.</p>
<p>Note: the 'mode' parameter defines whether to treat array values as a probability distribution function (pdf) or as sample points of a distribution (sample).</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Sample Central Moment -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/SampleCentralMoment.html">http://mathworld.wolfram.com/SampleCentralMoment.html</a></p>
<p class="last">[2] Central Moment - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Central_moment">http://en.wikipedia.org/wiki/Central_moment</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Centroid<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>centroid</strong> (<em>real</em>) - the centroid of the array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the centroid, normalized to a specified range, of the input array [1]. In particular, it can be used to compute spectral centroid or temporal centroid.</p>
<p>The spectral centroid is a measure that indicates where the &quot;center of mass&quot; of the spectrum is. Perceptually, it has a robust connection with the impression of &quot;brightness&quot; of a sound, and therefore is used to characterise musical timbre. It is calculated as the weighted mean of the frequencies present in the signal, with their magnitudes as the weights.</p>
<p>The temporal centroid is the point in time in a signal that is a temporal balancing point of the sound event energy. It can be computed from the envelope of the signal across audio samples [3] (see Envelope algorithm) or over the RMS level of signal across frames [4] (see RMS algorithm).</p>
<p>Note:
- For a spectral centroid [hz], frequency range should be equal to samplerate/2
- For a temporal envelope centroid [s], range should be equal to (audio_size_in_samples-1) / samplerate
- Exceptions are thrown when input array contains less than 2 elements.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Function Centroid -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/FunctionCentroid.html">http://mathworld.wolfram.com/FunctionCentroid.html</a>
[2] Spectral centroid - Wikipedia, the free encyclopedia,
<a class="reference external" href="https://en.wikipedia.org/wiki/Spectral_centroid">https://en.wikipedia.org/wiki/Spectral_centroid</a>
[3] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004.
[4] Klapuri, A., &amp; Davy, M. (Eds.). (2007). Signal processing methods for
music transcription. Springer Science &amp; Business Media.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ChordsDescriptors<br>[streaming]

</th><td class="col-xs-2">
<li><strong>chords</strong> (<em>string</em>) - the chord progression</li>
<li><strong>key</strong> (<em>string</em>) - the key of the whole song, from A to G</li>
<li><strong>scale</strong> (<em>string</em>) - the scale of the whole song (major or minor)</li>
</td><td class="col-xs-2">
<li><strong>chordsHistogram</strong> (<em>vector_real</em>) - the normalized histogram of chords</li>
<li><strong>chordsNumberRate</strong> (<em>real</em>) - the ratio of different chords from the total number of chords in the progression</li>
<li><strong>chordsChangesRate</strong> (<em>real</em>) - the rate at which chords change in the progression</li>
<li><strong>chordsKey</strong> (<em>string</em>) - the key of the progression, taken as the most frequent chord</li>
<li><strong>chordsScale</strong> (<em>string</em>) - the scale of the progression, whether major or minor</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>Given a chord progression this algorithm describes it by means of key, scale, histogram, and rate of change.
Note:</p>
<blockquote>
<ul class="simple">
<li>chordsHistogram indexes follow the circle of fifths order, while being shifted to the input key and scale</li>
<li>key and scale are taken from the most frequent chord. In the case where multiple chords are equally frequent, the chord is hierarchically chosen from the circle of fifths.</li>
<li>valid chords are C, Em, G, Bm, D, F#m, A, C#m, E, G#m, B, D#m, F#, A#m, C#, Fm, G#, Cm, D#, Gm, A#, Dm, F, Am. Chords that not follow this terminology (i.e. Gb) will raise an exception.</li>
</ul>
</blockquote>
<p>Input chords vector may not be empty, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Chord progression - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Chord_progression">http://en.wikipedia.org/wiki/Chord_progression</a></p>
<p class="last">[2] Circle of fifths - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Circle_of_fifths">http://en.wikipedia.org/wiki/Circle_of_fifths</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ChordsDetection<br>[streaming]

</th><td class="col-xs-2">
<li><strong>pcp</strong> (<em>vector_real</em>) - the pitch class profile from which to detect the chord</li>
</td><td class="col-xs-2">
<li><strong>chords</strong> (<em>string</em>) - the resulting chords, from A to G</li>
<li><strong>strength</strong> (<em>real</em>) - the strength of the chord</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hop size with which the input PCPs were computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>windowSize</strong> (<em>real ∈ (0, ∞), default = 2</em>) :</dt>
<dd><p class="first last">the size of the window on which to estimate the chords [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Using pitch profile classes, this algorithm calculates the best matching major or minor triad and outputs the result as a string (e.g. A#, Bm, G#m, C). This algorithm uses the Sharp versions of each Flatted note (i.e. Bb -&gt; A#).</p>
<p>Note:</p>
<blockquote>
<ul class="simple">
<li>This algorithm assumes that input pcps have been computed with framesize = 2*hopsize</li>
</ul>
</blockquote>
<p>Quality: experimental (prone to errors, algorithm needs improvement)</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez, &quot;Tonal Description of Polyphonic Audio for Music Content
Processing,&quot; INFORMS Journal on Computing, vol. 18, no. 3, pp. 294–304,
2006.</p>
<p class="last">[2] D. Temperley, &quot;What's key for key? The Krumhansl-Schmuckler
key-finding algorithm reconsidered&quot;, Music Perception vol. 17, no. 1,
pp. 65-100, 1999.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Clipper<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the output signal with the added noise</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>max</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum value above which the signal will be clipped</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>min</strong> (<em>real ∈ (-∞, ∞), default = -1</em>) :</dt>
<dd><p class="first last">the minimum value below which the signal will be clipped</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm clips the input signal to fit between the range given by the min and max parameters.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Clipping - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Clipping_(audio">http://en.wikipedia.org/wiki/Clipping_(audio</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Crest<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (cannot contain negative values, and must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>crest</strong> (<em>real</em>) - the crest of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the crest of an array. The crest is defined as the ratio between the maximum value and the arithmetic mean of an array. Typically it is used on the magnitude spectrum.</p>
<p>Crest cannot be computed neither on empty arrays nor arrays which contain negative values. In such cases, exceptions will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CrossCorrelation<br>[streaming]

</th><td class="col-xs-2">
<li><strong>arrayX</strong> (<em>vector_real</em>) - the first input array</li>
<li><strong>arrayY</strong> (<em>vector_real</em>) - the second input array</li>
</td><td class="col-xs-2">
<li><strong>crossCorrelation</strong> (<em>vector_real</em>) - the cross-correlation vector between the two input arrays (its size is equal to maxLag - minLag + 1)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxLag</strong> (<em>integer ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum lag to be computed between the two vectors</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minLag</strong> (<em>integer ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the minimum lag to be computed between the two vectors</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the cross-correlation vector of two signals. It accepts 2 parameters, minLag and maxLag which define the range of the computation of the innerproduct.</p>
<p>An exception is thrown if &quot;minLag&quot; is larger than &quot;maxLag&quot;. An exception is also thrown if the input vectors are empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Cross-correlation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Cross-correlation">http://en.wikipedia.org/wiki/Cross-correlation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
CubicSpline<br>[streaming]

</th><td class="col-xs-2">
<li><strong>x</strong> (<em>real</em>) - the input coordinate (x-axis)</li>
</td><td class="col-xs-2">
<li><strong>y</strong> (<em>real</em>) - the value of the spline at x</li>
<li><strong>dy</strong> (<em>real</em>) - the first derivative of the spline at x</li>
<li><strong>ddy</strong> (<em>real</em>) - the second derivative of the spline at x</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>leftBoundaryFlag</strong> (<em>integer ∈ {0, 1, 2}, default = 0</em>) :</dt>
<dd><p class="first last">type of boundary condition for the left boundary</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>leftBoundaryValue</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the value to be used in the left boundary, when leftBoundaryFlag is 1 or 2</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>rightBoundaryFlag</strong> (<em>integer ∈ {0, 1, 2}, default = 0</em>) :</dt>
<dd><p class="first last">type of boundary condition for the right boundary</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>rightBoundaryValue</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the value to be used in the right boundary, when rightBoundaryFlag is 1 or 2</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>xPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the x-coordinates where data is specified (the points must be arranged in ascending order and cannot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>yPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the y-coordinates to be interpolated (i.e. the known data)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Computes the second derivatives of a piecewise cubic spline.
The input value, i.e. the point at which the spline is to be evaluated typically should be between xPoints[0] and xPoints[size-1]. If the value lies outside this range, extrapolation is used.
Regarding [left/right] boundary condition flag parameters:</p>
<blockquote>
<ul class="simple">
<li>0: the cubic spline should be a quadratic over the first interval</li>
<li>1: the first derivative at the [left/right] endpoint should be [left/right]BoundaryFlag</li>
<li>2: the second derivative at the [left/right] endpoint should be [left/right]BoundaryFlag</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Spline interpolation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Spline_interpolation">http://en.wikipedia.org/wiki/Spline_interpolation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Danceability<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>danceability</strong> (<em>real</em>) - the danceability value. Normal values range from 0 to ~3. The higher, the more danceable.</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTau</strong> (<em>real ∈ (0, ∞), default = 8800</em>) :</dt>
<dd><p class="first last">maximum segment length to consider [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTau</strong> (<em>real ∈ (0, ∞), default = 310</em>) :</dt>
<dd><p class="first last">minimum segment length to consider [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tauMultiplier</strong> (<em>real ∈ [1, ∞), default = 1.1</em>) :</dt>
<dd><p class="first last">multiplier to increment from min to max tau</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Calculates the danceability vector for a given signal. The algorithm is
derived from Detrended Fluctuation Analysis (DFA) described in [1]. The
parameters minTau and maxTau are used to define the range of time over
which DFA will be performed. The output of this algorithm is the
danceability of the audio signal. These values usually range from 0 to 3
(higher values meaning more danceable).
Exception is thrown when minTau is greater than maxTau.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Streich, S. and Herrera, P., Detrended Fluctuation Analysis of Music
Signals: Danceability Estimation and further Semantic Characterization,
Proceedings of the AES 118th Convention, Barcelona, Spain, 2005</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DCRemoval<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal, with the DC component removed</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm removes the DC offset from a signal using a 1st order IIR highpass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Smith, J.O.  Introduction to Digital Filters with Audio Applications,
<a class="reference external" href="http://ccrma-www.stanford.edu/~jos/filters/DC_Blocker.html">http://ccrma-www.stanford.edu/~jos/filters/DC_Blocker.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DCT<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>dct</strong> (<em>vector_real</em>) - the discrete cosine transform of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ [1, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the size of the input array</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>outputSize</strong> (<em>integer ∈ [1, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the number of output coefficients</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the Discrete Cosine Transform of an array.
It uses the DCT-II form, with the 1/sqrt(2) scaling factor for the first coefficient.
Note: The 'inputSize' parameter is only used as an optimization when the algorithm is configured. The DCT will automatically adjust to the size of any input.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Discrete cosine transform - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Discrete_cosine_transform">http://en.wikipedia.org/wiki/Discrete_cosine_transform</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Decrease<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>decrease</strong> (<em>real</em>) - the decrease of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the decrease of an array of Reals (which is defined as the linear regression coefficient). The range parameter is used to normalize the result. For a spectral centroid, the range should be equal to Nyquist and for an audio centroid the range should be equal to (audiosize - 1) / samplerate.
The size of the input array must be at least two elements for &quot;decrease&quot; to be computed, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Least Squares Fitting -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/LeastSquaresFitting.html">http://mathworld.wolfram.com/LeastSquaresFitting.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Derivative<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the derivative of the input signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm returns the first-order derivative of the input signal, ie: for each input value, it returns the value minus the previous one.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DerivativeSFX<br>[streaming]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>vector_real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>derAvAfterMax</strong> (<em>real</em>) - the weighted average of the derivative after the maximum amplitude</li>
<li><strong>maxDerBeforeMax</strong> (<em>real</em>) - the maximum derivative before the maximum amplitude</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm returns two descriptors that are based on the derivative of a signal envelope.</p>
<p>The first descriptor is calculated after the maximum value of the input signal occurred. It is the average of the signal's derivative weighted by its amplitude. This coefficient helps discriminating impulsive sounds, which have a steep release phase, from non-impulsive sounds. The smaller the value the more impulsive.</p>
<p>The second descriptor is the maximum derivative, before the maximum value of the input signal occurred. This coefficient helps discriminating sounds that have a smooth attack phase, and therefore a smaller value than sounds with a fast attack.</p>
<p>This algorithm is meant to be fed by the outputs of the Envelope algorithm. If used in streaming mode, RealAccumulator should be connected in between.
An exception is thrown if the input signal is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Dissonance<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks (must be sorted by frequency)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks (must be sorted by frequency</li>
</td><td class="col-xs-2">
<li><strong>dissonance</strong> (<em>real</em>) - the dissonance of the audio signal (0 meaning completely consonant, and 1 meaning completely dissonant)</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the sensory dissonance (to distinguish from musical or theoretical dissonance) of an audio signal given its spectral peaks. Sensory dissonance measures perceptual roughness of the sound and is based on the roughness of its spectral peaks. Given the spectral peaks, the algorithm estimates total dissonance by summing up the normalized dissonance values for each pair of peaks. These values are computed using dissonance curves, which define dissonace between two spectral peaks according to their frequency and amplitude relations. The dissonance curves are based on perceptual experiments conducted in [1].
Exceptions are thrown when the size of the input vectors are not equal or if input frequencies are not ordered ascendantly</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] R. Plomp and W. J. M. Levelt, &quot;Tonal Consonance and Critical
Bandwidth,&quot; The Journal of the Acoustical Society of America, vol. 38,
no. 4, pp. 548–560, 1965.</p>
<p>[2] Critical Band - Handbook for Acoustic Ecology
<a class="reference external" href="http://www.sfu.ca/sonic-studio/handbook/Critical_Band.html">http://www.sfu.ca/sonic-studio/handbook/Critical_Band.html</a></p>
<p class="last">[3] Bark Scale -  Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Bark_scale">http://en.wikipedia.org/wiki/Bark_scale</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DistributionShape<br>[streaming]

</th><td class="col-xs-2">
<li><strong>centralMoments</strong> (<em>vector_real</em>) - the central moments of a distribution</li>
</td><td class="col-xs-2">
<li><strong>spread</strong> (<em>real</em>) - the spread (variance) of the distribution</li>
<li><strong>skewness</strong> (<em>real</em>) - the skewness of the distribution</li>
<li><strong>kurtosis</strong> (<em>real</em>) - the kurtosis of the distribution</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the spread (variance), skewness and kurtosis excess of an array of Reals given its central moments (see CentralMoments algorithm). These extracted features are good indicators of the shape of the distribution.
The size of the input array must be at least 5. An exception will be thrown otherwise.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004.</p>
<p>[2] Variance - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Variance">http://en.wikipedia.org/wiki/Variance</a></p>
<p>[3] Skewness - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Skewness">http://en.wikipedia.org/wiki/Skewness</a></p>
<p class="last">[4] Kurtosis - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Kurtosis">http://en.wikipedia.org/wiki/Kurtosis</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Duration<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>duration</strong> (<em>real</em>) - the duration of the signal [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the total length of a signal recording in seconds.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
DynamicComplexity<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>dynamicComplexity</strong> (<em>real</em>) - the dynamic complexity coefficient</li>
<li><strong>loudness</strong> (<em>real</em>) - an estimate of the loudness [dB]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>real ∈ (0, ∞), default = 0.2</em>) :</dt>
<dd><p class="first last">the frame size [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The dynamic complexity is the average absolute deviation from the global
loudness level estimate on the dB scale. It is related to the dynamic
range and to the amount of fluctuation in loudness present in a recording.</p>
<p>Silence at the beginning and at the end of a track are ignored in the
computation in order not to deteriorate the results.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] S. Streich, Music complexity: a multi-faceted description of audio
content, UPF, Barcelona, Spain, 2007.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EasyLoader<br>[streaming]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>real</em>) - the output audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>downmix</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the mixing type for stereo files</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>endTime</strong> (<em>real ∈ [0, ∞), default = 1e+06</em>) :</dt>
<dd><p class="first last">the end time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>replayGain</strong> (<em>real ∈ (-∞, ∞), default = -6</em>) :</dt>
<dd><p class="first last">the value of the replayGain that should be used to normalize the signal [dB]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the output sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTime</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file, this algorithm outputs the raw audio data, downmixed to mono. The audio is resampled in case the given sampling rate does not match the sampling rate of the input signal and is normalized by the given replayGain value.</p>
<p>This algorithm uses MonoLoader and therefore inherits all of its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Replay Gain - A Proposed Standard,</dt>
<dd><a class="reference external" href="http://replaygain.hydrogenaudio.org">http://replaygain.hydrogenaudio.org</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EffectiveDuration<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>effectiveDuration</strong> (<em>real</em>) - the effective duration of the signal [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>thresholdRatio</strong> (<em>real ∈ [0, 1], default = 0.4</em>) :</dt>
<dd><p class="first last">the ratio of the envelope maximum to be used as the threshold</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the effective duration of an envelope signal. The effective duration is a measure of the time the signal is perceptually meaningful. This is approximated by the time the envelope is above or equal to a given threshold and is above the -90db noise floor. This measure allows to distinguish percussive sounds from sustained sounds but depends on the signal length.
By default, this algorithm uses 40% of the envelope maximum as the threshold which is suited for short sounds. Note, that the 0% thresold corresponds to the duration of signal above -90db noise floor, while the 100% thresold corresponds to the number of times the envelope takes its maximum value.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Energy<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>energy</strong> (<em>real</em>) - the energy of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the energy of an array of Reals.</p>
<p>The input array should not be empty or an exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EnergyBand<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input frequency spectrum</li>
</td><td class="col-xs-2">
<li><strong>energyBand</strong> (<em>real</em>) - the energy in the frequency band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startCutoffFrequency</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start frequency from which to sum the energy [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>stopCutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the stop frequency to which to sum the energy [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the spectral energy of the given frequency band, including both start and stop cutoff frequencies.
Note that exceptions will be thrown when input spectrum is empty and if startCutoffFrequency is greater than startCutoffFrequency.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EnergyBandRatio<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>energyBandRatio</strong> (<em>real</em>) - the energy ratio of the specified band over the total energy</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startFrequency</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the frequency from which to start summing the energy [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>stopFrequency</strong> (<em>real ∈ [0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the frequency up to which to sum the energy [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the ratio of the spectral energy in the range [startFrequency, stopFrequency] over the total energy.</p>
<p>An exception is thrown when startFrequency is larger than stopFrequency
or the input spectrum is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Entropy<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (cannot contain negative values, and must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>entropy</strong> (<em>real</em>) - the entropy of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the Shannon entropy of an array. Entropy can be used to quantify the peakiness of a distribution. This has been used for voiced/unvoiced decision in automatic speech recognition.</p>
<p>Entropy cannot be computed neither on empty arrays nor arrays which contain negative values. In such cases, exceptions will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] H. Misra, S. Ikbal, H. Bourlard and H. Hermansky, &quot;Spectral entropy
based feature for robust ASR,&quot; in IEEE International Conference on
Acoustics, Speech, and Signal Processing (ICASSP'04).</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Envelope<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the resulting envelope of the signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>applyRectification</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether to apply rectification (envelope based on the absolute value of signal)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>attackTime</strong> (<em>real ∈ [0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the attack time of the first order lowpass in the attack phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>releaseTime</strong> (<em>real ∈ [0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the release time of the first order lowpass in the release phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the envelope of a signal by applying a non-symmetric lowpass filter on a signal. By default it rectifies the signal, but that is optional.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, Digital Audio Signal Processing,
John Wiley &amp; Sons Ltd, 1997, ch.7</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EqloudLoader<br>[streaming]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>real</em>) - the audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>downmix</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the mixing type for stereo files</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>endTime</strong> (<em>real ∈ [0, ∞), default = 1e+06</em>) :</dt>
<dd><p class="first last">the end time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>replayGain</strong> (<em>real ∈ (-∞, ∞), default = -6</em>) :</dt>
<dd><p class="first last">the value of the replayGain [dB] that should be used to normalize the signal [dB]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ {32000, 44100, 48000}, default = 44100</em>) :</dt>
<dd><p class="first last">the output sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTime</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start time of the slice to be extracted [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file this algorithm outputs the raw audio data downmixed to mono. Audio is resampled in case the given sampling rate does not match the sampling rate of the input signal and normalized by the given replayGain gain. In addition, audio data is filtered through an equal-loudness filter.</p>
<p>This algorithm uses MonoLoader and thus inherits all of its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Replay Gain - A Proposed Standard,</dt>
<dd><a class="reference external" href="http://replaygain.hydrogenaudio.org">http://replaygain.hydrogenaudio.org</a>  [2] Replay Gain - Equal Loudness Filter,
<a class="reference external" href="http://replaygain.hydrogenaudio.org/equal_loudness.html">http://replaygain.hydrogenaudio.org/equal_loudness.html</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
EqualLoudness<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ {32000, 44100, 48000}, default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements an equal-loudness filter. The human ear does not perceive sounds of all frequencies as having equal loudness, and to account for this, the signal is filtered by an inverted approximation of the equal-loudness curves. Technically, the filter is a cascade of a 10th order Yulewalk filter with a 2nd order Butterworth high pass filter.</p>
<p>This algorithm depends on the IIR algorithm. Any requirements of the IIR algorithm are imposed for this algorithm. This algorithm is only defined for the sampling rates specified in parameters. It will throw an exception if attempting to configure with any other sampling rate.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Replay Gain - Equal Loudness Filter,
<a class="reference external" href="http://replaygain.hydrogenaudio.org/proposal/equal_loudness.html">http://replaygain.hydrogenaudio.org/proposal/equal_loudness.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ERBBands<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energies/magnitudes of each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">an upper-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ (1, ∞), default = 1025</em>) :</dt>
<dd><p class="first last">the size of the spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 50</em>) :</dt>
<dd><p class="first last">a lower-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ (1, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the number of output bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {energy, magnitude}, default = energy</em>) :</dt>
<dd><p class="first last">compute energies or magnitudes</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>width</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">filter width with respect to ERB</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes energies/magnitudes in bands spaced on an Equivalent Rectangular Bandwidth (ERB) scale, given a spectrum. It applies a frequency domain filterbank using gammatone filters. Adapted from matlab code in:  D. P. W. Ellis (2009). 'Gammatone-like spectrograms', web resource [1].</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] <a class="reference external" href="http://www.ee.columbia.edu/~dpwe/resources/matlab/gammatonegram/">http://www.ee.columbia.edu/~dpwe/resources/matlab/gammatonegram/</a></p>
<p class="last">[2] B. C. Moore and B. R. Glasberg, &quot;Suggested formulae for calculating
auditory-filter bandwidths and excitation patterns,&quot; Journal of the
Acoustical Society of America, vol. 74, no. 3, pp. 750–753, 1983.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FadeDetection<br>[streaming]

</th><td class="col-xs-2">
<li><strong>rms</strong> (<em>real</em>) - rms values array</li>
</td><td class="col-xs-2">
<li><strong>fadeIn</strong> (<em>matrix_real</em>) - 2D-array containing start/stop timestamps corresponding to fade-ins [s] (ordered chronologically)</li>
<li><strong>fadeOut</strong> (<em>matrix_real</em>) - 2D-array containing start/stop timestamps corresponding to fade-outs [s] (ordered chronologically)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffHigh</strong> (<em>real ∈ (0, 1], default = 0.85</em>) :</dt>
<dd><p class="first last">fraction of the average RMS to define the maximum threshold</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>cutoffLow</strong> (<em>real ∈ [0, 1), default = 0.2</em>) :</dt>
<dd><p class="first last">fraction of the average RMS to define the minimum threshold</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ (0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">the rate of frames used in calculation of the RMS [frames/s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minLength</strong> (<em>real ∈ (0, ∞), default = 3</em>) :</dt>
<dd><p class="first last">the minimum length to consider a fade-in/out [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes two arrays containing the start/stop points of fade-ins and fade-outs detected in an audio file. The main hypothesis for the detection is that an increase or decrease of the RMS over time in an audio file corresponds to a fade-in or fade-out, repectively. Minimum and maximum mean-RMS-thresholds are used to define where fade-in and fade-outs occur.</p>
<p>An exception is thrown if the input &quot;rms&quot; is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Fade (audio engineering) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Fade-in">http://en.wikipedia.org/wiki/Fade-in</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FFT<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the FFT of the input frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the expected size of the input frame. This is purely optional and only targeted at optimizing the creation time of the FFT object</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the positive complex STFT (Short-term Fourier transform) of an array of Reals using the FFT algorithm. The resulting fft has a size of (s/2)+1, where s is the size of the input frame.
At the moment FFT can only be computed on frames which size is even and non zero, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Fast Fourier transform - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Fft">http://en.wikipedia.org/wiki/Fft</a></p>
<p class="last">[2] Fast Fourier Transform -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/FastFourierTransform.html">http://mathworld.wolfram.com/FastFourierTransform.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FileOutput<br>[streaming]

</th><td class="col-xs-2">

</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string, default = out.txt</em>) :</dt>
<dd><p class="first last">the name of the output file</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>mode</strong> (<em>string ∈ {text, binary}, default = text</em>) :</dt>
<dd><p class="first last">output mode</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Stores alphanumeric data into text or binary files</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Flatness<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>flatness</strong> (<em>real</em>) - the flatness (ratio between the geometric and the arithmetic mean of the input array)</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the flatness of an array, which is defined as the ratio between the geometric mean and the arithmetic mean.</p>
<p>Flatness is undefined for empty input and negative values, therefore an exception is thrown in any both cases.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FlatnessDB<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>flatnessDB</strong> (<em>real</em>) - the flatness dB</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the flatness of an array, which is defined as the ratio between the geometric mean and the arithmetic mean, and it converts it to dB scale.</p>
<p>Specifically, it can be used to compute spectral flatness [1,2], which is a measure of how noise-like a sound is, as opposed to being tone-like. The meaning of tonal in this context is in the sense of the amount of peaks or resonant structure in a power spectrum, as opposed to flat spectrum of a white noise. A high spectral flatness (approaching 1.0 for white noise) indicates that the spectrum has a similar amount of power in all spectral bands — this would sound similar to white noise, and the graph of the spectrum would appear relatively flat and smooth. A low spectral flatness (approaching 0.0 for a pure tone) indicates that the spectral power is concentrated in a relatively small number of bands — this would typically sound like a mixture of sine waves, and the spectrum would appear &quot;spiky&quot;</p>
<p>The size of the input array must be greater than 0. If the input array is empty an exception will be thrown. This algorithm uses the Flatness algorithm and thus inherits its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</p>
<p class="last">[2] Spectral flatness -  Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Spectral_flatness">http://en.wikipedia.org/wiki/Spectral_flatness</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FlatnessSFX<br>[streaming]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>vector_real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>flatness</strong> (<em>real</em>) - the flatness coefficient</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the flatness coefficient of a signal envelope.</p>
<p>There are two thresholds defined: a lower one at 20% and an upper one at 95%. The thresholds yield two values: one value which has 20% of the total values underneath, and one value which has 95% of the total values underneath. The flatness coefficient is then calculated as the ratio of these two values. This algorithm is meant to be plugged after Envelope algorithm, however in streaming mode a RealAccumulator algorithm should be connected in between the two.
In the current form the algorithm can't be calculated in streaming mode, since it would violate the streaming mode policy of having low memory consumption.</p>
<p>An exception is thrown if the input envelope is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Flux<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>flux</strong> (<em>real</em>) - the spectral flux of the input spectrum</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>halfRectify</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">half-rectify the differences in each spectrum bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>norm</strong> (<em>string ∈ {L1, L2}, default = L2</em>) :</dt>
<dd><p class="first last">the norm to use for difference computation</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm calculates the spectral flux of a given spectrum. Flux is defined as the L2-norm [1] or L1-norm [2] of the difference between two consecutive frames of the magnitude spectrum. The frames have to be of the same size in order to yield a meaningful result. The default L2-norm is used more commonly.</p>
<p>An exception is thrown if the size of the input spectrum does not equal the previous input spectrum's size.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Tzanetakis, G., Cook, P., &quot;Multifeature Audio Segmentation for
Browsing and Annotation&quot;, Proceedings of the 1999 IEEE Workshop on
Applications of Signal Processing to Audio and Acoustics, New Paltz,
NY, USA, 1999, W99 1-4</p>
<p>[2] S. Dixon, &quot;Onset detection revisited&quot;, in International Conference on
Digital Audio Effects (DAFx'06), 2006, vol. 120, pp. 133-137.</p>
<p class="last">[3] <a class="reference external" href="http://en.wikipedia.org/wiki/Spectral_flux">http://en.wikipedia.org/wiki/Spectral_flux</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FrameCutter<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the frames of the audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the size of the frame to cut</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ [1, ∞), default = 512</em>) :</dt>
<dd><p class="first last">the number of samples to jump after a frame is output</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lastFrameToEndOfFile</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether the beginning of the last frame should reach the end of file. Only applicable if startFromZero is true</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>silentFrames</strong> (<em>string ∈ {drop, keep, noise}, default = noise</em>) :</dt>
<dd><p class="first last">whether to [keep/drop/add noise to] silent frames</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startFromZero</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether to start the first frame at time 0 if true, or -frameSize/2 otherwise (zero-centered)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>validFrameThresholdRatio</strong> (<em>real ∈ [0, 1], default = 0</em>) :</dt>
<dd><p class="first last">frames smaller than this ratio will be discarded, those larger will be zero-padded to make a full frame (i.e. a value of 0 will never discard frames and a value of 1 will only keep frames that are of length 'frameSize')</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an input buffer this algorithm will return a frame (slice) of constant size every time it is called, and then jump a constant amount of samples in the future.
When no more frames can be extracted from the input buffer, it will return empty frames
If any frame could not be complete, because we start before the beginning of the input buffer or go past its end, the output frame will be zero-padded.</p>
<p>The rationale for deciding which is the last frame is the following: we should return as many frames as needed to consume all the information contained in the buffer, but no more.
This translates into 2 different conditions, depending on whether the algorithm has been configured with startFromZero = true or startFromZero = false:</p>
<blockquote>
<ul class="simple">
<li>startFromZero = true: a frame is the last one, whenever we are at or beyond the end of the stream. The last frame will be zero-padded if its size is less than &quot;frameSize&quot;</li>
<li>startFromZero = false: a frame is the last one if and only if the center of that frame is at or beyond the end of the stream</li>
</ul>
</blockquote>
<p>then it is the last one
In both cases, if the start of a frame is past the end of the buffer, we don't return it and stop processing, meaning that the previous frame that we returned was the last one.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FrameToReal<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the output audio samples</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing the overlap-add process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the overlap-add function is computed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm converts a sequence of input audio signal frames into a sequence of audio samples.</p>
<p>Empty input signals will raise an exception.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
FrequencyBands<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must be greater than size one)</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy in each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [0, 50, 100, 150, 200, 300, 400, 510, 630, 770, 920, 1080, 1270, 1480, 1720, 2000, 2320, 2700, 3150, 3700, 4400, 5300, 6400, 7700, 9500, 12000, 15500, 20500, 27000]</em>) :</dt>
<dd><p class="first last">list of frequency ranges in to which the spectrum is divided (these must be in ascending order and connot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the energy of an input spectrum for an arbitrary number of non overlapping frequency bands. For each band the power-spectrum (mag-squared) is summed.</p>
<p>Parameter &quot;frequencyBands&quot; must contain at least 2 frequencies, they all must be positive and must be ordered ascentdantly, otherwise an exception will be thrown. FrequencyBands is only defined for spectra, which size is greater than 1.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Frequency Range - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Frequency_band">http://en.wikipedia.org/wiki/Frequency_band</a></p>
<p class="last">[2] Band - Handbook For Acoustic Ecology,
<a class="reference external" href="http://www.sfu.ca/sonic-studio/handbook/Band.html">http://www.sfu.ca/sonic-studio/handbook/Band.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
GeometricMean<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>geometricMean</strong> (<em>real</em>) - the geometric mean of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the geometric mean of an array of positive Reals.</p>
<p>An exception is thrown if the input array does not contain strict positive numbers or the array is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</p>
<p class="last">[2] Geometric Mean -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/GeometricMean.html">http://mathworld.wolfram.com/GeometricMean.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
GFCC<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energies in ERB bands</li>
<li><strong>gfcc</strong> (<em>vector_real</em>) - the gammatone feature cepstrum coefficients</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the upper bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the lower bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ [1, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the number of bands in the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberCoefficients</strong> (<em>integer ∈ [1, ∞), default = 13</em>) :</dt>
<dd><p class="first last">the number of output cepstrum coefficients</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the equivalent of MFCCs but using a gammatone filterbank (ERBBands) scaled on an Equivalent Rectangular Bandwidth (ERB) scale. These coefficients could be called 'Gammatone Feature Cepstral Coefficients.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Y. Shao, Z. Jin, D. Wang, and S. Srinivasan, &quot;An auditory-based feature
for robust speech recognition,&quot; in IEEE International Conference on
Acoustics, Speech, and Signal Processing (ICASSP’09), 2009,
pp. 4625-4628.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HarmonicBpm<br>[streaming]

</th><td class="col-xs-2">
<li><strong>bpms</strong> (<em>vector_real</em>) - list of bpm candidates</li>
</td><td class="col-xs-2">
<li><strong>harmonicBpms</strong> (<em>vector_real</em>) - a list of bpms which are harmonically related to the bpm parameter</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bpm</strong> (<em>integer ∈ [1, ∞), default = 60</em>) :</dt>
<dd><p class="first last">the bpm used to find its harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">bpm threshold below which greatest common divisors are discarded</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, ∞), default = 5</em>) :</dt>
<dd><p class="first last">percentage tolerance to consider two bpms are equal or equal to a harmonic</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts bpms that are harmonically related to the tempo given by the 'bpm' parameter.
The algorithm assumes a certain bpm is harmonically related to parameter bpm, when the greatest common divisor between both bpms is greater than threshold.
The 'tolerance' parameter is needed in order to consider if two bpms are related. For instance, 120, 122 and 236 may be related or not depending on how much tolerance is given</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Greatest common divisor - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Greatest_common_divisor">http://en.wikipedia.org/wiki/Greatest_common_divisor</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HarmonicMask<br>[streaming]

</th><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the input frame</li>
<li><strong>pitch</strong> (<em>real</em>) - an estimate of the fundamental frequency of the signal [Hz]</li>
</td><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the output frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>attenuation</strong> (<em>real ∈ [-∞, ∞), default = -200</em>) :</dt>
<dd><p class="first last">attenuation in dB's of the muted pitched component. If value is positive the pitched component is attenuated (muted), if the value is negative the pitched component is soloed (i.e. background component is attenuated).</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>binWidth</strong> (<em>integer ∈ [0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">number of bins per harmonic partials applied to the mask. This will depend on the internal FFT size</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm applies a spectral mask to remove a pitched source component from the signal. It computes first an harmonic mask corresponding to the input pitch and applies the mask to the input FFT to remove that pitch. The bin width determines how many spectral bins are masked per harmonic partial.
An attenuation value in dB determines the amount of suppression of the pitched component w.r.t the background for the case of muting. A negative attenuation value allows soloing the pitched component.</p>
<p>References:</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HarmonicPeaks<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz] (ascending order)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks (ascending frequency order)</li>
<li><strong>pitch</strong> (<em>real</em>) - an estimate of the fundamental frequency of the signal [Hz]</li>
</td><td class="col-xs-2">
<li><strong>harmonicFrequencies</strong> (<em>vector_real</em>) - the frequencies of harmonic peaks [Hz]</li>
<li><strong>harmonicMagnitudes</strong> (<em>vector_real</em>) - the magnitudes of harmonic peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the number of harmonics to return including F0</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ (0, 0.5), default = 0.2</em>) :</dt>
<dd><p class="first last">the allowed ratio deviation from ideal harmonics</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm finds the harmonic peaks of a signal given its spectral peaks and its fundamental frequency.
Note:</p>
<blockquote>
<ul class="simple">
<li>&quot;tolerance&quot; parameter defines the allowed fixed deviation from ideal harmonics, being a percentage over the F0. For example: if the F0 is 100Hz you may decide to allow a deviation of 20%, that is a fixed deviation of 20Hz; for the harmonic series it is: [180-220], [280-320], [380-420], etc.</li>
<li>If &quot;pitch&quot; is zero, it means its value is unknown, or the sound is unpitched, and in that case the HarmonicPeaks algorithm returns an empty vector.</li>
<li>The output frequency and magnitude vectors are of size &quot;maxHarmonics&quot;. If a particular harmonic was not found among spectral peaks, its ideal frequency value is output together with 0 magnitude.</li>
</ul>
</blockquote>
<p>This algorithm is intended to receive its &quot;frequencies&quot; and &quot;magnitudes&quot; inputs from the SpectralPeaks algorithm.</p>
<blockquote>
<ul class="simple">
<li>When input vectors differ in size or are empty, an exception is thrown. Input vectors must be ordered by ascending frequency excluding DC components and not contain duplicates, otherwise an exception is thrown.</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Harmonic Spectrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Harmonic_spectrum">http://en.wikipedia.org/wiki/Harmonic_spectrum</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HFC<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>hfc</strong> (<em>real</em>) - the high-frequency coefficient</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞], default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {Masri, Jensen, Brossier}, default = Masri</em>) :</dt>
<dd><p class="first last">the type of HFC coefficient to be computed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the High Frequency Content of a signal spectrum.
It can be computed according to the following techniques:</p>
<blockquote>
<ul class="simple">
<li>'Masri' (default) which does: sum |X(n)|^2*k,</li>
<li>'Jensen' which does: sum |X(n)|*k^2</li>
<li>'Brossier' which does: sum |X(n)|*k</li>
</ul>
</blockquote>
<p>Exception is thrown for empty input spectra.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] P. Masri and A. Bateman, “Improved modelling of attack transients in
music analysis-resynthesis,” in Proceedings of the International
Computer Music Conference, 1996, pp. 100–103.</p>
<p>[2] K. Jensen and T. H. Andersen, “Beat estimation on the beat,” in
Applications of Signal Processing to Audio and Acoustics, 2003 IEEE
Workshop on., 2003, pp. 87–90.</p>
<p class="last">[3] High frequency content measure - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/High_Frequency_Content_measure">http://en.wikipedia.org/wiki/High_Frequency_Content_measure</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HighPass<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 1st order IIR high-pass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, p. 40,
John Wiley &amp; Sons, 2002</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HighResolutionFeatures<br>[streaming]

</th><td class="col-xs-2">
<li><strong>hpcp</strong> (<em>vector_real</em>) - the pitch class profile from which to detect the chord</li>
</td><td class="col-xs-2">
<li><strong>equalTemperedDeviation</strong> (<em>real</em>) - measure of the deviation of HPCP local maxima with respect to equal-tempered bins</li>
<li><strong>nonTemperedEnergyRatio</strong> (<em>real</em>) - ratio between the energy on non-tempered bins and the total energy</li>
<li><strong>nonTemperedPeaksEnergyRatio</strong> (<em>real</em>) - ratio between the energy on non-tempered peaks and the total energy</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxPeaks</strong> (<em>integer ∈ [1, ∞), default = 24</em>) :</dt>
<dd><p class="first last">maximum number of HPCP peaks to consider when calculating outputs</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes high-resolution chroma features from an HPCP vector. The vector's size must be a multiple of 12 and it is recommended that it be larger than 120. In otherwords, the HPCP's resolution should be 10 Cents or more.
The high-resolution features being computed are:</p>
<blockquote>
<ul class="simple">
<li>Equal-temperament deviation: a measure of the deviation of HPCP local maxima with respect to equal-tempered bins. This is done by:
a) Computing local maxima of HPCP vector
b) Computing the deviations from equal-tempered (abs) bins and their average</li>
<li>Non-tempered energy ratio: the ratio betwen the energy on non-tempered bins and the total energy, computed from the HPCP average</li>
<li>Non-tempered peak energy ratio: the ratio betwen the energy on non tempered peaks and the total energy, computed from the HPCP average</li>
</ul>
</blockquote>
<p>HighFrequencyFeatures is intended to be used in conjunction with HPCP algorithm. Any input vector which size is not a positive multiple of 12, will raise an exception.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez and P. Herrera, &quot;Comparative Analysis of Music Recordings
from Western and Non-Western traditions by Automatic Tonal Feature
Extraction,&quot; Empirical Musicology Review, vol. 3, pp. 140–156, 2008.</p>
<p class="last">[2] <a class="reference external" href="https://en.wikipedia.org/wiki/Equal_temperament">https://en.wikipedia.org/wiki/Equal_temperament</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
HPCP<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><strong>hpcp</strong> (<em>vector_real</em>) - the resulting harmonic pitch class profile</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandPreset</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">enables whether to use a band preset</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonics</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">number of harmonics for frequency contribution, 0 indicates exclusive fundamental frequency contribution</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">the maximum frequency that contributes to the HPCP [Hz] (the difference between the max and split frequencies must not be less than 200.0 Hz)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxShifted</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether to shift the HPCP vector so that the maximum peak is at index 0</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the minimum frequency that contributes to the HPCP [Hz] (the difference between the min and split frequencies must not be less than 200.0 Hz)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>nonLinear</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">enables whether to apply a Jordi non-linear post-processing function to the output</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>normalized</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether to normalize the HPCP vector</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 440</em>) :</dt>
<dd><p class="first last">the reference frequency for semitone index calculation, corresponding to A3 [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [12, ∞), default = 12</em>) :</dt>
<dd><p class="first last">the size of the output HPCP (must be a positive nonzero multiple of 12)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>splitFrequency</strong> (<em>real ∈ (0, ∞), default = 500</em>) :</dt>
<dd><p class="first last">the split frequency for low and high bands, not used if bandPreset is false [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>weightType</strong> (<em>string ∈ {none, cosine, squaredCosine}, default = squaredCosine</em>) :</dt>
<dd><p class="first last">type of weighting function for determining frequency contribution</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>windowSize</strong> (<em>real ∈ (0, 12], default = 1</em>) :</dt>
<dd><p class="first last">the size, in semitones, of the window used for the weighting</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Computes a Harmonic Pitch Class Profile (HPCP), that is a k*12 dimensional vector which represents the intensities of the twelve (k==1) semitone pitch classes (corresponsing to notes from A to G#), or subdivisions of these (k&gt;1). It does this from the spectral peaks of a signal.
Regarding frequency parameters, exceptions are thrown if &quot;minFrequency&quot;, &quot;splitFrequency&quot; and &quot;maxFrequency&quot; are not separated by at least 200Hz from each other, requiring that &quot;maxFrequency&quot; be greater than &quot;splitFrequency&quot; and &quot;splitFrequency&quot; be greater than &quot;minFrequenc&quot;.Other exceptions are thrown if input vectors have different size, if parameter &quot;size&quot; is not a positive non-zero multiple of 12 or if &quot;windowSize&quot; is less than one hpcp bin (12/size).</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] T. Fujishima, &quot;Realtime Chord Recognition of Musical Sound: A System
Using Common Lisp Music,&quot; in International Computer Music Conference
(ICMC'99), pp. 464-467, 1999.
[2] E. Gómez, &quot;Tonal Description of Polyphonic Audio for Music Content
Processing,&quot; INFORMS Journal on Computing, vol. 18, no. 3, pp. 294–304,
2006.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
IFFT<br>[streaming]

</th><td class="col-xs-2">
<li><strong>fft</strong> (<em>vector_complex</em>) - the input frame</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the IFFT of the input frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the expected size of the input frame. This is purely optional and only targeted at optimizing the creation time of the FFT object</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm calculates the inverse STFT (Short-term Fourier transform) of an array of complex values using the FFT algorithm. The resulting frame has a size of (s-1)*2, where s is the size of the input fft frame. The inverse Fourier transform is not defined for frames which size is less than 2 samples. Otherwise an exception is thrown.</p>
<p>An exception is thrown if the input's size is not larger than 1.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Fast Fourier transform - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Fft">http://en.wikipedia.org/wiki/Fft</a></p>
<p class="last">[2] Fast Fourier Transform -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/FastFourierTransform.html">http://mathworld.wolfram.com/FastFourierTransform.html</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
IIR<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>denominator</strong> (<em>vector_real, default = [1]</em>) :</dt>
<dd><p class="first last">the list of coefficients of the denominator. Often referred to as the A coefficient vector.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numerator</strong> (<em>vector_real, default = [1]</em>) :</dt>
<dd><p class="first last">the list of coefficients of the numerator. Often referred to as the B coefficient vector.</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a standard IIR filter. It filters the data in the input vector with the filter described by parameter vectors 'numerator' and 'denominator' to create the output filtered vector. In the litterature, the numerator is often referred to as the 'B' coefficients and the denominator as the 'A' coefficients.</p>
<dl class="docutils">
<dt>The filter is a Direct Form II Transposed implementation of the standard difference equation:</dt>
<dd>a(0)*y(n) = b(0)*x(n) + b(1)*x(n-1) + ... + b(nb-1)*x(n-nb+1) - a(1)*y(n-1) - ... - a(nb-1)*y(n-na+1)</dd>
</dl>
<p>This algorithm maintains a state which is the state of the delays. One should call the reset() method to reinitialize the state to all zeros.</p>
<p>An exception is thrown if the &quot;numerator&quot; or &quot;denominator&quot; parameters are empty. An exception is also thrown if the first coefficient of the &quot;denominator&quot; parameter is 0.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Smith, J.O.  Introduction to Digital Filters with Audio Applications,
<a class="reference external" href="http://ccrma-www.stanford.edu/~jos/filters/">http://ccrma-www.stanford.edu/~jos/filters/</a></p>
<p class="last">[2] Infinite Impulse Response - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/IIR">http://en.wikipedia.org/wiki/IIR</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Inharmonicity<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the harmonic peaks [Hz] (in ascending order)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the harmonic peaks (in frequency ascending order</li>
</td><td class="col-xs-2">
<li><strong>inharmonicity</strong> (<em>real</em>) - the inharmonicity of the audio signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the inharmonicity of a signal given its spectral peaks. The inharmonicity value is computed as an energy weighted divergence of the spectral components from their closest multiple of the fundamental frequency. The fundamental frequency is taken as the first spectral peak from the input. The inharmonicity value ranges from 0 (purely harmonic signal) to 1 (inharmonic signal).</p>
<p>Inharmonicity was designed to be fed by the output from the HarmonicPeaks algorithm. Note that DC components should be removed from the signal before obtaining its peaks. An exception is thrown if a peak is given at 0Hz.</p>
<p>An exception is thrown if frequency vector is not sorted in ascendently, if it contains duplicates or if any input vector is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004.</p>
<p class="last">[2] Inharmonicity - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Inharmonicity">http://en.wikipedia.org/wiki/Inharmonicity</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
InstantPower<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>power</strong> (<em>real</em>) - the instant power of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the instant power of an array. That is, the energy of the array over its size.</p>
<p>An exception is thrown when input array is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Energy (signal processing) - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Key<br>[streaming]

</th><td class="col-xs-2">
<li><strong>pcp</strong> (<em>vector_real</em>) - the input pitch class profile</li>
</td><td class="col-xs-2">
<li><strong>key</strong> (<em>string</em>) - the estimated key, from A to G</li>
<li><strong>scale</strong> (<em>string</em>) - the scale of the key (major or minor)</li>
<li><strong>strength</strong> (<em>real</em>) - the strength of the estimated key</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>numHarmonics</strong> (<em>integer ∈ [1, ∞), default = 4</em>) :</dt>
<dd><p class="first last">number of harmonics that should contribute to the polyphonic profile (1 only considers the fundamental harmonic)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pcpSize</strong> (<em>integer ∈ [12, ∞), default = 36</em>) :</dt>
<dd><p class="first last">number of array elements used to represent a semitone times 12 (this parameter is only a hint, during computation, the size of the input PCP is used instead)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>profileType</strong> (<em>string ∈ {diatonic, krumhansl, temperley, weichai, tonictriad, temperley2005, thpcp, shaath, gomez, noland, faraldo, pentatonic, edmm, edma}, default = temperley</em>) :</dt>
<dd><p class="first last">the type of polyphic profile to use for correlation calculation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>slope</strong> (<em>real ∈ [0, ∞), default = 0.6</em>) :</dt>
<dd><p class="first last">value of the slope of the exponential harmonic contribution to the polyphonic profile</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>usePolyphony</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">enables the use of polyphonic profiles to define key profiles (this includes the contributions from triads as well as pitch harmonics)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useThreeChords</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">consider only the 3 main triad chords of the key (T, D, SD) to build the polyphonic profiles</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Using pitch profile classes, this algorithm calculates the best matching key estimate for a given HPCP. The algorithm was severely adapted and changed from the original implementation for readability and speed.</p>
<p>Key will throw exceptions either when the input pcp size is not a positive multiple of 12 or if the key could not be found. Also if parameter &quot;scale&quot; is set to &quot;minor&quot; and the profile type is set to &quot;weichai&quot;</p>
<blockquote>
<p>Abouth the Key Profiles:</p>
<ul class="simple">
<li>'Diatonic' - binary profile with diatonic notes of both modes. Could be useful for ambient music or diatonic music which is not strictly 'tonal functional'.</li>
<li>'Tonic Triad' - just the notes of the major and minor chords. Exclusively for testing.</li>
<li>'Krumhansl' - reference key profiles after cognitive experiments with users. They should work generally fine for pop music.</li>
<li>'Temperley' - key profiles extracted from corpus analysis of euroclassical music. Therefore, they perform best on this repertoire (especially in minor).</li>
<li>'Shaath' -  profiles based on Krumhansl's specifically tuned to popular and electronic music.</li>
<li>'Noland' - profiles from Bach's 'Well Tempered Klavier'.</li>
<li>'edma' - automatic profiles extracted from corpus analysis of electronic dance music [3]. They normally perform better that Shaath's</li>
<li>'edmm' - automatic profiles extracted from corpus analysis of electronic dance music and manually tweaked according to heuristic observation. It will report major modes (which are poorly represented in EDM) as minor, but improve performance otherwise [3].</li>
<li>Other key profiles ('Faraldo', 'Pentatonic') are experimental and will be removed on due time.</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez, &quot;Tonal Description of Polyphonic Audio for Music Content
Processing,&quot; INFORMS Journal on Computing, vol. 18, no. 3, pp. 294–304,
2006.</p>
<p class="last">[2] D. Temperley, &quot;What's key for key? The Krumhansl-Schmuckler
key-finding algorithm reconsidered&quot;, Music Perception vol. 17, no. 1,
pp. 65-100, 1999.  [3] Á. Faraldo, E. Gómez, S. Jordà, P.Herrera, &quot;Key Estimation in Electronic
Dance Music. Proceedings of the 38th International Conference on information
Retrieval, Padova, 2016. (In Press.)</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
KeyExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>real</em>) - the audio signal</li>
</td><td class="col-xs-2">
<li><strong>key</strong> (<em>string</em>) - see Key algorithm documentation</li>
<li><strong>scale</strong> (<em>string</em>) - see Key algorithm documentation</li>
<li><strong>strength</strong> (<em>real</em>) - see Key algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 4096</em>) :</dt>
<dd><p class="first last">the framesize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hopsize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tuningFrequency</strong> (<em>real ∈ (0, ∞), default = 440</em>) :</dt>
<dd><p class="first last">the tuning frequency of the input signal</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts tonal features</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Larm<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the audio input signal</li>
</td><td class="col-xs-2">
<li><strong>larm</strong> (<em>real</em>) - the LARM loudness estimate [dB]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>attackTime</strong> (<em>real ∈ [0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the attack time of the first order lowpass in the attack phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>power</strong> (<em>real ∈ (-∞, ∞), default = 1.5</em>) :</dt>
<dd><p class="first last">the power used for averaging</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>releaseTime</strong> (<em>real ∈ [0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the release time of the first order lowpass in the release phase [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the long-term loudness of an audio signal. The LARM model is based on the asymmetrical low-pass filtering of the Peak Program Meter (PPM), combined with Revised Low-frequency B-weighting (RLB) and power mean calculations. LARM has shown to be a reliable and objective loudness estimate of music and speech.</p>
<p>It accepts a power parameter to define the exponential for computing the power mean. Note that if the parameter's value is 2, this algorithm would be equivalent to RMS and if 1, this algorithm would be the mean of the absolute value.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Skovenborg and S. H. Nielsen, &quot;Evaluation of different loudness
models with music and speech material,” in The 117th AES Convention, 2004.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Leq<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal (must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>leq</strong> (<em>real</em>) - the equivalent sound level estimate</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the Equivalent sound level (Leq) of an audio signal. The Leq measure can be derived from the Revised Low-frequency B-weighting (RLB) or from the raw signal as described in [1]. If the signal contains no energy, Leq defaults to essentias definition of silence which is -90dB.
This algorithm will throw an exception on empty input.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. A. Soulodre, &quot;Evaluation of Objective Loudness Meters,&quot; in
The 116th AES Convention, 2004.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LevelExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the loudness values</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 88200</em>) :</dt>
<dd><p class="first last">frame size to compute loudness</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">hop size to compute loudness</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts the loudness of an audio signal</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LogAttackTime<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal envelope (must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>logAttackTime</strong> (<em>real</em>) - the log (base 10) of the attack time [log10(s)]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startAttackThreshold</strong> (<em>real ∈ [0, 1], default = 0.2</em>) :</dt>
<dd><p class="first last">the percentage of the input signal envelope at which the starting point of the attack is considered</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>stopAttackThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">the percentage of the input signal envelope at which the ending point of the attack is considered</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the log (base 10) of the attack time of a signal envelope. The attack time is defined as the time duration from when the sound becomes perceptually audible to when it reaches its maximum intensity. By default, the start of the attack is estimated as the point where the signal envelope reaches 20% of its maximum value in order to account for possible noise presence. Also by default, the end of the attack is estimated as as the point where the signal envelope has reached 90% of its maximum value, in order to account for the possibility that the max value occurres after the logAttack, as in trumpet sounds.</p>
<p>With this said, LogAttackTime's input is intended to be fed by the output of the Envelope algorithm. In streaming mode, the RealAccumulator algorithm should be connected between Envelope and LogAttackTime.</p>
<p>Note that startAttackThreshold cannot be greater than stopAttackThreshold and the input signal should not be empty. In any of these cases an exception will be thrown.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Loudness<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the loudness of the input signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the loudness of a signal, which is defined by Steven's power law as its energy raised to the power of 0.67.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Energy (signal processing) - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Energy_(signal_processing">http://en.wikipedia.org/wiki/Energy_(signal_processing</a>)</p>
<p>[2] Stevens' power law - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Stevens%27_power_law">http://en.wikipedia.org/wiki/Stevens%27_power_law</a></p>
<p class="last">[3] S. S. Stevens, Psychophysics. Transaction Publishers, 1975.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LoudnessEBUR128<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>stereosample</em>) - the input stereo audio signal</li>
</td><td class="col-xs-2">
<li><strong>momentaryLoudness</strong> (<em>real</em>) - momentary loudness (over 400ms) (LUFS)</li>
<li><strong>shortTermLoudness</strong> (<em>real</em>) - short-term loudness (over 3 seconds) (LUFS)</li>
<li><strong>integratedLoudness</strong> (<em>real</em>) - integrated loudness (overall) (LUFS)</li>
<li><strong>loudnessRange</strong> (<em>real</em>) - loudness range over an arbitrary long time interval [3] (dB, LU)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>real ∈ (0, 0.1], default = 0.1</em>) :</dt>
<dd><p class="first last">the hop size with which the loudness is computed [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes loudness descriptors in accordance with EBU R128 recommendation.
- The input stereo signal is preprocessed with a K-weighting filter [2] (see LoudnessEBUR128Filter algorithm), composed of two stages: a shelving filter and a high-pass filter (RLB-weighting curve).
- Momentary loudness is computed by integrating the sum of powers over a sliding rectangular window of 400 ms. The measurement is not gated.
- Short-term loudness is computed by integrating the sum of powers over a sliding rectangular window of 3 seconds. The measurement is not gated.
- Integrated loudness is a loudness value averaged over an arbitrary long time interval with gating of 400 ms blocks with two thresholds [2].</p>
<blockquote>
<ul class="simple">
<li>Absolute 'silence' gating threshold at -70 LUFS for the computation of the absolute-gated loudness level.</li>
<li>Relative gating threshold, 10 LU below the absolute-gated loudness level.</li>
</ul>
</blockquote>
<ul class="simple">
<li>Loudness range is computed from short-term loudness values. It is defined as the difference between the estimates of the 10th and 95th percentiles of the distribution of the loudness values with applied gating [3].<ul>
<li>Absolute 'silence' gating threshold at -70 LUFS for the computation of the absolute-gated loudness level.</li>
<li>Relative gating threshold, -20 LU below the absolute-gated loudness level.</li>
</ul>
</li>
</ul>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] EBU Tech 3341-2011. &quot;Loudness Metering: 'EBU Mode' metering to supplement
loudness normalisation in accordance with EBU R 128&quot;
[2] ITU-R BS.1770-2. &quot;Algorithms to measure audio programme loudness and true-peak audio level
[3] EBU Tech Doc 3342-2011. &quot;Loudness Range: A measure to supplement loudness
normalisation in accordance with EBU R 128&quot;
[4] <a class="reference external" href="http://tech.ebu.ch/loudness">http://tech.ebu.ch/loudness</a>
[5] <a class="reference external" href="http://en.wikipedia.org/wiki/LKFS">http://en.wikipedia.org/wiki/LKFS</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LoudnessEBUR128Filter<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>stereosample</em>) - the input stereo audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal (the sum of squared amplitudes of both channels filtered by ITU-R BS.1770 algorithm</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This is an auxilary signal preprocessing algorithm used within the LoudnessEBUR128 algorithm. It applies the pre-processing K-weighting filter and computes signal representation requiered by LoudnessEBUR128 in accordance with the EBU R128 recommendation.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[2] ITU-R BS.1770-2. &quot;Algorithms to measure audio programme loudness and true-peak audio level</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LoudnessVickers<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the Vickers loudness [dB]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ [44100, 44100], default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate of the input signal which is used to create the weight vector [Hz] (currently, this algorithm only works on signals with a sampling rate of 44100Hz)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes Vickers's loudness for a given audio signal. Currently, this algorithm only works for signals with a 44100Hz sampling rate. This algorithm is meant to be given frames of audio as input (not entire audio signals). The algorithm described in the paper performs a weighted average of the loudness value computed for each of the given frames, this step is left as a post processing step and is not performed by this algorithm.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Vickers, &quot;Automatic Long-term Loudness and Dynamics Matching,&quot; in
The 111th AES Convention, 2001.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LowLevelSpectralEqloudExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>spectral_centroid</strong> (<em>real</em>) - See Centroid algorithm documentation</li>
<li><strong>dissonance</strong> (<em>real</em>) - See Dissonance algorithm documentation</li>
<li><strong>sccoeffs</strong> (<em>vector_real</em>) - See SpectralContrast algorithm documentation</li>
<li><strong>scvalleys</strong> (<em>vector_real</em>) - See SpectralContrast algorithm documentation</li>
<li><strong>spectral_kurtosis</strong> (<em>real</em>) - See DistributionShape algorithm documentation</li>
<li><strong>spectral_skewness</strong> (<em>real</em>) - See DistributionShape algorithm documentation</li>
<li><strong>spectral_spread</strong> (<em>real</em>) - See DistributionShape algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts a set of level spectral features for which it is recommended to apply a preliminary equal-loudness filter over an input audio signal (according to the internal evaluations conducted at Music Technology Group). To this end, you are expected to provide the output of EqualLoudness algorithm as an input for this algorithm. Still, you are free to provide an unprocessed audio input in the case you want to compute these features without equal-loudness filter.</p>
<p>Note that at present we do not dispose any reference to justify the necessity of equal-loudness filter. Our recommendation is grounded on internal evaluations conducted at Music Technology Group that have shown the increase in numeric robustness as a function of the audio encoders used (mp3, ogg, ...) for these features.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LowLevelSpectralExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>barkbands</strong> (<em>vector_real</em>) - spectral energy at each bark band. See BarkBands alogithm</li>
<li><strong>barkbands_kurtosis</strong> (<em>real</em>) - kurtosis from bark bands. See DistributionShape algorithm documentation</li>
<li><strong>barkbands_skewness</strong> (<em>real</em>) - skewness from bark bands. See DistributionShape algorithm documentation</li>
<li><strong>barkbands_spread</strong> (<em>real</em>) - spread from barkbands. See DistributionShape algorithm documentation</li>
<li><strong>hfc</strong> (<em>real</em>) - See HFC algorithm documentation</li>
<li><strong>mfcc</strong> (<em>vector_real</em>) - See MFCC algorithm documentation</li>
<li><strong>pitch</strong> (<em>real</em>) - See PitchYinFFT algorithm documentation</li>
<li><strong>pitch_instantaneous_confidence</strong> (<em>real</em>) - See PitchYinFFT algorithm documentation</li>
<li><strong>pitch_salience</strong> (<em>real</em>) - See PitchSalience algorithm documentation</li>
<li><strong>silence_rate_20dB</strong> (<em>real</em>) - See SilenceRate algorithm documentation</li>
<li><strong>silence_rate_30dB</strong> (<em>real</em>) - See SilenceRate algorithm documentation</li>
<li><strong>silence_rate_60dB</strong> (<em>real</em>) - See SilenceRate algorithm documentation</li>
<li><strong>spectral_complexity</strong> (<em>real</em>) - See Spectral algorithm documentation</li>
<li><strong>spectral_crest</strong> (<em>real</em>) - See Crest algorithm documentation</li>
<li><strong>spectral_decrease</strong> (<em>real</em>) - See Decrease algorithm documentation</li>
<li><strong>spectral_energy</strong> (<em>real</em>) - See Energy algorithm documentation</li>
<li><strong>spectral_energyband_low</strong> (<em>real</em>) - Energy in band (20,150] Hz. See EnergyBand algorithm documentation</li>
<li><strong>spectral_energyband_middle_low</strong> (<em>real</em>) - Energy in band (150,800] Hz.See EnergyBand algorithm documentation</li>
<li><strong>spectral_energyband_middle_high</strong> (<em>real</em>) - Energy in band (800,4000] Hz. See EnergyBand algorithm documentation</li>
<li><strong>spectral_energyband_high</strong> (<em>real</em>) - Energy in band (4000,20000] Hz. See EnergyBand algorithm documentation</li>
<li><strong>spectral_flatness_db</strong> (<em>real</em>) - See flatnessDB algorithm documentation</li>
<li><strong>spectral_flux</strong> (<em>real</em>) - See Flux algorithm documentation</li>
<li><strong>spectral_rms</strong> (<em>real</em>) - See RMS algorithm documentation</li>
<li><strong>spectral_rolloff</strong> (<em>real</em>) - See RollOff algorithm documentation</li>
<li><strong>spectral_strongpeak</strong> (<em>real</em>) - See StrongPeak algorithm documentation</li>
<li><strong>zerocrossingrate</strong> (<em>real</em>) - See ZeroCrossingRate algorithm documentation</li>
<li><strong>inharmonicity</strong> (<em>real</em>) - See Inharmonicity algorithm documentation</li>
<li><strong>tristimulus</strong> (<em>vector_real</em>) - See Tristimulus algorithm documentation</li>
<li><strong>oddtoevenharmonicenergyratio</strong> (<em>real</em>) - See OddToEvenHarmonicEnergyRatio algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts all low level spectral features from an audio signal</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LowPass<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoffFrequency</strong> (<em>real ∈ (0, ∞), default = 1500</em>) :</dt>
<dd><p class="first last">the cutoff frequency for the filter [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements a 1st order IIR low-pass filter. Because of its dependence on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] U. Zölzer, DAFX - Digital Audio Effects, p. 40,
John Wiley &amp; Sons, 2002</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
LPC<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>lpc</strong> (<em>vector_real</em>) - the LPC coefficients</li>
<li><strong>reflection</strong> (<em>vector_real</em>) - the reflection coefficients</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>order</strong> (<em>integer ∈ [2, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the order of the LPC analysis (typically [8,14])</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {regular, warped}, default = regular</em>) :</dt>
<dd><p class="first last">the type of LPC (regular or warped)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the Linear Predictive Coefficients of a signal and the associated Reflection coefficients.</p>
<p>An exception is thrown if the &quot;order&quot; provided is larger than the size of the input signal.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Linear predictive coding - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Linear_predictive_coding">http://en.wikipedia.org/wiki/Linear_predictive_coding</a></p>
<p class="last">[2] J. Makhoul, &quot;Spectral analysis of speech by linear prediction,&quot; IEEE
Transactions on Audio and Electroacoustics, vol. 21, no. 3, pp. 140–148,
1973.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Magnitude<br>[streaming]

</th><td class="col-xs-2">
<li><strong>complex</strong> (<em>vector_complex</em>) - the input vector of complex numbers</li>
</td><td class="col-xs-2">
<li><strong>magnitude</strong> (<em>vector_real</em>) - the magnitudes of the input vector</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the absolute value of each element in a vector of complex numbers.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Complex Modulus -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/ComplexModulus.html">http://mathworld.wolfram.com/ComplexModulus.html</a></p>
<p class="last">[2] Complex number - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Complex_numbers#Absolute_value.2C_conjugation_and_distance">http://en.wikipedia.org/wiki/Complex_numbers#Absolute_value.2C_conjugation_and_distance</a>.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MaxFilter<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - signal to be filtered</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - filtered output</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>causal</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">use casual filter (window is behind current element otherwise it is centered around)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>width</strong> (<em>integer ∈ [2, ∞), default = 3</em>) :</dt>
<dd><p class="first last">the window size, has to be odd if the window is centered</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Maximum filter for 1d signal (van Herk/Gil-Werman Algorithm).</p>
<dl class="docutils">
<dt>References:</dt>
<dd>TODO</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MaxMagFreq<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must have more than 1 element)</li>
</td><td class="col-xs-2">
<li><strong>maxMagFreq</strong> (<em>real</em>) - the frequency with the largest magnitude [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the frequency with the largest magnitude.
Note that a spectrum must contain at least two elements otherwise an exception is thrown</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MaxToTotal<br>[streaming]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>maxToTotal</strong> (<em>real</em>) - the maximum amplitude position to total length ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the ratio between the index of the maximum value of the envelope of a signal and the total length of the envelope. This ratio shows how much the maximum amplitude is off-center. Its value is close to 0 if the maximum is close to the beginning (e.g. Decrescendo or Impulsive sounds), close to 0.5 if it is close to the middle (e.g. Delta sounds) and close to 1 if it is close to the end of the sound (e.g. Crescendo sounds). This algorithm is intended to be fed by the output of the Envelope algorithm</p>
<p>MaxToTotal will throw an exception if the input envelope is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Mean<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>mean</strong> (<em>real</em>) - the mean of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the mean of an array of Reals.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Median<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (must be non-empty)</li>
</td><td class="col-xs-2">
<li><strong>median</strong> (<em>real</em>) - the median of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the median of an array of Reals. When there is an odd number of numbers, the median is simply the middle number. For example, the median of 2, 4, and 7 is 4. When there is an even number of numbers, the median is the mean of the two middle numbers. Thus, the median of the numbers 2, 4, 7, 12 is (4+7)/2 = 5.5. See [1] for more info.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Statistical Median -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/StatisticalMedian.html">http://mathworld.wolfram.com/StatisticalMedian.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MelBands<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy in mel bands</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">an upper-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ (1, ∞), default = 1025</em>) :</dt>
<dd><p class="first last">the size of the spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">a lower-bound limit for the frequencies to be included in the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ (1, ∞), default = 24</em>) :</dt>
<dd><p class="first last">the number of output bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sample rate</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the energy in mel bands for a given spectrum. It applies a frequency-domain filterbank (MFCC FB-40, [1]), which consists of equal area triangular filters spaced according to the mel scale. The filterbank is normalized in such a way that the sum of coefficients for every filter equals one. It is recommended that the input &quot;spectrum&quot; be calculated by the Spectrum algorithm.</p>
<p>It is required that parameter &quot;highMelFrequencyBound&quot; not be larger than the Nyquist frequency, but must be larger than the parameter, &quot;lowMelFrequencyBound&quot;. Also, The input spectrum must contain at least two elements. If any of these requirements are violated, an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] T. Ganchev, N. Fakotakis, and G. Kokkinakis, &quot;Comparative evaluation
of various MFCC implementations on the speaker verification task,&quot; in
International Conference on Speach and Computer (SPECOM’05), 2005,
vol. 1, pp. 191–194.</p>
<p class="last">[2] Mel-frequency cepstrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient">http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MetadataReader<br>[streaming]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>title</strong> (<em>string</em>) - the title of the track</li>
<li><strong>artist</strong> (<em>string</em>) - the artist of the track</li>
<li><strong>album</strong> (<em>string</em>) - the album on which this track appears</li>
<li><strong>comment</strong> (<em>string</em>) - the comment field stored in the tags</li>
<li><strong>genre</strong> (<em>string</em>) - the genre as stored in the tags</li>
<li><strong>tracknumber</strong> (<em>string</em>) - the track number</li>
<li><strong>date</strong> (<em>string</em>) - the date of publication</li>
<li><strong>duration</strong> (<em>integer</em>) - the duration of the track, in seconds</li>
<li><strong>bitrate</strong> (<em>integer</em>) - the bitrate of the track [kb/s]</li>
<li><strong>sampleRate</strong> (<em>integer</em>) - the sample rate [Hz]</li>
<li><strong>channels</strong> (<em>integer</em>) - the number of channels</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>failOnError</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">if true, the algorithm throws an exception when encountering an error (e.g. trying to open an unsupported file format), otherwise the algorithm leaves all fields blank</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string, default = &quot;&quot;</em>) :</dt>
<dd><p class="first last">the name of the file from which to read the tags</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs the metadata tags associated with audio files, as well as their audio properties (e.g. bitrate, length, etc.). Supported audio file types are:</p>
<blockquote>
<ul class="simple">
<li>mp3</li>
<li>flac</li>
<li>ogg</li>
</ul>
</blockquote>
<p>An exception is thrown if unsupported filetype is given or if the file does not exist.
Please observe that the .wav format is not supported. Also note that this algorithm incorrectly calculates the number of channels for a file in mp3 format only for versions less than 1.5 of taglib in Linux and less or equal to 1.5 in Mac OS X
If using this algorithm on Windows, you must ensure that the filename is encoded as UTF-8.
This algorithm also contains some heuristic to try to deal with encoding errors in the tags and tries to do the appropriate conversion if a problem was found (mostly twice latin1-&gt;utf8 conversion).</p>
<p>MetadataReader reads all metadata tags found in audio and stores them in the pool tagPool. Standard metadata tags found in audio files include strings mentioned in [1,2]. Tag strings are case-sensitive and they are converted to lower-case when stored to the pool. It is possible to filter these tags by using 'filterMetadataTags' parameter. This parameter should specify a white-list of tag strings as they are found in the audio file (e.g., &quot;ARTIST&quot;).</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] <a class="reference external" href="https://taglib.github.io/api/classTagLib_1_1PropertyMap.html#details">https://taglib.github.io/api/classTagLib_1_1PropertyMap.html#details</a></p>
<p class="last">[2] <a class="reference external" href="https://picard.musicbrainz.org/docs/mappings/">https://picard.musicbrainz.org/docs/mappings/</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Meter<br>[streaming]

</th><td class="col-xs-2">
<li><strong>beatogram</strong> (<em>vector_vector_real</em>) - filtered matrix loudness</li>
</td><td class="col-xs-2">
<li><strong>meter</strong> (<em>real</em>) - the time signature</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm estimates the time signature of a given beatogram by finding the highest correlation between beats.</p>
<p>Quality: experimental (not evaluated, do not use)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MFCC<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energies in mel bands</li>
<li><strong>mfcc</strong> (<em>vector_real</em>) - the mel frequency cepstrum coefficients</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ (0, ∞), default = 11000</em>) :</dt>
<dd><p class="first last">the upper bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inputSize</strong> (<em>integer ∈ (1, ∞), default = 1025</em>) :</dt>
<dd><p class="first last">the size of input spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the lower bound of the frequency range [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ [1, ∞), default = 40</em>) :</dt>
<dd><p class="first last">the number of mel-bands in the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberCoefficients</strong> (<em>integer ∈ [1, ∞), default = 13</em>) :</dt>
<dd><p class="first last">the number of output mel coefficients</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the mel-frequency cepstrum coefficients.
As there is no standard implementation, the MFCC-FB40 is used by default:</p>
<blockquote>
<ul class="simple">
<li>filterbank of 40 bands from 0 to 11000Hz</li>
<li>take the log value of the spectrum energy in each mel band</li>
<li>DCT of the 40 bands down to 13 mel coefficients</li>
</ul>
</blockquote>
<p>There is a paper describing various MFCC implementations [1].</p>
<p>This algorithm depends on the algorithms MelBands and DCT and therefore inherits their parameter restrictions. An exception is thrown if any of these restrictions are not met. The input &quot;spectrum&quot; is passed to the MelBands algorithm and thus imposes MelBands' input requirements. Exceptions are inherited by MelBands as well as by DCT.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] T. Ganchev, N. Fakotakis, and G. Kokkinakis, &quot;Comparative evaluation
of various MFCC implementations on the speaker verification task,&quot; in
International Conference on Speach and Computer (SPECOM’05), 2005, vol. 1,
pp. 191–194.</p>
<p class="last">[2] Mel-frequency cepstrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient">http://en.wikipedia.org/wiki/Mel_frequency_cepstral_coefficient</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MinToTotal<br>[streaming]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>real</em>) - the envelope of the signal</li>
</td><td class="col-xs-2">
<li><strong>minToTotal</strong> (<em>real</em>) - the minimum amplitude position to total length ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the ratio between the index of the minimum value of the envelope of a signal and the total length of the envelope.</p>
<p>An exception is thrown if the input envelop is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MonoLoader<br>[streaming]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>real</em>) - the mono audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>downmix</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the mixing type for stereo files</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the file from which to read</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the desired output sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio file this algorithm outputs the raw audio data downmixed to mono. Audio is resampled in case the given sampling rate does not match the sampling rate of the input signal.</p>
<p>This algorithm uses AudioLoader and thus inherits all of its input requirements and exceptions.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MonoMixer<br>[streaming]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>stereosample</em>) - the input stereo signal</li>
<li><strong>numberChannels</strong> (<em>integer</em>) - the number of channels of the input signal</li>
</td><td class="col-xs-2">
<li><strong>audio</strong> (<em>real</em>) - the downmixed signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {left, right, mix}, default = mix</em>) :</dt>
<dd><p class="first last">the type of downmixing performed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a stereo signal, this algorithm downmixes the signal into a single channel. If the signal was already a monoaural, it is left unchanged.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] downmixing - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Downmixing">http://en.wikipedia.org/wiki/Downmixing</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MonoWriter<br>[streaming]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>real</em>) - the input audio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bitrate</strong> (<em>integer ∈ {32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160, 192, 224, 256, 320}, default = 192</em>) :</dt>
<dd><p class="first last">the audio bit rate for compressed formats [kbps]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filename</strong> (<em>string</em>) :</dt>
<dd><p class="first last">the name of the encoded file</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>format</strong> (<em>string ∈ {wav, aiff, mp3, ogg, flac}, default = wav</em>) :</dt>
<dd><p class="first last">the audio output format</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm writes a mono audio stream to a file.</p>
<p>Supported formats are wav, aiff, mp3, flac and ogg. An exception is thrown when other extensions are given. Note that to encode in mp3 format it is mandatory that ffmpeg was configured with mp3 enabled.</p>
<p>If the file specified by filename could not be opened or the header of the file omits channel's information, an exception is thrown.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MovingAverage<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the filtered signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ (1, ∞), default = 6</em>) :</dt>
<dd><p class="first last">the size of the window [audio samples]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm implements an FIR Moving Average filter. Because of its dependece on IIR, IIR's requirements are inherited.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Moving Average Filters, <a class="reference external" href="http://www.dspguide.com/ch15.htm">http://www.dspguide.com/ch15.htm</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
MultiPitchMelodia<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_vector_real</em>) - the estimated pitch values per frames [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">guess pitch using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency for salience function peaks (ignore peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered hamonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change durig 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">tine continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates multiple fundamental frequency contours from the input signal. It is a multi pitch version of the MELODIA algorithm described in [1]. While the algorithm is originally designed to extract melody in polyphonic music, this implementation is adapted for multiple sources. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. To this end, PitchSalienceFunction, PitchSalienceFunctionPeaks, PitchContours, and PitchContoursMonoMelody algorithms are employed. It is strongly advised to use the default parameter values which are optimized according to [1] (where further details are provided) except for minFrequency, maxFrequency, and voicingTolerance, which will depend on your application.</p>
<p>The output is a vector of estimated melody pitch values and a vector of confidence values.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</p>
<p>[2] <a class="reference external" href="http://mtg.upf.edu/technologies/melodia">http://mtg.upf.edu/technologies/melodia</a></p>
<p class="last">[3] <a class="reference external" href="http://www.justinsalamon.com/melody-extraction">http://www.justinsalamon.com/melody-extraction</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Multiplexer<br>[streaming]

</th><td class="col-xs-2">

</td><td class="col-xs-2">
<li><strong>data</strong> (<em>vector_real</em>) - the frame containing the input values and/or input frames</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>numberRealInputs</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the number of inputs of type Real to multiplex</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberVectorRealInputs</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the number of inputs of type vector&lt;Real&gt; to multiplex</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns a single vector from a given number of real values and/or frames. Frames from different inputs are multiplexed onto a single stream in an alternating fashion.</p>
<p>This algorithm throws an exception if the number of input reals (or vector&lt;real&gt;) is less than the number specified in configuration parameters or if the user tries to acces an input which has not been specified.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Multiplexer - Wikipedia, the free encyclopedia,</dt>
<dd><a class="reference external" href="http://en.wikipedia.org/wiki/Multiplexer">http://en.wikipedia.org/wiki/Multiplexer</a></dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
NoiseAdder<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the output signal with the added noise</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>fixSeed</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">if true, 0 is used as the seed for generating random values</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>level</strong> (<em>integer ∈ (-∞, 0], default = -100</em>) :</dt>
<dd><p class="first last">power level of the noise generator [dB]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm adds some amount of noise to an input signal, and returns the resulting output signal. The average energy of the noise in dB is defined by the level parameter, and is generated using the Mersenne Twister random number generator.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Mersenne Twister: A random number generator (since 1997/10),
<a class="reference external" href="http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html">http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/emt.html</a></p>
<p class="last">[2] Mersenne twister - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Mersenne_twister">http://en.wikipedia.org/wiki/Mersenne_twister</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
NoveltyCurve<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencyBands</strong> (<em>vector_real</em>) - the frequency bands</li>
</td><td class="col-xs-2">
<li><strong>novelty</strong> (<em>real</em>) - the novelty curve as a single vector</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ [1, ∞), default = 344.531</em>) :</dt>
<dd><p class="first last">the sampling rate of the input audio</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>normalize</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">whether to normalize each band's energy</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>weightCurve</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">vector containing the weights for each frequency band. Only if weightCurveType==supplied</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>weightCurveType</strong> (<em>string ∈ {flat, triangle, inverse_triangle, parabola, inverse_parabola, linear, quadratic, inverse_quadratic, supplied}, default = inverse_quadratic</em>) :</dt>
<dd><p class="first last">the type of weighting to be used for the bands novelty</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio signal, this algorithm computes the novelty curve, such as defined in [1].</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] P. Grosche and M. Müller, &quot;A mid-level representation for capturing
dominant tempo and pulse information in music recordings,&quot; in
International Society for Music Information Retrieval Conference
(ISMIR’09), 2009, pp. 189–194.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OddToEvenHarmonicEnergyRatio<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the harmonic peaks (at least two frequencies in frequency ascending order)</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the harmonic peaks (at least two magnitudes in frequency ascending order)</li>
</td><td class="col-xs-2">
<li><strong>oddToEvenHarmonicEnergyRatio</strong> (<em>real</em>) - the ratio between the odd and even harmonic energies of the given harmonic peaks</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the ratio between a signal's odd and even harmonic energy given the signal's harmonic peaks. The odd to even harmonic energy ratio is a measure allowing to distinguish odd-harmonic-energy predominant sounds (such as from a clarinet) from equally important even-harmonic-energy sounds (such as from a trumpet). The required harmonic frequencies and magnitudes can be computed by the HarmonicPeaks algorithm.
In the case when the even energy is zero, which may happen when only even harmonics where found or when only one peak was found, the algorithm outputs the maximum real number possible. Therefore, this algorithm should be used in conjunction with the harmonic peaks algorithm.
If no peaks are supplied, the algorithm outputs a value of one, assuming either the spectrum was flat or it was silent.</p>
<p>An exception is thrown if the input frequency and magnitude vectors have different size. Finally, an exception is thrown if the frequency and magnitude vectors are not ordered by ascending frequency.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] K. D. Martin and Y. E. Kim, &quot;Musical instrument identification:
A pattern-recognition approach,&quot; The Journal of the Acoustical Society of
America, vol. 104, no. 3, pp. 1768–1768, 1998.</p>
<p class="last">[2] K. Ringgenberg et al., &quot;Musical Instrument Recognition,&quot;
<a class="reference external" href="http://cnx.org/content/col10313/1.3/pdf">http://cnx.org/content/col10313/1.3/pdf</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OnsetDetection<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
<li><strong>phase</strong> (<em>vector_real</em>) - the phase vector corresponding to this spectrum--used only by the &quot;complex&quot; method</li>
</td><td class="col-xs-2">
<li><strong>onsetDetection</strong> (<em>real</em>) - the value of the detection function in the current frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>method</strong> (<em>string ∈ {hfc, complex, complex_phase, flux, melflux, rms}, default = hfc</em>) :</dt>
<dd><p class="first last">the method used for onset detection</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs an onset detection function useful for describing onset occurrences. The output of this algorithm should be post-processed in order to determine whether the frame contains an onset or not. Namely, it could be fed to the Onsets algorithm. It is recommended that the input &quot;spectrum&quot; is generated by the Spectrum algorithm.
Four methods are available:</p>
<blockquote>
<ul class="simple">
<li>'HFC', the High Frequency Content detection function which accurately detects percussive events (see HFC algorithm for details).</li>
<li>'complex', the Complex-Domain spectral difference function [1] taking into account changes in magnitude and phase. It emphasizes note onsets either as a result of significant change in energy in the magnitude spectrum, and/or a deviation from the expected phase values in the phase spectrum, caused by a change in pitch.</li>
<li>'complex_phase', the simplified Complex-Domain spectral difference function [2] taking into account phase changes, weighted by magnitude. TODO:It reacts better on tonal sounds such as bowed string, but tends to over-detect percussive events.</li>
<li>'flux', the Spectral Flux detection function which characterizes changes in magnitude spectrum. See Flux algorithm for details.</li>
<li>'melflux', the spectral difference function, similar to spectral flux, but using half-rectified energy changes in Mel-frequency bands of the spectrum [3].</li>
<li>'rms', the difference function, measuring the half-rectified change of the RMS of the magnitude spectrum (i.e., measuring overall energy flux) [4].</li>
</ul>
</blockquote>
<p>If using the 'HFC' detection function, make sure to adhere to HFC's input requirements when providing an input spectrum. Input vectors of different size or empty input spectra will raise exceptions.
If using the 'complex' detection function, suggested parameters for computation of &quot;spectrum&quot; and &quot;phase&quot; are 44100Hz sample rate, frame size of 1024 and hopSize of 512 samples, which results in a resolution of 11.6ms, and a Hann window.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Bello, Juan P., Chris Duxbury, Mike Davies, and Mark Sandler, On the
use of phase and energy for musical onset detection in the complex domain,
Signal Processing Letters, IEEE 11, no. 6 (2004): 553-556.</p>
<p>[2] P. Brossier, J. P. Bello, and M. D. Plumbley, &quot;Fast labelling of notes
in music signals,&quot; in International Symposium on Music Information
Retrieval (ISMIR’04), 2004, pp. 331–336.</p>
<p>[3] D. P. W. Ellis, &quot;Beat Tracking by Dynamic Programming,&quot; Journal of
New Music Research, vol. 36, no. 1, pp. 51–60, 2007.</p>
<p class="last">[4] J. Laroche, &quot;Efficient Tempo and Beat Tracking in Audio Recordings,&quot;
JAES, vol. 51, no. 4, pp. 226–233, 2003.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OnsetDetectionGlobal<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>onsetDetections</strong> (<em>real</em>) - the frame-wise values of the detection function</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing onset detection function</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 512</em>) :</dt>
<dd><p class="first last">the hop size for computing onset detection function</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>method</strong> (<em>string ∈ {infogain, beat_emphasis}, default = infogain</em>) :</dt>
<dd><p class="first last">the method used for onset detection</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs an onset detection function useful for describing onset occurrences. Detection values are computed frame-wisely given an input signal. The output of this algorithm should be post-processed in order to determine whether the frame contains an onset or not. Namely, it could be fed to the Onsets algorithm.
The following method are available:</p>
<blockquote>
<ul class="simple">
<li>'infogain', the spectral difference measured by the modified information gain [1]. For each frame, it accounts for energy change in between preceding and consecutive frames, histogrammed together, in order to suppress short-term variations on frame-by-frame basis.</li>
<li>'beat_emphasis', the beat emphasis function [1]. This function is a linear combination of onset detection functions (complex spectral differences) in a number of sub-bands, weighted by their beat strength computed over the entire input signal.</li>
</ul>
</blockquote>
<p>Note:</p>
<blockquote>
<ul class="simple">
<li>'infogain' onset detection has been optimized for the default sampleRate=44100Hz, frameSize=2048, hopSize=512.</li>
<li>'beat_emphasis' is optimized for a fixed resolution of 11.6ms, which corresponds to the default sampleRate=44100Hz, frameSize=1024, hopSize=512.</li>
</ul>
<p>Optimal performance of beat detection with TempoTapDegara is not guaranteed for other settings.</p>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] S. Hainsworth and M. Macleod, &quot;Onset detection in musical audio
signals,&quot; in International Computer Music Conference (ICMC’03), 2003,
pp. 163–6.</p>
<p class="last">[2] M. E. P. Davies, M. D. Plumbley, and D. Eck, &quot;Towards a musical beat
emphasis function,&quot; in IEEE Workshop on Applications of Signal Processing
to Audio and Acoustics, 2009. WASPAA  ’09, 2009, pp. 61–64.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OnsetRate<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>onsetTimes</strong> (<em>vector_real</em>) - the detected onset times [s]</li>
<li><strong>onsetRate</strong> (<em>real</em>) - the number of onsets per second</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>Given an audio signal, this algorithm outputs the rate at which onsets occur and the onsets' position in time. Onset detection functions are computed using both high frequency content and complex-domain methods available in OnsetDetection algorithm. See OnsetDetection for more information.
Please note that due to a dependence on the Onsets algorithm, this algorithm is only valid for audio signals with a sampling rate of 44100Hz.
This algorithm throws an exception if the input signal is empty.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Onsets<br>[streaming]

</th><td class="col-xs-2">
<li><strong>detections</strong> (<em>matrix_real</em>) - matrix containing onset detection functions--rows represent the values of different detection functions and columns represent different frames of audio (i.e. detections[i][j] represents the value of the ith detection function for the jth frame of audio)</li>
<li><strong>weights</strong> (<em>vector_real</em>) - the weighting coefficicients for each detection function, must be the same as the first dimension of &quot;detections&quot;</li>
</td><td class="col-xs-2">
<li><strong>onsets</strong> (<em>vector_real</em>) - the onset times [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>alpha</strong> (<em>real ∈ [0, 1], default = 0.1</em>) :</dt>
<dd><p class="first last">the proportion of the mean included to reject smaller peaks--filters very short onsets</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>delay</strong> (<em>integer ∈ (0, ∞), default = 5</em>) :</dt>
<dd><p class="first last">the number of frames used to compute the threshold--size of short-onset filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ (0, ∞), default = 86.1328</em>) :</dt>
<dd><p class="first last">frames per second</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>silenceThreshold</strong> (<em>real ∈ [0, 1], default = 0.02</em>) :</dt>
<dd><p class="first last">the threshold for silence</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes onset times in seconds from an array of detection functions extracted from an audio file.</p>
<p>The main operations are:</p>
<blockquote>
<ul class="simple">
<li>normalizing detection functions,</li>
<li>summing detection functions into a global detection function,</li>
<li>smoothing the global detection function,</li>
<li>thresholding the global detection function for silence,</li>
<li>finding the possible onsets using an adaptative threshold,</li>
<li>cleaning operations on the vector of possible onsets,</li>
<li>onsets time conversion.</li>
</ul>
</blockquote>
<p>Note:</p>
<blockquote>
<ul class="simple">
<li>This algorithm has been optimized for a frameRate of 44100.0/512.0.</li>
<li>At least one Detection function must be supplied at input.</li>
<li>The number of weights must match the number of detection functions.</li>
</ul>
</blockquote>
<p>As mentioned above, the &quot;frameRate&quot; parameter expects a value of 44100/512 (the default), but will work with other values, although the quality of the results is not guaranteed then. An exception is also thrown if the input &quot;detections&quot; matrix is empty. Finally, an exception is thrown if the size of the &quot;weights&quot; input does not equal the first dimension of the &quot;detections&quot; matrix.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] P. Brossier, J. P. Bello, and M. D. Plumbley, &quot;Fast labelling of notes
in music signals,” in International Symposium on Music Information
Retrieval (ISMIR’04), 2004, pp. 331–336.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
OverlapAdd<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the windowed input audio frame</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the output overlap-add audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing the overlap-add process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the overlap-add function is computed</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<div class="system-message">
<p class="system-message-title">System Message: INFO/1 (<tt class="docutils">&lt;stdin&gt;</tt>, line 26)</p>
Possible title underline, too short for the title.
Treating it as ordinary text because it's so short.</div>
<p>This algorithm returns the output of an overlap-add process of a sequence of input audio signal frames. It considers that the input audio frames are windowed audio signals. Giving the size of the frame and the hop size, overlapping and adding consecutive frames with produce a continuous signal.
.</p>
<p>Empty input signals will raise an exception.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Overlap–add method - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Overlap-add_method">http://en.wikipedia.org/wiki/Overlap-add_method</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Panning<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrumLeft</strong> (<em>vector_real</em>) - left channel's spectrum</li>
<li><strong>spectrumRight</strong> (<em>vector_real</em>) - right channel's spectrum</li>
</td><td class="col-xs-2">
<li><strong>panningCoeffs</strong> (<em>matrix_real</em>) - parameters that define the panning curve at each frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>averageFrames</strong> (<em>integer ∈ [0, ∞), default = 43</em>) :</dt>
<dd><p class="first last">number of frames to take into account for averaging</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numBands</strong> (<em>integer ∈ [1, ∞), default = 1</em>) :</dt>
<dd><p class="first last">number of mel bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numCoeffs</strong> (<em>integer ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of coefficients used to define the panning curve at each frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>panningBins</strong> (<em>integer ∈ (1, ∞), default = 512</em>) :</dt>
<dd><p class="first last">size of panorama histogram (in bins)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>warpedPanorama</strong> (<em>bool ∈ {false, true}, default = true</em>) :</dt>
<dd><p class="first last">if true, warped panorama is applied, having more resolution in the center area</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm characterizes panorama distribution by comparing spectra from the left and right channels. The panning coefficients are extracted by:</p>
<ul class="simple">
<li>determining the spatial location of frequency bins given left and right channel spectra;</li>
<li>computing panorama histogram weighted by the energy of frequency bins, averaging it across frames and normalizing;</li>
<li>converting the normalized histogram into panning coefficients (IFFT of the log-histogram).</li>
</ul>
<p>The resulting coefficients will show peaks on the initial bins for left panned audio, and right panning will appear as peaks in the upper bins.</p>
<p>Since panning can vary very rapidly from one frame to the next, the coefficients can be averaged over a time window of several frames by specifying &quot;averageFrames&quot; parameter. If a single vector of panning coefficients for the whole audio input is required, &quot;averageFrames&quot; should correspond to the length of audio input. In standard mode, sequential runs of compute() method on each frame are required for averaging across frames.</p>
<p>Application: music classification, in particular genre classification [2].</p>
<p>Note: At present time, the original algorithm has not been tested in multi-band mode. That is, numBands must remain 1.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] E. Gómez, P. Herrera, P. Cano, J. Janer, J. Serrà, J. Bonada,
S. El-Hajj, T. Aussenac, and G. Holmberg, &quot;Music similarity systems and
methods using descriptors,” U.S. Patent WO 2009/0012022009.</p>
<p class="last">[2] Guaus, E. (2009). Audio content processing for automatic music genre
classification: descriptors, databases, and classifiers. PhD Thesis.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PeakDetection<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>positions</strong> (<em>vector_real</em>) - the positions of the peaks</li>
<li><strong>amplitudes</strong> (<em>vector_real</em>) - the amplitudes of the peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>interpolate</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">boolean flag to enable interpolation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxPeaks</strong> (<em>integer ∈ [1, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the maximum number of returned peaks</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxPosition</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum value of the range to evaluate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minPosition</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the minimum value of the range to evaluate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>orderBy</strong> (<em>string ∈ {position, amplitude}, default = position</em>) :</dt>
<dd><p class="first last">the ordering type of the output peaks (ascending by position or descending by value)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the input range</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ (-∞, ∞), default = -1e+06</em>) :</dt>
<dd><p class="first last">peaks below this given threshold are not output</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The peak detection algorithm detects local maxima (peaks) in a data array.
The algorithm finds positive slopes and detects a peak when the slope changes sign and the peak is above the threshold.
It optionally interpolates using parabolic curve fitting.</p>
<p>Exceptions are thrown if parameter &quot;minPosition&quot; is greater than parameter &quot;maxPosition&quot;, also if the size of the input array is less than 2 elements.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Peak Detection,
<a class="reference external" href="http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html">http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContours<br>[streaming]

</th><td class="col-xs-2">
<li><strong>peakBins</strong> (<em>vector_vector_real</em>) - frame-wise array of cent bins corresponding to pitch salience function peaks</li>
<li><strong>peakSaliences</strong> (<em>vector_vector_real</em>) - frame-wise array of values of salience function peaks</li>
</td><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 2], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change durig 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">time continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm tracks a set of predominant pitch contours from an audio signal. This algorithm is intended to receive its &quot;frequencies&quot; and &quot;magnitudes&quot; inputs from the PitchSalienceFunctionPeaks algorithm outputs aggregated over all frames in the sequence. The output is a vector of estimated melody pitch values.</p>
<p>When input vectors differ in size, an exception is thrown. Input vectors must not contain negative salience values otherwise an exception is thrown. Avoiding erroneous peak duplicates (peaks of the same cent bin) is up to the user's own control and is highly recommended, but no exception will be thrown.</p>
<p>Recommended processing chain: (see [1]): EqualLoudness -&gt; frame slicing with sample rate = 44100, frame size = 2048, hop size = 128 -&gt; Windowing with Hann, x4 zero padding -&gt; Spectrum -&gt; SpectralPeaks -&gt; PitchSalienceFunction (10 cents bin resolution) -&gt; PitchSalienceFunctionPeaks.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContoursMelody<br>[streaming]

</th><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of the start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - vector of estimated pitch values (i.e., melody) [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">Estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (Hz)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voiceVibrato</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">detect voice vibrato</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voicingTolerance</strong> (<em>real ∈ [-1.0, 1.4], default = 0.2</em>) :</dt>
<dd><p class="first last">allowed deviation below the average contour mean salience of all contours (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm converts a set of pitch contours into a sequence of predominant f0 values in Hz by taking the value of the most predominant contour in each frame.
This algorithm is intended to receive its &quot;contoursBins&quot;, &quot;contoursSaliences&quot;, and &quot;contoursStartTimes&quot; inputs from the PitchContours algorithm. The &quot;duration&quot; input corresponds to the time duration of the input signal. The output is a vector of estimated pitch values and a vector of confidence values.</p>
<p>Note that &quot;pitchConfidence&quot; can be negative in the case of &quot;guessUnvoiced&quot;=True: the absolute values represent the confidence, negative values correspond to segments for which non-salient contours where selected, zero values correspond to non-voiced segments.</p>
<p>When input vectors differ in size, or &quot;numberFrames&quot; is negative, an exception is thrown. Input vectors must not contain negative start indices nor negative bin and salience values otherwise an exception is thrown.</p>
<p>Recommended processing chain: (see [1]): EqualLoudness -&gt; frame slicing with sample rate = 44100, frame size = 2048, hop size = 128 -&gt; Windowing with Hann, x4 zero padding -&gt; Spectrum -&gt; SpectralPeaks -&gt; PitchSalienceFunction -&gt; PitchSalienceFunctionPeaks -&gt; PitchContours.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContoursMonoMelody<br>[streaming]

</th><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of the start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - vector of estimated pitch values (i.e., melody) [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">Estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (Hz)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm converts a set of pitch contours into a sequence of f0 values in Hz by taking the value of the most salient contour in each frame.
In contrast to pitchContoursMelody, it assumes a single source.
This algorithm is intended to receive its &quot;contoursBins&quot;, &quot;contoursSaliences&quot;, and &quot;contoursStartTimes&quot; inputs from the PitchContours algorithm. The &quot;duration&quot; input corresponds to the time duration of the input signal. The output is a vector of estimated pitch values and a vector of confidence values.</p>
<p>Note that &quot;pitchConfidence&quot; can be negative in the case of &quot;guessUnvoiced&quot;=True: the absolute values represent the confidence, negative values correspond to segments for which non-salient contours where selected, zero values correspond to non-voiced segments.</p>
<p>When input vectors differ in size, or &quot;numberFrames&quot; is negative, an exception is thrown. Input vectors must not contain negative start indices nor negative bin and salience values otherwise an exception is thrown.</p>
<p>Recommended processing chain: (see [1]): EqualLoudness -&gt; frame slicing with sample rate = 44100, frame size = 2048, hop size = 128 -&gt; Windowing with Hann, x4 zero padding -&gt; Spectrum -&gt; SpectralPeaks -&gt; PitchSalienceFunction -&gt; PitchSalienceFunctionPeaks -&gt; PitchContours.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchContoursMultiMelody<br>[streaming]

</th><td class="col-xs-2">
<li><strong>contoursBins</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of cent bin values representing each contour</li>
<li><strong>contoursSaliences</strong> (<em>vector_vector_real</em>) - array of frame-wise vectors of pitch saliences representing each contour</li>
<li><strong>contoursStartTimes</strong> (<em>vector_real</em>) - array of the start times of each contour [s]</li>
<li><strong>duration</strong> (<em>real</em>) - time duration of the input signal [s]</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_vector_real</em>) - vector of estimated pitch values (i.e., melody) [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">Estimate pitch for non-voiced segments by using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore contours with peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (Hz)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm post-processes a set of pitch contours into a sequence of mutliple f0 values in Hz.
This algorithm is intended to receive its &quot;contoursBins&quot;, &quot;contoursSaliences&quot;, and &quot;contoursStartTimes&quot; inputs from the PitchContours algorithm. The &quot;duration&quot; input corresponds to the time duration of the input signal. The output is a vector of estimated pitch values</p>
<p>When input vectors differ in size, or &quot;numberFrames&quot; is negative, an exception is thrown. Input vectors must not contain negative start indices nor negative bin and salience values otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchFilter<br>[streaming]

</th><td class="col-xs-2">
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - vector of pitch confidence values for the input frames</li>
<li><strong>pitch</strong> (<em>vector_real</em>) - vector of pitch values for the input frames [Hz]</li>
</td><td class="col-xs-2">
<li><strong>pitchFiltered</strong> (<em>real</em>) - vector of corrected pitch values [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>confidenceThreshold</strong> (<em>integer ∈ [0, ∞), default = 36</em>) :</dt>
<dd><p class="first last">ratio between the average confidence of the most confident chunk and the minimum allowed average confidence of a chunk</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minChunkSize</strong> (<em>integer ∈ [0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">minumum number of frames in non-zero pitch chunks</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useAbsolutePitchConfidence</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">treat negative pitch confidence values as positive (use with melodia guessUnvoiced=True)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm corrects the fundamental frequency estimations for a sequence of frames given pitch values together with their confidence values (e.g., by removing non-confident parts and spurious jumps in pitch, and applying octave corrections).</p>
<p>They can be computed with the PitchYinFFT, PitchYin, or PredominantPitchMelodia algorithms.
If you use PredominantPitchMelodia with guessUnvoiced=True, set useAbsolutePitchConfidence=True.</p>
<p>The algorithm can be used for any type of monophonic and heterophonic music.</p>
<p>The original algorithm [1] was proposed to be used for Makam music and employs signal&quot;energy&quot; of frames instead of pitch confidence.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] B. Bozkurt, &quot;An Automatic Pitch Analysis Method for Turkish Maqam
Music,&quot; Journal of New Music Research. 37(1), 1-13.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchMelodia<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the estimated pitch values per frames [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - the estimated pitch confidence</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">guess pitch using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency for salience function peaks (ignore peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered hamonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change durig 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">tine continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency corresponding to the melody of a monophonic music signal (i.e. solo violin, solo singing voice). It implements the MELODIA algorithm described in [1]. While the algorithm is originally designed to extract the predominant melody from polyphonic music, this implementation is adapted for monophonic signals. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. To this end, PitchSalienceFunction, PitchSalienceFunctionPeaks, PitchContours, and PitchContoursMonoMelody algorithms are employed. It is strongly advised to use the default parameter values which are optimized according to [1] (where further details are provided) except for minFrequency and maxFrequency, which will depend on your application.</p>
<p>The output is a vector of estimated melody pitch values and a vector of confidence values.</p>
<p>It is recommended to apply EqualLoudness on the input signal (see [1]) as a pre-processing stage before running this algorithm.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</p>
<p>[2] <a class="reference external" href="http://mtg.upf.edu/technologies/melodia">http://mtg.upf.edu/technologies/melodia</a></p>
<p class="last">[3] <a class="reference external" href="http://www.justinsalamon.com/melody-extraction">http://www.justinsalamon.com/melody-extraction</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchSalience<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>pitchSalience</strong> (<em>real</em>) - the pitch salience (normalized from 0 to 1)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>highBoundary</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">until which frequency we are looking for the minimum (must be smaller than half sampleRate) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowBoundary</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">from which frequency we are looking for the maximum (must not be larger than highBoundary) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the pitch salience of a spectrum. The pitch salience is given by the ratio of the highest auto correlation value of the spectrum to the non-shifted auto correlation value. Pitch salience was designed as quick measure of tone sensation. Unpitched sounds (non-musical sound effects) and pure tones have an average pitch salience value close to 0 whereas sounds containing several harmonics in the spectrum tend to have a higher value.</p>
<p>Note that this algorithm may give better results when used with low sampling rates (i.e. 8000) as the information in the bands musically meaningful will have more relevance.</p>
<p>This algorithm uses AutoCorrelation on the input &quot;spectrum&quot; and thus inherits its input requirements and exceptions. An exception is thrown at configuration time if &quot;lowBoundary&quot; is larger than &quot;highBoundary&quot; and/or if &quot;highBoundary&quot; is not smaller than half &quot;sampleRate&quot;. At computation time, an exception is thrown if the input spectrum is empty. Also note that feeding silence to this algorithm will return zero.</p>
<p>Application: characterizing percussive sounds.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Ricard &quot;Towards computational morphological description of sound.
DEA pre-thesis research work, Universitat Pompeu Fabra, Barcelona, 2004.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchSalienceFunction<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><strong>salienceFunction</strong> (<em>vector_real</em>) - array of the quantized pitch salience values</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>real ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered harmonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the pitch salience function of a signal frame given its spectral peaks. The salience function covers a pitch range of nearly five octaves (i.e., 6000 cents), starting from the &quot;referenceFrequency&quot;, and is quantized into cent bins according to the specified &quot;binResolution&quot;. The salience of a given frequency is computed as the sum of the weighted energies found at integer multiples (harmonics) of that frequency.</p>
<p>This algorithm is intended to receive its &quot;frequencies&quot; and &quot;magnitudes&quot; inputs from the SpectralPeaks algorithm. The output is a vector of salience values computed for the cent bins. The 0th bin corresponds to the specified &quot;referenceFrequency&quot;.</p>
<p>When input vectors differ in size or are empty, an exception is thrown. Input vectors must contain positive frequencies and not contain negative magnitudes otherwise an exception is thrown. It is highly recommended to avoid erroneous peak duplicates (peaks of the same frequency occuring more than ones), but it is up to the user's own control and no exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchSalienceFunctionPeaks<br>[streaming]

</th><td class="col-xs-2">
<li><strong>salienceFunction</strong> (<em>vector_real</em>) - the array of salience function values corresponding to cent frequency bins</li>
</td><td class="col-xs-2">
<li><strong>salienceBins</strong> (<em>vector_real</em>) - the cent bins corresponding to salience function peaks</li>
<li><strong>salienceValues</strong> (<em>vector_real</em>) - the values of salience function peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 1760</em>) :</dt>
<dd><p class="first last">the maximum frequency to evaluate (ignore peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the minimum frequency to evaluate (ignore peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the peaks of a given pitch salience function.</p>
<p>This algorithm is intended to receive its &quot;salienceFunction&quot; input from the PitchSalienceFunction algorithm. The peaks are detected using PeakDetection algorithm. The outputs are two arrays of bin numbers and salience values corresponding to the peaks.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><dl class="first last docutils">
<dt>[1] Salamon, J., &amp; Gómez E. (2012).  Melody Extraction from Polyphonic Music Signals using Pitch Contour Characteristics.</dt>
<dd>IEEE Transactions on Audio, Speech and Language Processing. 20(6), 1759-1770.</dd>
</dl>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchYin<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal frame</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>real</em>) - detected pitch [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>real</em>) - confidence with which the pitch was detected [0,1]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [2, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">number of samples in the input frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>interpolate</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">enable interpolation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">sampling rate of the input spectrum [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, 1], default = 0.15</em>) :</dt>
<dd><p class="first last">tolerance for peak detection</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency from a given spectrum. It is an implementation of the Yin algorithm [1] for computations in the time domain.</p>
<p>An exception is thrown if an empty signal is provided.</p>
<p>Please note that if &quot;pitchConfidence&quot; is zero, &quot;pitch&quot; is undefined and should not be used for other algorithms.
Also note that a null &quot;pitch&quot; is never ouput by the algorithm and that &quot;pitchConfidence&quot; must always be checked out.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] De Cheveigné, A., &amp; Kawahara, H. &quot;YIN, a fundamental frequency estimator
for speech and music. The Journal of the Acoustical Society of America,
111(4), 1917-1930, 2002.</p>
<p class="last">[2] Pitch detection algorithm - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Pitch_detection_algorithm">http://en.wikipedia.org/wiki/Pitch_detection_algorithm</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PitchYinFFT<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (preferably created with a hann window)</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>real</em>) - detected pitch [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>real</em>) - confidence with which the pitch was detected [0,1]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [2, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">number of samples in the input spectrum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>interpolate</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">boolean flag to enable interpolation</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">sampling rate of the input spectrum [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency corresponding to the melody of a monophonic music signal (i.e. solo violin or solo singing voice). It is an implementation of YinFFT algorithm [1], which is an optimized version of Yin algorithm for computation in the frequency domain. It is recommended to window the input spectrum with a Hann window. The raw spectrum can be computed with the Spectrum algorithm.</p>
<p>An exception is thrown if an empty spectrum is provided.</p>
<p>Please note that if &quot;pitchConfidence&quot; is zero, &quot;pitch&quot; is undefined and should not be used for other algorithms.
Also note that a null &quot;pitch&quot; is never ouput by the algorithm and that &quot;pitchConfidence&quot; must always be checked out.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] P. M. Brossier, &quot;Automatic Annotation of Musical Audio for Interactive
Applications,” QMUL, London, UK, 2007.</p>
<p class="last">[2] Pitch detection algorithm - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Pitch_detection_algorithm">http://en.wikipedia.org/wiki/Pitch_detection_algorithm</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PolarToCartesian<br>[streaming]

</th><td class="col-xs-2">
<li><strong>magnitude</strong> (<em>vector_real</em>) - the magnitude vector</li>
<li><strong>phase</strong> (<em>vector_real</em>) - the phase vector</li>
</td><td class="col-xs-2">
<li><strong>complex</strong> (<em>vector_complex</em>) - the resulting complex vector</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm converts an array of complex numbers from its polar form to its cartesian form through the Euler formula:</dt>
<dd><dl class="first last docutils">
<dt>z = x + i*y = |z|(cos(α) + i sin(α))</dt>
<dd>where x = Real part, y = Imaginary part,
and |z| = modulus = magnitude, α = phase</dd>
</dl>
</dd>
</dl>
<p>An exception is thrown if the size of the magnitude vector does not match the size of the phase vector.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Polar coordinate system - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Polar_coordinates">http://en.wikipedia.org/wiki/Polar_coordinates</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PoolAggregator<br>[streaming]

</th><td class="col-xs-2">
<li><strong>input</strong> (<em>pool</em>) - the input pool</li>
</td><td class="col-xs-2">
<li><strong>output</strong> (<em>pool</em>) - a pool containing the aggregate values of the input pool</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>defaultStats</strong> (<em>vector_string, default = [&quot;mean&quot;, &quot;var&quot;, &quot;min&quot;, &quot;max&quot;, &quot;median&quot;]</em>) :</dt>
<dd><p class="first last">the default statistics to be computed for each descriptor in the input pool</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>exceptions</strong> (<em>map_vector_string, default = {}</em>) :</dt>
<dd><p class="first last">a mapping between descriptor names (no duplicates) and the types of statistics to be computed for those descriptors (e.g. { lowlevel.bpm : [min, max], lowlevel.gain : [var, min, dmean] })</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm performs statistical aggregation on a Pool and places the results of the aggregation into a new Pool. Supported statistical units are:</dt>
<dd>'min' (minimum),
'max' (maximum),
'median'
'mean'
'var' (variance),
'skew' (skewness),
'kurt' (kurtosis),
'dmean' (mean of the derivative),
'dvar' (variance of the derivative),
'dmean2' (mean of the second derivative),
'dvar2' (variance of the second derivative),
'cov' (covariance), and
'icov' (inverse covariance).
'copy' (verbatim copy of descriptor, no aggregation; exclusive: cannot be performed with any other statistical units).
'value' (copy of the descriptor, but the value is placed under the name '&lt;descriptor name&gt;.value')</dd>
</dl>
<p>These statistics can be computed for single dimensional vectors in a Pool, with the exception of 'cov' and 'icov'. All of the above statistics can be
computed for two dimensional vectors in the Pool. With the exception of 'cov' and 'icov', two-dimensional statistics are calculated by aggregating
each column and placing the result into a vector of the same size as the size of each vector in the input Pool. The previous implies that each
vector in the pool (under a particular descriptor of course) must have equal size. This implication also applies for 'cov' and 'icov'.</p>
<p>An additional restriction for using the 'icov' statistic is that the covariance matrix for a particular descriptor must be invertible. The 'cov' and 'icov' aggregation statistics each return a square matrix with dimension equal to the length of the vectors under the given descriptor.</p>
<p>Please also note that only the absolute values of the first and second derivates are considered when calculating the mean ('dmean' and 'dmean2') as well as for the variance ('dvar' and 'dvar2'). This is to avoid a trivial solution for the mean.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PowerMean<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array (must contain only positive real numbers)</li>
</td><td class="col-xs-2">
<li><strong>powerMean</strong> (<em>real</em>) - the power mean of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>power</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the power to which to elevate each element before taking the mean</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the Power Mean of an array of Reals. It accepts one parameter, p, which is the power (or order or degree) of the Power Mean. Note that if p=-1, the Power Mean is equal to the Harmonic Mean, if p=0, the Power Mean is equal to the Geometric Mean, if p=1, the Power Mean is equal to the Arithmetic Mean, if p=2, the Power Mean is equal to the Root Mean Square.</p>
<p>Exceptions are thrown if input array either is empty or it contains non positive numbers.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Power Mean -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/PowerMean.html">http://mathworld.wolfram.com/PowerMean.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PowerSpectrum<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>powerSpectrum</strong> (<em>vector_real</em>) - the power spectrum of the input signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the expected size of the input frame (this is purely optional and only targeted at optimizing the creation time of the FFT object)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the power spectrum of an array of Reals. The resulting power spectrum is of the same size as the incoming frame.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Power Spectrum - from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/PowerSpectrum.html">http://mathworld.wolfram.com/PowerSpectrum.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
PredominantPitchMelodia<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the estimated pitch values per frames [Hz]</li>
<li><strong>pitchConfidence</strong> (<em>vector_real</em>) - confidence with which the pitch was detected</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binResolution</strong> (<em>real ∈ (0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">salience function bin resolution [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>filterIterations</strong> (<em>integer ∈ [1, ∞), default = 3</em>) :</dt>
<dd><p class="first last">number of interations for the octave errors / pitch outlier filtering process</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing pitch saliecnce</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>guessUnvoiced</strong> (<em>bool ∈ {false, true}, default = false</em>) :</dt>
<dd><p class="first last">guess pitch using non-salient contours when no salient ones are present in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>harmonicWeight</strong> (<em>real ∈ (0, 1), default = 0.8</em>) :</dt>
<dd><p class="first last">harmonic weighting parameter (weight decay ratio between two consequent harmonics, =1 for no decay)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 128</em>) :</dt>
<dd><p class="first last">the hop size with which the pitch salience function was computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeCompression</strong> (<em>real ∈ (0, 1], default = 1</em>) :</dt>
<dd><p class="first last">magnitude compression parameter (=0 for maximum compression, =1 for no compression)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>integer ∈ [0, ∞), default = 40</em>) :</dt>
<dd><p class="first last">peak magnitude threshold (maximum allowed difference from the highest peak in dBs)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ [0, ∞), default = 20000</em>) :</dt>
<dd><p class="first last">the maximum allowed frequency for salience function peaks (ignore peaks above) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minDuration</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the minimum allowed contour duration [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 80</em>) :</dt>
<dd><p class="first last">the minimum allowed frequency for salience function peaks (ignore peaks below) [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberHarmonics</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">number of considered hamonics</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakDistributionThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">allowed deviation below the peak salience mean over all frames (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>peakFrameThreshold</strong> (<em>real ∈ [0, 1], default = 0.9</em>) :</dt>
<dd><p class="first last">per-frame salience threshold factor (fraction of the highest peak salience in a frame)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pitchContinuity</strong> (<em>real ∈ [0, ∞), default = 27.5625</em>) :</dt>
<dd><p class="first last">pitch continuity cue (maximum allowed pitch change durig 1 ms time period) [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>referenceFrequency</strong> (<em>real ∈ (0, ∞), default = 55</em>) :</dt>
<dd><p class="first last">the reference frequency for Hertz to cent convertion [Hz], corresponding to the 0th cent bin</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeContinuity</strong> (<em>integer ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">tine continuity cue (the maximum allowed gap duration for a pitch contour) [ms]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voiceVibrato</strong> (<em>bool ∈ {true, false}, default = false</em>) :</dt>
<dd><p class="first last">detect voice vibrato</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>voicingTolerance</strong> (<em>real ∈ [-1.0, 1.4], default = 0.2</em>) :</dt>
<dd><p class="first last">allowed deviation below the average contour mean salience of all contours (fraction of the standard deviation)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the fundamental frequency of the predominant melody from polyphonic music signals (i.e. the singing voice melody in an accompanied singing recording). It implements the MELODIA algorithm described in [1]. The approach is based on the creation and characterization of pitch contours, time continuous sequences of pitch candidates grouped using auditory streaming cues. It furthermore determines for each frame, if the predominant melody is present or not. To this end, PitchSalienceFunction, PitchSalienceFunctionPeaks, PitchContours, and PitchContoursMelody algorithms are employed. It is strongly advised to use the default parameter values which are optimized according to [1] (where further details are provided) except for minFrequency, maxFrequency, and voicingTolerance, which will depend on your application.</p>
<p>The output is a vector of estimated melody pitch values and a vector of confidence values. The first value corresponds to the beginning of the input signal (time 0).</p>
<p>It is recommended to apply EqualLoudness on the input signal (see [1]) as a pre-processing stage before running this algorithm.</p>
<p>Note that &quot;pitchConfidence&quot; can be negative in the case of &quot;guessUnvoiced&quot;=True: the absolute values represent the confidence, negative values correspond to segments for which non-salient contours where selected, zero values correspond to non-voiced segments.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</p>
<p>[2] <a class="reference external" href="http://mtg.upf.edu/technologies/melodia">http://mtg.upf.edu/technologies/melodia</a></p>
<p class="last">[3] <a class="reference external" href="http://www.justinsalamon.com/melody-extraction">http://www.justinsalamon.com/melody-extraction</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RawMoments<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>rawMoments</strong> (<em>vector_real</em>) - the (raw) moments of the input array</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>range</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the range of the input array, used for normalizing the results</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the first 5 raw moments of an array of Reals. The output array is of size 6 because the zero-ith moment is used for padding so that the first moment corresponds to index 1.</p>
<dl class="docutils">
<dt>Note:</dt>
<dd>This algorithm has a range parameter, which usually represents a frequency (results will range from 0 to range). For a spectral centroid, the range should be equal to samplerate / 2. For an audio centroid, the frequency range should be equal to (audio_size-1) / samplerate.</dd>
</dl>
<p>An exception is thrown if the input array's size is smaller than 2.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Raw Moment -- from Wolfram MathWorld,
<a class="reference external" href="http://mathworld.wolfram.com/RawMoment.html">http://mathworld.wolfram.com/RawMoment.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RealAccumulator<br>[streaming]

</th><td class="col-xs-2">
<li><strong>data</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the accumulated signal in one single frame</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm takes a stream of Real values and outputs them as a single vector when the end of the stream is reached.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ReplayGain<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>replayGain</strong> (<em>real</em>) - the ReplayGain gain value in dB</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>applyEqloud</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">enables whether this algorithm should apply an equal-loudness filter (set to false if the input audio signal is already equal-loudness filtered)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the Replay Gain loudness value of the audio. The algorithm is described in detail at [1]. The value returned is the 'standard' ReplayGain value, not the value with 6dB preamplification as it is computed by lame, mp3gain, vorbisgain, and all widely used ReplayGain programs.</p>
<p>This algorithm is only defined for input signals which size is larger than 0.05ms, otherwise an exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Replay Gain - A Proposed Standard, <a class="reference external" href="http://replaygain.hydrogenaudio.org">http://replaygain.hydrogenaudio.org</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Resample<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the resampled signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>inputSampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the input signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>outputSampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the output signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>quality</strong> (<em>integer ∈ [0, 4], default = 1</em>) :</dt>
<dd><p class="first last">the quality of the conversion, 0 for best quality</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm resamples the input signal to the desired sampling rate.</p>
<p>This algorithm is only supported if essentia has been compiled with Real=float, otherwise it will throw an exception. It may also throw an exception if there is an internal error in the SRC library during conversion.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Secret Rabbit Code, <a class="reference external" href="http://www.mega-nerd.com/SRC">http://www.mega-nerd.com/SRC</a></p>
<p class="last">[2] Resampling - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Resampling">http://en.wikipedia.org/wiki/Resampling</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmDescriptors<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>beats_position</strong> (<em>vector_real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>bpm</strong> (<em>real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>bpm_estimates</strong> (<em>vector_real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>bpm_intervals</strong> (<em>vector_real</em>) - See RhythmExtractor2013 algorithm documentation</li>
<li><strong>first_peak_bpm</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>first_peak_spread</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>first_peak_weight</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>second_peak_bpm</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>second_peak_spread</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
<li><strong>second_peak_weight</strong> (<em>real</em>) - See BpmHistogramDescriptors algorithm documentation</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>this algorithm computes low level rhythm features</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - input signal</li>
</td><td class="col-xs-2">
<li><strong>bpm</strong> (<em>real</em>) - the tempo estimation [bpm]</li>
<li><strong>ticks</strong> (<em>vector_real</em>) -  the estimated tick locations [s]</li>
<li><strong>estimates</strong> (<em>vector_real</em>) - the list of bpm estimates characterizing the bpm distribution for the signal [bpm]</li>
<li><strong>bpmIntervals</strong> (<em>vector_real</em>) - list of beats interval [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameHop</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the number of feature frames separating two evaluations</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the number audio samples used to compute a feature</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">the number of audio samples per features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lastBeatInterval</strong> (<em>real ∈ [0, ∞), default = 0.1</em>) :</dt>
<dd><p class="first last">the minimum interval between last beat and end of file [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberFrames</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the number of feature frames to buffer on</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tempoHints</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the optional list of initial beat locations, to favor the detection of pre-determined tempo period and beats alignment [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tolerance</strong> (<em>real ∈ [0, ∞), default = 0.24</em>) :</dt>
<dd><p class="first last">the minimum interval between two consecutive beats [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useBands</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether or not to use band energy as periodicity function</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>useOnset</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">whether or not to use onsets as periodicity function</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the tempo in bpm from an input signal, as well as the beat locations. The algorithm combines several periodicity functions and estimates beats using TempoTap and TempoTapTicks. It combines:
- onset detection functions based on high-frequency content (see OnsetDetection)
- complex-domain spectral difference function (see OnsetDetection)
- periodicity function based on energy bands (see FrequencyBands, TempoScaleBands)</p>
<p>Note that this algorithm is outdated in terms of beat tracking accuracy, and it is highly recommended to use RhythmExtractor2013 instead.</p>
<p>Quality: outdated (use RhythmExtractor2013 instead).</p>
<p>An exception is thrown if neither &quot;useOnset&quot; nor &quot;useBands&quot; are enabled (i.e. set to true).</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmExtractor2013<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - input signal</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) -  the estimated tick locations [s]</li>
<li><strong>confidence</strong> (<em>real</em>) - confidence with which the ticks are detected (ignore this value if using 'degara' method)</li>
<li><strong>bpm</strong> (<em>real</em>) - the tempo estimation [bpm]</li>
<li><strong>estimates</strong> (<em>vector_real</em>) - the list of bpm estimates characterizing the bpm distribution for the signal [bpm]</li>
<li><strong>bpmIntervals</strong> (<em>vector_real</em>) - list of beats interval [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">the fastest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>method</strong> (<em>string ∈ {multifeature, degara}, default = multifeature</em>) :</dt>
<dd><p class="first last">the method used for beat tracking</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">the slowest tempo to detect [bpm]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the beat locations and the confidence of their estimation given an input signal, as well as its tempo in bpm. The beat locations can be computed using:</p>
<blockquote>
<ul class="simple">
<li>'multifeature', the BeatTrackerMultiFeature algorithm</li>
<li>'degara', the BeatTrackerDegara algorithm (note that there is no confidence estimation for this method, the output confidence value is always 0)</li>
</ul>
</blockquote>
<p>See BeatTrackerMultiFeature and  BeatTrackerDegara algorithms for more details.</p>
<p>Note that the algorithm requires the sample rate of the input signal to be 44100 Hz in order to work correctly.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RhythmTransform<br>[streaming]

</th><td class="col-xs-2">
<li><strong>melBands</strong> (<em>vector_real</em>) - the energy in the melbands</li>
</td><td class="col-xs-2">
<li><strong>rhythm</strong> (<em>matrix_real</em>) - consecutive frames in the rhythm domain</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">the frame size to compute the rhythm trasform</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 32</em>) :</dt>
<dd><p class="first last">the hop size to compute the rhythm transform</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The Rhythm Transform algorithm is based on the rhythm transform as described in [1]. It computes a rhythmical representation of the input signal in the rhythm domain much like FFT computes a representation in the frequency domain. Additionally features as rhythmic centroid and MFCCs can be calculated from this rhythmic representation.
Note that parameters &quot;frameSize&quot; and &quot;hopSize&quot; are defined for the rhythm transformation (FFT transform on the rhythm space) and have a different meaning than the sizes in the temporal dimension.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Guaus and P. Herrera, &quot;The rhythm transform: towards a generic
rhythm description,&quot; in International Computer Music Conference (ICMC’05),
2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RMS<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>rms</strong> (<em>real</em>) - the root mean square of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm computes the Root Mean Square (quadratic mean) of an array of Reals.
RMS is not defined for empty arrays. In such case, an exception will be thrown
.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Root mean square - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Root_mean_square">http://en.wikipedia.org/wiki/Root_mean_square</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
RollOff<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input audio spectrum (must have more than one elements)</li>
</td><td class="col-xs-2">
<li><strong>rollOff</strong> (<em>real</em>) - the roll-off frequency [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cutoff</strong> (<em>real ∈ (0, 1), default = 0.85</em>) :</dt>
<dd><p class="first last">the ratio of total energy to attain before yielding the roll-off frequency</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal (used to normalize rollOff) [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the roll-off frequency of a spectrum. The roll-off frequency is defined as the frequency under which some percentage (cutoff) of the total energy of the spectrum is contained. The roll-off frequency can be used to distinguish between harmonic (below roll-off) and noisy sounds (above roll-off).</p>
<p>An exception is thrown if the input audio spectrum is smaller than 2.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SBic<br>[streaming]

</th><td class="col-xs-2">
<li><strong>features</strong> (<em>matrix_real</em>) - extracted features matrix (rows represent features, and columns represent frames of audio)</li>
</td><td class="col-xs-2">
<li><strong>segmentation</strong> (<em>vector_real</em>) - a list of frame indices that indicate where a segment of audio begins/ends (the indices of the first and last frame are also added to the list at the beginning and end, respectively)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>cpw</strong> (<em>real ∈ [0, ∞), default = 1.5</em>) :</dt>
<dd><p class="first last">complexity penalty weight</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inc1</strong> (<em>integer ∈ [1, ∞), default = 60</em>) :</dt>
<dd><p class="first last">first pass increment [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>inc2</strong> (<em>integer ∈ [1, ∞), default = 20</em>) :</dt>
<dd><p class="first last">second pass increment [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minLength</strong> (<em>integer ∈ [1, ∞), default = 10</em>) :</dt>
<dd><p class="first last">minimum length of a segment [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>size1</strong> (<em>integer ∈ [1, ∞), default = 300</em>) :</dt>
<dd><p class="first last">first pass window size [frames]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>size2</strong> (<em>integer ∈ [1, ∞), default = 200</em>) :</dt>
<dd><p class="first last">second pass window size [frames]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This descriptor segments the audio file into homogeneous portions using the Bayesian Information Criterion. The algorithm searches segments for which the feature vectors have the same probability distribution based on the implementation in [1]. The input matrix is assumed to have features along dim1 (horizontal) while frames along dim2 (vertical).</p>
<p>The segmentation is done in three phases: coarse segmentation, fine segmentation and segment validation. The first phase uses parameters 'size1' and 'inc1' to perform BIC segmentation. The second phase uses parameters 'size2' and 'inc2' to perform a local search for segmentation around the segmentation done by the first phase. Finally, the validation phase verifies that BIC differentials at segmentation points are positive as well as filters out any segments that are smaller than 'minLength'.</p>
<p>Because this algorithm takes as input feature vectors of frames, all units are in terms of frames. For example, if a 44100Hz audio signal is segmented as [0, 99, 199] with a frame size of 1024 and a hopsize of 512, this means, in the time domain, that the audio signal is segmented at [0s, 99*512/44100s, 199*512/44100s].</p>
<p>An exception is thrown if the input only contains one frame of features (i.e. second dimension is less than 2).</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Audioseg, <a class="reference external" href="http://audioseg.gforge.inria.fr">http://audioseg.gforge.inria.fr</a></p>
<p class="last">[2] G. Gravier, M. Betser, and M. Ben, Audio Segmentation Toolkit,
release 1.2, 2010. Available online:
<a class="reference external" href="https://gforge.inria.fr/frs/download.php/25187/audioseg-1.2.pdf">https://gforge.inria.fr/frs/download.php/25187/audioseg-1.2.pdf</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Scale<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the output audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>clipping</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">boolean flag whether to apply clipping or not</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>factor</strong> (<em>real ∈ [0, ∞), default = 10</em>) :</dt>
<dd><p class="first last">the multiplication factor by which the audio will be scaled</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxAbsValue</strong> (<em>real ∈ [0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum value above which to apply clipping</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm scales the audio by the specified factor, using clipping if required.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SilenceRate<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input frame</li>
</td><td class="col-xs-2">

</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>thresholds</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the threshold values</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a list of thresholds, this algorithm creates a equally-sized list of outputs and returns 1 on a given output whenever the instant power of the input frame is below the given output's respective threshold, and returns 0 otherwise. This is done for each frame with respect to all outputs. In other words, if a given frame's instant power is below several given thresholds, then each of the corresponding outputs will emit a 1.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SineModel<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must have more than 1 element)</li>
</td><td class="col-xs-2">
<li><strong>maxMagFreq</strong> (<em>real</em>) - the frequency with the largest magnitude [Hz]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the sine model without sine tracking.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SingleBeatLoudness<br>[streaming]

</th><td class="col-xs-2">
<li><strong>beat</strong> (<em>vector_real</em>) - the sliced beat</li>
</td><td class="col-xs-2">
<li><strong>loudness</strong> (<em>real</em>) - the beat's energy in the whole spectrum</li>
<li><strong>loudnessBandRatio</strong> (<em>vector_real</em>) - the beat's energy ratio on each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>beatDuration</strong> (<em>real ∈ (0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">the size of the window in which the beat will be restricted [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beatWindowDuration</strong> (<em>real ∈ (0, ∞), default = 0.1</em>) :</dt>
<dd><p class="first last">the size of the window in which to look for the beginning of the beat [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [0, 200, 400, 800, 1600, 3200, 22000]</em>) :</dt>
<dd><p class="first last">the bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>onsetStart</strong> (<em>string ∈ {sumEnergy,  peakEnergy}, default = sumEnergy</em>) :</dt>
<dd><p class="first last">criteria for finding the start of the beat</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the loudness of a single beat, on the whole frequency range and on each specified frequency band (bands by default: 0-200 Hz, 200-400 Hz, 400-800 Hz, 800-1600 Hz, 1600-3200 Hz, 3200-22000Hz, following E. Scheirer [1]). See the Loudness algorithm for a description of loudness.</p>
<p>This algorithm throws an exception either when parameter beatDuration is larger than beatWindowSize or when the size of the input beat is less than beatWindowSize plus beatDuration.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. D. Scheirer, &quot;Tempo and beat analysis of acoustic musical signals,&quot;
The Journal of the Acoustical Society of America, vol. 103, p. 588, 1998.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SingleGaussian<br>[streaming]

</th><td class="col-xs-2">
<li><strong>matrix</strong> (<em>matrix_real</em>) - the input data matrix (e.g. the MFCC descriptor over frames)</li>
</td><td class="col-xs-2">
<li><strong>mean</strong> (<em>vector_real</em>) - the mean of the values</li>
<li><strong>covariance</strong> (<em>matrix_real</em>) - the covariance matrix</li>
<li><strong>inverseCovariance</strong> (<em>matrix_real</em>) - the inverse of the covariance matrix</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm implements the single gaussian method. For example, using the single gaussian on descriptors like MFCC with the symmetric Kullback-Leibler divergence might be a much better option than just the mean and variance of the descriptors over a whole signal.</p>
<p>An exception is thrown if the covariance of the input matrix is singular or if the input matrix is empty.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Pampalk, &quot;Computational models of music similarity and their
application in music information retrieval,” Vienna University of
Technology, 2006.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Slicer<br>[streaming]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the frames of the sliced input signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>endTimes</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of end times for the slices you want to extract</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTimes</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">the list of start times for the slices you want to extract</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>timeUnits</strong> (<em>string ∈ {samples, seconds}, default = seconds</em>) :</dt>
<dd><p class="first last">the units of time of the start and end times</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns a vector of slices, which start and end times are given as parameters.</p>
<p>The parameters, &quot;startTimes&quot; and &quot;endTimes&quot; must be coherent. If these parameters differ in size, an exception is thrown. If a particular startTime is larger than its corresponding endTime, an exception is thrown.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralComplexity<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>spectralComplexity</strong> (<em>real</em>) - the spectral complexity of the input spectrum</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>real ∈ [0, ∞), default = 0.005</em>) :</dt>
<dd><p class="first last">the minimum spectral-peak magnitude that contributes to spectral complexity</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the spectral complexity of an spectrum of Reals. The spectral complexity is based on the number of peaks in the input spectrum.</p>
<p>It is recommended that the input &quot;spectrum&quot; be computed by the Spectrum algorithm. The input &quot;spectrum&quot; is passed to the SpectralPeaks algorithm and thus inherits its input requirements and exceptions.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] C. Laurier, O. Meyers, J. Serrà, M. Blech, P. Herrera, and X. Serra,
&quot;Indexing music by mood: design and integration of an automatic
content-based annotator,&quot; Multimedia Tools and Applications, vol. 48,
no. 1, pp. 161–184, 2009.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralContrast<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio spectrum</li>
</td><td class="col-xs-2">
<li><strong>spectralContrast</strong> (<em>vector_real</em>) - the spectral contrast coefficients</li>
<li><strong>spectralValley</strong> (<em>vector_real</em>) - the magnitudes of the valleys</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ [2, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the size of the fft frames</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>highFrequencyBound</strong> (<em>real ∈ (0, ∞), default = 11000</em>) :</dt>
<dd><p class="first last">the upper bound of the highest band</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>lowFrequencyBound</strong> (<em>real ∈ [0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">the lower bound of the lowest band</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>neighbourRatio</strong> (<em>real ∈ (0, 1], default = 0.4</em>) :</dt>
<dd><p class="first last">the ratio of the bins in the sub band used to calculate the peak and valley</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberBands</strong> (<em>integer ∈ (0, ∞), default = 6</em>) :</dt>
<dd><p class="first last">the number of bands in the filter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 22050</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>staticDistribution</strong> (<em>real ∈ [0, 1], default = 0.15</em>) :</dt>
<dd><p class="first last">the ratio of the bins to distribute equally</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>The Spectral Contrast feature is based on the Octave Based Spectral Contrast feature as described in [1]. The version implemented here is a modified version to improve discriminative power and robustness. The modifications are described in [2].</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] D.-N. Jiang, L. Lu, H.-J. Zhang, J.-H. Tao, and L.-H. Cai, &quot;Music type
classification by spectral contrast feature,&quot; in IEEE International
Conference on Multimedia and Expo (ICME’02), 2002, vol. 1, pp. 113–116.</p>
<p class="last">[2] V. Akkermans, J. Serrà, and P. Herrera, &quot;Shape-based spectral contrast
descriptor,&quot; in Sound and Music Computing Conference (SMC’09), 2009,
pp. 143–148.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralPeaks<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum</li>
</td><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>magnitudeThreshold</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">peaks below this given threshold are not outputted</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">the maximum frequency of the range to evaluate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxPeaks</strong> (<em>integer ∈ [1, ∞), default = 100</em>) :</dt>
<dd><p class="first last">the maximum number of returned peaks</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the minimum frequency of the range to evaluate [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>orderBy</strong> (<em>string ∈ {frequency, magnitude}, default = frequency</em>) :</dt>
<dd><p class="first last">the ordering type of the outputted peaks (ascending by frequency or descending by magnitude)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts peaks from a spectrum. It is important to note that the peak algorithm is independent of an input that is linear or in dB, so one has to adapt the threshold to fit with the type of data fed to it. The algorithm relies on PeakDetection algorithm which is run with parabolic interpolation [1]. The exactness of the peak-searching depends heavily on the windowing type. It gives best results with dB input, a blackman-harris 92dB window and interpolation set to true. According to [1], spectral peak frequencies tend to be about twice as accurate when dB magnitude is used rather than just linear magnitude. For further information about the peak detection, see the description of the PeakDetection algorithm.</p>
<p>It is recommended that the input &quot;spectrum&quot; be computed by the Spectrum algorithm. This algorithm uses PeakDetection. See documentation for possible exceptions and input requirements on input &quot;spectrum&quot;.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Peak Detection,
<a class="reference external" href="http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html">http://ccrma.stanford.edu/~jos/parshl/Peak_Detection_Steps_3.html</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SpectralWhitening<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the audio linear spectrum</li>
<li><strong>frequencies</strong> (<em>vector_real</em>) - the spectral peaks' linear frequencies</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the spectral peaks' linear magnitudes</li>
</td><td class="col-xs-2">
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the whitened spectral peaks' linear magnitudes</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 5000</em>) :</dt>
<dd><p class="first last">max frequency to apply whitening to [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Performs spectral whitening of spectral peaks of a given spectrum. The algorithm works in dB scale, but the conversion is done by the algorithm so input should be in linear scale. The concept of 'whitening' refers to 'white noise' or a non-zero flat spectrum. It first computes a spectral envelope similar to the 'true envelope' in [1], and then modifies the amplitude of each peak relative to the envelope. For example, the predominant peaks will have a value close to 0dB because they are very close to the envelope. On the other hand, minor peaks between significant peaks will have lower amplitudes such as -30dB.</p>
<p>The input &quot;frequencies&quot; and &quot;magnitudes&quot; can be computed using the SpectralPeaks algorithm.</p>
<p>An exception is thrown if the input frequency and magnitude input vectors are of different size.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] A. Röbel and X. Rodet, &quot;Efficient spectral envelope estimation and its
application to pitch shifting and envelope preservation,&quot; in International
Conference on Digital Audio Effects (DAFx’05), 2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Spectrum<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the magnitude spectrum of the input audio signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [1, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the expected size of the input audio signal (this is an optional parameter to optimize memory allocation)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm calculates the magnitude spectrum of an array of Reals. The resulting magnitude spectrum has a size which is half the size of the input array plus one.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Frequency spectrum - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Frequency_spectrum">http://en.wikipedia.org/wiki/Frequency_spectrum</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Spline<br>[streaming]

</th><td class="col-xs-2">
<li><strong>x</strong> (<em>real</em>) - the input coordinate (x-axis)</li>
</td><td class="col-xs-2">
<li><strong>y</strong> (<em>real</em>) - the value of the spline at x</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>beta1</strong> (<em>real ∈ [0, ∞], default = 1</em>) :</dt>
<dd><p class="first last">the skew or bias parameter (only available for type beta)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>beta2</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the tension parameter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {b, beta, quadratic}, default = b</em>) :</dt>
<dd><p class="first last">the type of spline to be computed</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>xPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the x-coordinates where data is specified (the points must be arranged in ascending order and cannot contain duplicates)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>yPoints</strong> (<em>vector_real, default = [0, 1]</em>) :</dt>
<dd><p class="first last">the y-coordinates to be interpolated (i.e. the known data)</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Evaluates a piecewise spline of type b, beta or quadratic.
The input value, i.e. the point at which the spline is to be evaluated typically should be between xPoins[0] and xPoinst[size-1]. If the value lies outside this range, extrapolation is used.
Regarding spline types:</p>
<blockquote>
<ul class="simple">
<li>B: evaluates a cubic B spline approximant.</li>
<li>Beta: evaluates a cubic beta spline approximant. For beta splines parameters 'beta1' and 'beta2' can be supplied. For no bias set beta1 to 1 and for no tension set beta2 to 0. Note that if beta1=1 and beta2=0, the cubic beta becomes a cubic B spline. On the other hand if beta1=1 and beta2 is large the beta spline turns into a linear spline.</li>
<li>Quadratic: evaluates a piecewise quadratic spline at a point. Note that size of input must be odd.</li>
</ul>
</blockquote>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Spline interpolation - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Spline_interpolation">http://en.wikipedia.org/wiki/Spline_interpolation</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StartStopSilence<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frames</li>
</td><td class="col-xs-2">
<li><strong>startFrame</strong> (<em>integer</em>) - number of the first non-silent frame</li>
<li><strong>stopFrame</strong> (<em>integer</em>) - number of the last non-silent frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>integer ∈ (-∞, 0]), default = -60</em>) :</dt>
<dd><p class="first last">the threshold below which average energy is defined as silence [dB]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm outputs the frame at which sound begins and the frame at which sound ends.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StereoDemuxer<br>[streaming]

</th><td class="col-xs-2">
<li><strong>audio</strong> (<em>stereosample</em>) - the input stereo signal</li>
</td><td class="col-xs-2">
<li><strong>left</strong> (<em>real</em>) - the left channel of the audio signal</li>
<li><strong>right</strong> (<em>real</em>) - the right channel of the audio signal</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>Given a stereo signal, this algorithm outputs left and right channel separately.If the signal is monophonic, it outputs a zero signal on the right channel.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StrongDecay<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>strongDecay</strong> (<em>real</em>) - the strong decay</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm extracts the Strong Decay of an audio signal. The Strong Decay is built from the non-linear combination of the signal energy and the signal temporal centroid, the latter being the balance of the absolute value of the signal. A signal containing a temporal centroid near its start boundary and a strong energy is said to have a strong decay.</p>
<p>This algorithm is not defined for zero signals (i.e. silence) nor when the signal's size is less than two, as it could not compute its centroid.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] F. Gouyon and P. Herrera, &quot;Exploration of techniques for automatic
labeling of audio drum tracks instruments,&quot; in MOSART: Workshop on Current
Directions in Computer Music, 2001.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
StrongPeak<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must be greater than one element and cannot contain negative values)</li>
</td><td class="col-xs-2">
<li><strong>strongPeak</strong> (<em>real</em>) - the Strong Peak ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm extracts the Strong Peak from an audio spectrum. The Strong Peak is defined as the ratio between the spectrum's maximum peak's magnitude and the &quot;bandwidth&quot; of the peak above a threshold (half its amplitude). This ratio reveals whether the spectrum presents a very &quot;pronounced&quot; maximum peak (i.e. the thinner and the higher the maximum of the spectrum is, the higher the ratio value).</p>
<p>Note that &quot;bandwidth&quot; is defined as the width of the peak in the log10-frequency domain. This is different than as implemented in [1]. Using the log10-frequency domain allows this algorithm to compare strong peaks at lower frequencies with those from higher frequencies.</p>
<p>An exception is thrown if the input spectrum contains less than two elements.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] F. Gouyon and P. Herrera, &quot;Exploration of techniques for automatic
labeling of audio drum tracks instruments,” in MOSART: Workshop on Current
Directions in Computer Music, 2001.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SuperFluxExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>onsets</strong> (<em>vector_real</em>) - lists of onsets</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>combine</strong> (<em>real ∈ (0, ∞), default = 20</em>) :</dt>
<dd><p class="first last">time threshold for double onsets detections (ms)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the frame size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">the hop size for computing low level features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>ratioThreshold</strong> (<em>real ∈ [0, ∞), default = 16</em>) :</dt>
<dd><p class="first last">ratio threshold for peak-picking compared to novelty_signal/novelty_average, 0  disable it ,  for low energy onsets</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">threshold for peak peaking compared to the difference of novelty_signal and average_signal ,  for peaking onsets in ambien noise</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<dl class="docutils">
<dt>This algorithm extracts onsets from audio file following SuperFlux algorithm [1] adapted from python code available in [2]</dt>
<dd>[1] &quot;Maximum Filter Vibrato Suppression for Onset Detection&quot; by Sebastian Böck and Gerhard Widmer in Proceedings of the 16th International Conference on Digital Audio Effects (DAFx-13), Maynooth, Ireland, September 2013                                                       [2] <a class="reference external" href="https://github.com/CPJKU/SuperFlux/">https://github.com/CPJKU/SuperFlux/</a></dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SuperFluxNovelty<br>[streaming]

</th><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the input bands spectrogram</li>
</td><td class="col-xs-2">
<li><strong>Differences</strong> (<em>real</em>) - SuperFluxNovelty input</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>binWidth</strong> (<em>integer ∈ [3, ∞), default = 3</em>) :</dt>
<dd><p class="first last">height(n of frequency bins) of the SuperFluxNoveltyFilter</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameWidth</strong> (<em>integer ∈ (0, ∞), default = 2</em>) :</dt>
<dd><p class="first last">number of frame for differentiation</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Novelty curve from Superflux algorithm (see SuperFluxExtractor for references)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
SuperFluxPeaks<br>[streaming]

</th><td class="col-xs-2">
<li><strong>novelty</strong> (<em>real</em>) - the input novelty</li>
</td><td class="col-xs-2">
<li><strong>peaks</strong> (<em>vector_real</em>) - peaks instants [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>combine</strong> (<em>real ∈ (0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">ms for onset combination</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameRate</strong> (<em>real ∈ (0, ∞), default = 172</em>) :</dt>
<dd><p class="first last">frameRate</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pre_avg</strong> (<em>real ∈ (0, ∞), default = 100</em>) :</dt>
<dd><p class="first last">use N miliseconds past information for moving average</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>pre_max</strong> (<em>real ∈ (0, ∞), default = 30</em>) :</dt>
<dd><p class="first last">use N miliseconds past information for moving maximum</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>ratioThreshold</strong> (<em>real ∈ [0, ∞), default = 16</em>) :</dt>
<dd><p class="first last">ratio threshold for peak-picking compared to novelty_signal/novelty_average, 0  disable it ,  for low energy onsets</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [0, ∞), default = 0.05</em>) :</dt>
<dd><p class="first last">threshold for peak peaking compared to the difference of novelty_signal and average_signal ,  for peaking onsets in ambien noise</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Peak peaking from Superflux algorithm (see SuperFluxExtractor for references)</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TCToTotal<br>[streaming]

</th><td class="col-xs-2">
<li><strong>envelope</strong> (<em>real</em>) - the envelope of the signal (its length must be greater than 1</li>
</td><td class="col-xs-2">
<li><strong>TCToTotal</strong> (<em>real</em>) - the temporal centroid to total length ratio</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the ratio of the temporal centroid to the total length of a signal envelope. This ratio shows how the sound is 'balanced'. Its value is close to 0 if most of the energy lies at the beginning of the sound (e.g. decrescendo or impulsive sounds), close to 0.5 if the sound is symetric (e.g. 'delta unvarying' sounds), and close to 1 if most of the energy lies at the end of the sound (e.g. crescendo sounds).</p>
<p>Please note that the TCToTotal ratio is not defined for a zero signal (a signal consisting of only zeros), nor it is defined for a signal of less than 2 elements.An exception is thrown if the given envelope's size is not larger than 1. And also if the integral of the input envelope is 0 (i.e. envelope is only zeros or if its sum is 0).</p>
<p>This algorithm is intended to be plugged after the Envelope algorithm</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoScaleBands<br>[streaming]

</th><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the audio power spectrum divided into bands</li>
</td><td class="col-xs-2">
<li><strong>scaledBands</strong> (<em>vector_real</em>) - the output bands after scaling</li>
<li><strong>cumulativeBands</strong> (<em>real</em>) - cumulative sum of the output bands before scaling</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>bandsGain</strong> (<em>vector_real, default = [2, 3, 2, 1, 1.20000004768, 2, 3, 2.5]</em>) :</dt>
<dd><p class="first last">gain for each bands</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameTime</strong> (<em>real ∈ (0, ∞), default = 512</em>) :</dt>
<dd><p class="first last">the frame rate in samples</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes features for tempo tracking. The output features should be used with the TempoTap algorithm. See standard_rhythmextractor_tempotap in examples folder.</p>
<p>An exception is thrown if less than 1 band is given. An exception is also thrown if the there are not an equal number of bands given as band-gains given.</p>
<p>Quality: outdated (the associated TempoTap algorithm is outdated, however it can be potentially used as an onset detection function for other tempo estimation algorithms although no evaluation has been done)</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Algorithm by Fabien Gouyon and Simon Dixon. There is no reference at
the time of this writing.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTap<br>[streaming]

</th><td class="col-xs-2">
<li><strong>featuresFrame</strong> (<em>vector_real</em>) - input temporal features of a frame</li>
</td><td class="col-xs-2">
<li><strong>periods</strong> (<em>vector_real</em>) - list of tempo estimates found for each input feature, in frames</li>
<li><strong>phases</strong> (<em>vector_real</em>) - list of initial phase candidates found for each input feature, in frames</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameHop</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">number of feature frames separating two evaluations</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">number of audio samples in a frame</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">fastest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">slowest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>numberFrames</strong> (<em>integer ∈ (0, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">number of feature frames to buffer on</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tempoHints</strong> (<em>vector_real, default = []</em>) :</dt>
<dd><p class="first last">optional list of initial beat locations, to favor the detection of pre-determined tempo period and beats alignment [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates the periods and phases of a periodic signal, represented by a sequence of values of any number of detection functions, such as energy bands, onsets locations, etc. It requires to be sequentially run on a vector of such values (&quot;featuresFrame&quot;) for each particular audio frame in order to get estimations related to that frames. The estimations are done for each detection function separately, utilizing the latest &quot;frameHop&quot; frames, including the present one, to compute autocorrelation. Empty estimations will be returned until enough frames are accumulated in the algorithm's buffer.
The algorithm uses elements of the following beat-tracking methods:</p>
<blockquote>
<ul class="simple">
<li>BeatIt, elaborated by Fabien Gouyon and Simon Dixon (input features) [1]</li>
<li>Multi-comb filter with Rayleigh weighting, Mathew Davies [2]</li>
</ul>
</blockquote>
<p>Parameter &quot;maxTempo&quot; should be 20bpm larger than &quot;minTempo&quot;, otherwise an exception is thrown. The same applies for parameter &quot;frameHop&quot;, which should not be greater than numberFrames. If the supplied &quot;tempoHints&quot; did not match any realistic bpm value, an exeception is thrown.</p>
<p>This algorithm is thought to provide the input for TempoTapTicks algorithm. The &quot;featureFrame&quot; vectors can be formed by Multiplexer algorithm in the case of combining different features.</p>
<p>Quality: outdated (use TempoTapDegara instead)</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] F. Gouyon, &quot;A computational approach to rhythm description: Audio
features for the computation of rhythm periodicity functions and their use
in tempo induction and music content processing,&quot; UPF, Barcelona, Spain,
2005.</p>
<p class="last">[2] M. Davies and M. Plumbley, &quot;Causal tempo tracking of audio,&quot; in
International Symposium on Music Information Retrieval (ISMIR'04), 2004.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTapDegara<br>[streaming]

</th><td class="col-xs-2">
<li><strong>onsetDetections</strong> (<em>real</em>) - per-frame onset detection values</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>real</em>) - the list of resulting ticks [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxTempo</strong> (<em>integer ∈ [60, 250], default = 208</em>) :</dt>
<dd><p class="first last">fastest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minTempo</strong> (<em>integer ∈ [40, 180], default = 40</em>) :</dt>
<dd><p class="first last">slowest tempo allowed to be detected [bpm]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>resample</strong> (<em>string ∈ {none, x2, x3, x4}, default = none</em>) :</dt>
<dd><p class="first last">use upsampling of the onset detection function (may increase accuracy)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRateODF</strong> (<em>real ∈ (0, ∞), default = 86.1328</em>) :</dt>
<dd><p class="first last">the sampling rate of the onset detection function [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm estimates beat positions given an onset detection function.  The detection function is partitioned into 6-second frames with a 1.5-second increment, and the autocorrelation is computed for each frame, and is weighted by a tempo preference curve [2]. Periodicity estimations are done frame-wisely, searching for the best match with the Viterbi algorith [3]. The estimated periods are then passed to the probabilistic beat tracking algorithm [1], which computes beat positions.</p>
<p>Note that the input values of the onset detection functions must be non-negative otherwise an exception is thrown. Parameter &quot;maxTempo&quot; should be 20bpm larger than &quot;minTempo&quot;, otherwise an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] Degara, N., Rua, E. A., Pena, A., Torres-Guijarro, S., Davies, M. E., &amp; Plumbley, M. D. (2012). Reliability-informed beat tracking of musical signals. Audio, Speech, and Language Processing, IEEE Transactions on, 20(1), 290-301.
[2] Davies, M. E., &amp; Plumbley, M. D. (2007). Context-dependent beat tracking of musical audio. Audio, Speech, and Language Processing, IEEE Transactions on, 15(3), 1009-1020.
[3] Stark, A. M., Davies, M. E., &amp; Plumbley, M. D. (2009, September). Real-time beatsynchronous analysis of musical audio. In 12th International Conference on Digital Audio Effects (DAFx-09), Como, Italy.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTapMaxAgreement<br>[streaming]

</th><td class="col-xs-2">
<li><strong>tickCandidates</strong> (<em>vector_vector_real</em>) - the tick candidates estimated using different beat trackers (or features) [s]</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) - the list of resulting ticks [s]</li>
<li><strong>confidence</strong> (<em>real</em>) - confidence with which the ticks were detected [0, 5.32]</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm estimates beat positions and confidence of their estimation based on the maximum mutual agreement between given beat postion candidates, estimated by different beat trackers (or using different features) [1,2].</p>
<p>Note that the input tick times should be in ascending order and that they cannot contain negative values otherwise an exception will be thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] J. R. Zapata, A. Holzapfel, M. E. Davies, J. L. Oliveira, and
F. Gouyon, &quot;Assigning a confidence threshold on automatic beat annotation
in large datasets,&quot; in International Society for Music Information
Retrieval Conference (ISMIR’12), 2012.</p>
<p class="last">[2] A. Holzapfel, M. E. Davies, J. R. Zapata, J. L. Oliveira, and
F. Gouyon, &quot;Selective sampling for beat tracking evaluation,&quot; IEEE
Transactions on Audio, Speech, and Language Processing, vol. 13, no. 9,
pp. 2539-2548, 2012.</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TempoTapTicks<br>[streaming]

</th><td class="col-xs-2">
<li><strong>periods</strong> (<em>vector_real</em>) - tempo period candidates for the current frame, in frames</li>
<li><strong>phases</strong> (<em>vector_real</em>) - tempo ticks phase candidates for the current frame, in frames</li>
</td><td class="col-xs-2">
<li><strong>ticks</strong> (<em>vector_real</em>) - the list of resulting ticks [s]</li>
<li><strong>matchingPeriods</strong> (<em>vector_real</em>) - list of matching periods [s]</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameHop</strong> (<em>integer ∈ (0, ∞), default = 512</em>) :</dt>
<dd><p class="first last">number of feature frames separating two evaluations</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 256</em>) :</dt>
<dd><p class="first last">number of audio samples per features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm builds the list of ticks from the period and phase candidates given by the TempoTap algorithm.</p>
<p>Quality: outdated (use TempoTapDegara instead)</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] F. Gouyon, &quot;A computational approach to rhythm description: Audio
features for the computation of rhythm periodicity functions and their use
in tempo induction and music content processing,&quot; UPF, Barcelona, Spain,
2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TonalExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>chords_changes_rate</strong> (<em>real</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_histogram</strong> (<em>vector_real</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_key</strong> (<em>string</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_number_rate</strong> (<em>real</em>) - See ChordsDescriptors algorithm documentation</li>
<li><strong>chords_progression</strong> (<em>string</em>) - See ChordsDetection algorithm documentation</li>
<li><strong>chords_scale</strong> (<em>string</em>) - See ChordsDetection algorithm documentation</li>
<li><strong>chords_strength</strong> (<em>real</em>) - See ChordsDetection algorithm documentation</li>
<li><strong>hpcp</strong> (<em>vector_real</em>) - See HPCP algorithm documentation</li>
<li><strong>hpcp_highres</strong> (<em>vector_real</em>) - See HPCP algorithm documentation</li>
<li><strong>key_key</strong> (<em>string</em>) - See Key algorithm documentation</li>
<li><strong>key_scale</strong> (<em>string</em>) - See Key algorithm documentation</li>
<li><strong>key_strength</strong> (<em>real</em>) - See Key algorithm documentation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 4096</em>) :</dt>
<dd><p class="first last">the framesize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hopsize for computing tonal features</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>tuningFrequency</strong> (<em>real ∈ (0, ∞), default = 440</em>) :</dt>
<dd><p class="first last">the tuning frequency of the input signal</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts tonal features</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TriangularBands<br>[streaming]

</th><td class="col-xs-2">
<li><strong>spectrum</strong> (<em>vector_real</em>) - the input spectrum (must be greater than size one)</li>
</td><td class="col-xs-2">
<li><strong>bands</strong> (<em>vector_real</em>) - the energy in each band</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frequencyBands</strong> (<em>vector_real, default = [21.533203125, 43.06640625, 64.599609375, 86.1328125, 107.666015625, 129.19921875, 150.732421875, 172.265625, 193.798828125, 215.33203125, 236.865234375, 258.3984375, 279.931640625, 301.46484375, 322.998046875, 344.53125, 366.064453125, 387.59765625, 409.130859375, 430.6640625, 452.197265625, 473.73046875, 495.263671875, 516.796875, 538.330078125, 559.86328125, 581.396484375, 602.9296875, 624.462890625, 645.99609375, 667.529296875, 689.0625, 710.595703125, 732.12890625, 753.662109375, 775.1953125, 796.728515625, 839.794921875, 861.328125, 882.861328125, 904.39453125, 925.927734375, 968.994140625, 990.52734375, 1012.06054688, 1055.12695312, 1076.66015625, 1098.19335938, 1141.25976562, 1184.32617188, 1205.859375, 1248.92578125, 1270.45898438, 1313.52539062, 1356.59179688, 1399.65820312, 1442.72460938, 1485.79101562, 1528.85742188, 1571.92382812, 1614.99023438, 1658.05664062, 1701.12304688, 1765.72265625, 1808.7890625, 1873.38867188, 1916.45507812, 1981.0546875, 2024.12109375, 2088.72070312, 2153.3203125, 2217.91992188, 2282.51953125, 2347.11914062, 2411.71875, 2497.8515625, 2562.45117188, 2627.05078125, 2713.18359375, 2799.31640625, 2885.44921875, 2950.04882812, 3036.18164062, 3143.84765625, 3229.98046875, 3316.11328125, 3423.77929688, 3509.91210938, 3617.578125, 3725.24414062, 3832.91015625, 3940.57617188, 4069.77539062, 4177.44140625, 4306.640625, 4435.83984375, 4565.0390625, 4694.23828125, 4844.97070312, 4974.16992188, 5124.90234375, 5275.63476562, 5426.3671875, 5577.09960938, 5749.36523438, 5921.63085938, 6093.89648438, 6266.16210938, 6459.9609375, 6653.75976562, 6847.55859375, 7041.35742188, 7256.68945312, 7450.48828125, 7687.35351562, 7902.68554688, 8139.55078125, 8376.41601562, 8613.28125, 8871.6796875, 9130.078125, 9388.4765625, 9668.40820312, 9948.33984375, 10249.8046875, 10551.2695312, 10852.734375, 11175.7324219, 11498.7304688, 11843.2617188, 12187.7929688, 12553.8574219, 12919.921875, 13285.9863281, 13673.5839844, 14082.7148438, 14491.8457031, 14922.5097656, 15353.1738281, 15805.3710938, 16257.5683594]</em>) :</dt>
<dd><p class="first last">list of frequency ranges into which the spectrum is divided (these must be in ascending order and connot contain duplicates),each triangle is build as x(i-1)=, x(i)=1, x(i+1)=0 over i, the resulting number of bands is size of input array - 2</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>log</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">taking log10 (1 + magnitude) in each band</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the audio signal [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm computes the energy of an input spectrum for an arbitrary number of overlapping Triangular frequency bands. For each band the power-spectrum (mag-squared) is summed.</p>
<p>Parameter &quot;TriangularBands&quot; must contain at least 2 frequencies, they all must be positive and must be ordered ascentdantly, otherwise an exception will be thrown. TriangularBands is only defined for spectrum, which size is greater than 1.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Trimmer<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the trimmed signal</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>endTime</strong> (<em>real ∈ [0, ∞), default = 1e+06</em>) :</dt>
<dd><p class="first last">the end time of the slice you want to extract [s]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the sampling rate of the input audio signal [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>startTime</strong> (<em>real ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the start time of the slice you want to extract [s]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given an audio signal, this algorithm it extracts a slice of the signal between startTime and endTime.
Giving &quot;startTime&quot; greater than &quot;endTime&quot; will raise an exception.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Tristimulus<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the harmonic peaks ordered by frequency</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the harmonic peaks ordered by frequency</li>
</td><td class="col-xs-2">
<li><strong>tristimulus</strong> (<em>vector_real</em>) - a three-element vector that measures the mixture of harmonics of the given spectrum</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the tristimulus of a signal given its harmonic peaks. The tristimulus has been introduced as a timbre equivalent to the color attributes in the vision. The tristimulus is composed of three different types of energy ratio allowing for a fine-grained description of the first harmonic of the spectrum, which are perceptually more salient.</p>
<p>Tristimulus is intended to be fed by the output of the HarmonicPeaks algorithm. The algorithm throws an exception when the input frequencies are not in ascending order and/or if the input vectors are of different sizes.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Tristimulus (audio) - Wikipedia, the free encyclopedia
<a class="reference external" href="http://en.wikipedia.org/wiki/Tristimulus_(audio">http://en.wikipedia.org/wiki/Tristimulus_(audio</a>)</p>
<p class="last">[2] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TuningFrequency<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frequencies</strong> (<em>vector_real</em>) - the frequencies of the spectral peaks [Hz]</li>
<li><strong>magnitudes</strong> (<em>vector_real</em>) - the magnitudes of the spectral peaks</li>
</td><td class="col-xs-2">
<li><strong>tuningFrequency</strong> (<em>real</em>) - the tuning frequency [Hz]</li>
<li><strong>tuningCents</strong> (<em>real</em>) - the deviation from 440 Hz (between -35 to 65 cents)</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>resolution</strong> (<em>real ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">resolution in cents (logarithmic scale, 100 cents = 1 semitone) for tuning frequency determination</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a sequence/set of spectral peaks, this algorithm estimates the tuning frequency of a given song. The result is the tuning frequency in Hz, and its distance from 440Hz in cents. This version is slightly adapted from the original algorithm by Emilia Gomez, but gives the same results.</p>
<p>Input vectors should have the same size, otherwise an exception is thrown. This algorithm should be given the outputs of the spectral peaks algorithm.</p>
<p>Application: Western vs non-western music classification, key estimation, HPCP computation, tonal similarity.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] E. Gómez, &quot;Key estimation from polyphonic audio,&quot; in Music Information
Retrieval Evaluation Exchange (MIREX’05), 2005.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
TuningFrequencyExtractor<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>real</em>) - the input audio signal</li>
</td><td class="col-xs-2">
<li><strong>tuningFrequency</strong> (<em>real</em>) - the computed tuning frequency</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>frameSize</strong> (<em>integer ∈ (0, ∞), default = 4096</em>) :</dt>
<dd><p class="first last">the frameSize for computing tuning frequency</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>hopSize</strong> (<em>integer ∈ (0, ∞), default = 2048</em>) :</dt>
<dd><p class="first last">the hopsize for computing tuning frequency</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>this algorithm extracts the tuning frequency of an audio signal</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
UnaryOperator<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array transformed by unary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {identity, abs, log10, log, ln, lin2db, db2lin, sin, cos, sqrt, square}, default = identity</em>) :</dt>
<dd><p class="first last">the type of the unary operator to apply to input array</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a vector of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>log and ln are equivalent to the natural logarithm</li>
<li>for log, ln, log10 and lin2db, x is clipped to 1e-30 for x&lt;1e-30</li>
<li>for x&lt;0, sqrt(x) is invalid</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
UnaryOperatorStream<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>real</em>) - the input array transformed by unary operation</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>scale</strong> (<em>real ∈ (-∞, ∞), default = 1</em>) :</dt>
<dd><p class="first last">multiply result by factor</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>shift</strong> (<em>real ∈ (-∞, ∞), default = 0</em>) :</dt>
<dd><p class="first last">shift result by value (add value)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {identity, abs, log10, log, ln, lin2db, db2lin, sin, cos, sqrt, square}, default = identity</em>) :</dt>
<dd><p class="first last">the type of the unary operator to apply to input array</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a vector of Reals, this algorithm will perform basic arithmetical operations on it, element by element.
Note:</p>
<blockquote>
<ul class="simple">
<li>log and ln are equivalent to the natural logarithm</li>
<li>for log, ln, log10 and lin2db, x is clipped to 1e-30 for x&lt;1e-30</li>
<li>for x&lt;0, sqrt(x) is invalid</li>
<li>scale and shift parameters define linear transformation to be applied to the resulting elements</li>
</ul>
</blockquote>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Variance<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the input array</li>
</td><td class="col-xs-2">
<li><strong>variance</strong> (<em>real</em>) - the variance of the input array</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm calculates the variance of an array of Reals.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
VectorRealAccumulator<br>[streaming]

</th><td class="col-xs-2">
<li><strong>data</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_vector_real</em>) - the accumulated signal in one single frame</li>
</td><td class="col-xs-2">

</td><td class="col-xs-5">
<p>This algorithm takes a stream of Real values and outputs them as a single vector when the end of the stream is reached.</p>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Vibrato<br>[streaming]

</th><td class="col-xs-2">
<li><strong>pitch</strong> (<em>vector_real</em>) - the pitch trajectory [Hz].</li>
</td><td class="col-xs-2">
<li><strong>vibratoFrequency</strong> (<em>vector_real</em>) - estimated vibrato frquency [Hz]; zero if no vibrato was detected.</li>
<li><strong>vibratoExtend</strong> (<em>vector_real</em>) - estimated vibrato frquency [Hz]; zero if no vibrato was detected.</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxExtend</strong> (<em>real ∈ (0, ∞), default = 250</em>) :</dt>
<dd><p class="first last">maximum considered vibrato extend [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>maxFrequency</strong> (<em>real ∈ (0, ∞), default = 8</em>) :</dt>
<dd><p class="first last">maximum considered vibrato frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minExtend</strong> (<em>real ∈ (0, ∞), default = 50</em>) :</dt>
<dd><p class="first last">minimum considered vibrato extend [cents]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>minFrequency</strong> (<em>real ∈ (0, ∞), default = 4</em>) :</dt>
<dd><p class="first last">minimum considered vibrato frequency [Hz]</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 344.531</em>) :</dt>
<dd><p class="first last">sample rate of the input pitch contour</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>Given a pitch contour [Hz], this algorithm detects the presence of vibrato and estimates the corresponding parameters. The result is the vibrato frequency in Hz and the extend (peak to peak) in cents. If no vibrato is detected in a frame, the output of both values is zero.</p>
<p>This algorithm should be given the outputs of a pitch estimator, i.e. PredominantMelody, PitchYinFFT or PitchMelodia and the corresponding sample rate with which it was computed.</p>
<p>The algorithm is an extended version of the vocal vibrato detection in PerdominantMelody.</p>
<dl class="docutils">
<dt>References:</dt>
<dd>[1] J. Salamon and E. Gómez, &quot;Melody extraction from polyphonic music
signals using pitch contour characteristics,&quot; IEEE Transactions on Audio,
Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, 2012.</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
WarpedAutoCorrelation<br>[streaming]

</th><td class="col-xs-2">
<li><strong>array</strong> (<em>vector_real</em>) - the array to be analyzed</li>
</td><td class="col-xs-2">
<li><strong>warpedAutoCorrelation</strong> (<em>vector_real</em>) - the warped auto-correlation vector</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>maxLag</strong> (<em>integer ∈ (0, ∞), default = 1</em>) :</dt>
<dd><p class="first last">the maximum lag for which the auto-correlation is computed (inclusive) (must be smaller than signal size)</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>sampleRate</strong> (<em>real ∈ (0, ∞), default = 44100</em>) :</dt>
<dd><p class="first last">the audio sampling rate [Hz]</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the warped auto-correlation of an audio signal. The implementation is an adapted version of K. Schmidt's implementation of the matlab algorithm from the 'warped toolbox' by Aki Harma and Matti Karjalainen found [2]. For a detailed explanation of the algorithm, see [1].
This algorithm is only defined for positive lambda = 1.0674*sqrt(2.0*atan(0.00006583*sampleRate)/PI) - 0.1916, thus it will throw an exception when the supplied sampling rate does not pass the requirements.
If maxLag is larger than the size of the input array, an exception is thrown.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] A. Härmä, M. Karjalainen, L. Savioja, V. Välimäki, U. K. Laine, and
J. Huopaniemi, &quot;Frequency-Warped Signal Processing for Audio Applications,&quot;
JAES, vol. 48, no. 11, pp. 1011–1031, 2000.</p>
<p class="last">[2] WarpTB - Matlab Toolbox for Warped DSP
<a class="reference external" href="http://www.acoustics.hut.fi/software/warp">http://www.acoustics.hut.fi/software/warp</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
Windowing<br>[streaming]

</th><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the input audio frame</li>
</td><td class="col-xs-2">
<li><strong>frame</strong> (<em>vector_real</em>) - the windowed audio frame</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>size</strong> (<em>integer ∈ [2, ∞), default = 1024</em>) :</dt>
<dd><p class="first last">the window size</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>type</strong> (<em>string ∈ {hamming, hann, triangular, square, blackmanharris62, blackmanharris70, blackmanharris74, blackmanharris92}, default = hann</em>) :</dt>
<dd><p class="first last">the window type, which can be 'hamming', 'hann', 'triangular', 'square' or 'blackmanharrisXX'</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>zeroPadding</strong> (<em>integer ∈ [0, ∞), default = 0</em>) :</dt>
<dd><p class="first last">the size of the zero-padding</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt><strong>zeroPhase</strong> (<em>bool ∈ {true, false}, default = true</em>) :</dt>
<dd><p class="first last">a boolean value that enables zero-phase windowing</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm applies windowing to audio signals.
It optionally applies zero-phase windowing and optionally adds zero-padding.
The resulting windowed frame size is equal to the incoming frame size plus the number of padded zeros.
The available windows are normalized (to have an area of 1) and then scaled by a factor of 2.</p>
<p>An exception is thrown if the size of the frame is less than 2.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] F. J. Harris, &quot;On the use of windows for harmonic analysis with the
discrete Fourier transform, Proceedings of the IEEE, vol. 66, no. 1,
pp. 51-83, Jan. 1978</p>
<p class="last">[2] Window function - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Window_function">http://en.wikipedia.org/wiki/Window_function</a></p>
</dd>
</dl>
</td></tr>
<tr>
<th scope="row" class="col-xs-1">
ZeroCrossingRate<br>[streaming]

</th><td class="col-xs-2">
<li><strong>signal</strong> (<em>vector_real</em>) - the input signal</li>
</td><td class="col-xs-2">
<li><strong>zeroCrossingRate</strong> (<em>real</em>) - the zero-crossing rate</li>
</td><td class="col-xs-2">
<li><dl class="first docutils">
<dt><strong>threshold</strong> (<em>real ∈ [0, ∞], default = 0</em>) :</dt>
<dd><p class="first last">the threshold which will be taken as the zero axis in both positive and negative sign</p>
</dd>
</dl>
</li>
</td><td class="col-xs-5">
<p>This algorithm returns the zero-crossing rate of an audio signal. It is the number of sign changes between consecutive signal values divided by the total number of values. Noisy signals tend to have higher zero-crossing rate.
In order to avoid small variations around zero caused by noise, a threshold around zero is given to consider a valid zerocrosing whenever the boundary is crossed.</p>
<p>Empty input signals will raise an exception.</p>
<dl class="docutils">
<dt>References:</dt>
<dd><p class="first">[1] Zero Crossing - Wikipedia, the free encyclopedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Zero-crossing_rate">http://en.wikipedia.org/wiki/Zero-crossing_rate</a></p>
<p class="last">[2] G. Peeters, &quot;A large set of audio features for sound description
(similarity and classification) in the CUIDADO project,&quot; CUIDADO I.S.T.
Project Report, 2004</p>
</dd>
</dl>
</td></tr>

    </tbody>
</table>
</body>
</html>
